{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Jupyter notebook for test of any type**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pipe/venv/bigDatavenv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "import os\n",
    "import numpy as np\n",
    "import pyspark as ps\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import desc, asc, min, max, to_timestamp, col, count, date_trunc, udf, pandas_udf, PandasUDFType,to_date, date_trunc,length,lower, split, explode\n",
    "import langdetect \n",
    "from pyspark.sql.types import StringType, BooleanType\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get the absolute path of the project root\n",
    "project_root = os.path.abspath(\"..\")  # Adjust if necessary\n",
    "\n",
    "# Add the src directory to Python's path\n",
    "sys.path.append(os.path.join(project_root, \"src\"))\n",
    "\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import s3_utils as s3U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-03-24 17:31:43--  https://huggingface.co/datasets/Zihan1004/FNSPID/resolve/main/Stock_news/All_external.csv\n",
      "Resolving huggingface.co (huggingface.co)... 54.192.95.70, 54.192.95.21, 54.192.95.79, ...\n",
      "Connecting to huggingface.co (huggingface.co)|54.192.95.70|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://cdn-lfs-us-1.hf.co/repos/a0/19/a01967ba742831f4b6903f146b4f5d9a3d2eeeefa619387e8cc87df2d889332c/5d4c018036bd82ca821da71b7a9c0c7db3289642e0fc6f897ea69f4a0c5135c3?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27All_external.csv%3B+filename%3D%22All_external.csv%22%3B&response-content-type=text%2Fcsv&Expires=1742837503&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc0MjgzNzUwM319LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zL2EwLzE5L2EwMTk2N2JhNzQyODMxZjRiNjkwM2YxNDZiNGY1ZDlhM2QyZWVlZWZhNjE5Mzg3ZThjYzg3ZGYyZDg4OTMzMmMvNWQ0YzAxODAzNmJkODJjYTgyMWRhNzFiN2E5YzBjN2RiMzI4OTY0MmUwZmM2Zjg5N2VhNjlmNGEwYzUxMzVjMz9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSomcmVzcG9uc2UtY29udGVudC10eXBlPSoifV19&Signature=H9IOkAvKum3AXYNmBI2rtcqKkfbZyWpDYPK1J3W5RcgYWQjyKajHH7RIBawuIQqACgQdw7xyRQbpyQB2zmPzGrIGugpGaPOM1vMCA8e6UOyUAVoaYMZKi87VZ78Nd6IcQqZ9cYHdbO6lvP-pC9E7xbpXxDlqV8jhMn3I6Vb9sZu%7EPtv4qxFHI5aHAmU20YR3Tdi1OOBT8ziHcziSRPs%7ETdQAElurIek2H%7EabupIa4Ad6W96TkUPEKr-7lpRznRNEa9-of9nTUIEeybOHaomdr7UkH5QPkPK11rW9IvHXXbO6M6Y0ltE4IpxfMGXks5L0VECHd6sfupIH2aRllhpHJg__&Key-Pair-Id=K24J24Z295AEI9 [following]\n",
      "--2025-03-24 17:31:43--  https://cdn-lfs-us-1.hf.co/repos/a0/19/a01967ba742831f4b6903f146b4f5d9a3d2eeeefa619387e8cc87df2d889332c/5d4c018036bd82ca821da71b7a9c0c7db3289642e0fc6f897ea69f4a0c5135c3?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27All_external.csv%3B+filename%3D%22All_external.csv%22%3B&response-content-type=text%2Fcsv&Expires=1742837503&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc0MjgzNzUwM319LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zL2EwLzE5L2EwMTk2N2JhNzQyODMxZjRiNjkwM2YxNDZiNGY1ZDlhM2QyZWVlZWZhNjE5Mzg3ZThjYzg3ZGYyZDg4OTMzMmMvNWQ0YzAxODAzNmJkODJjYTgyMWRhNzFiN2E5YzBjN2RiMzI4OTY0MmUwZmM2Zjg5N2VhNjlmNGEwYzUxMzVjMz9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSomcmVzcG9uc2UtY29udGVudC10eXBlPSoifV19&Signature=H9IOkAvKum3AXYNmBI2rtcqKkfbZyWpDYPK1J3W5RcgYWQjyKajHH7RIBawuIQqACgQdw7xyRQbpyQB2zmPzGrIGugpGaPOM1vMCA8e6UOyUAVoaYMZKi87VZ78Nd6IcQqZ9cYHdbO6lvP-pC9E7xbpXxDlqV8jhMn3I6Vb9sZu%7EPtv4qxFHI5aHAmU20YR3Tdi1OOBT8ziHcziSRPs%7ETdQAElurIek2H%7EabupIa4Ad6W96TkUPEKr-7lpRznRNEa9-of9nTUIEeybOHaomdr7UkH5QPkPK11rW9IvHXXbO6M6Y0ltE4IpxfMGXks5L0VECHd6sfupIH2aRllhpHJg__&Key-Pair-Id=K24J24Z295AEI9\n",
      "Resolving cdn-lfs-us-1.hf.co (cdn-lfs-us-1.hf.co)... 108.157.109.49, 108.157.109.126, 108.157.109.99, ...\n",
      "Connecting to cdn-lfs-us-1.hf.co (cdn-lfs-us-1.hf.co)|108.157.109.49|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 5731397037 (5.3G) [text/csv]\n",
      "Saving to: ‘All_external.csv’\n",
      "\n",
      "All_external.csv    100%[===================>]   5.34G  32.0MB/s    in 4m 22s  \n",
      "\n",
      "2025-03-24 17:36:05 (20.9 MB/s) - ‘All_external.csv’ saved [5731397037/5731397037]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://huggingface.co/datasets/Zihan1004/FNSPID/resolve/main/Stock_news/All_external.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket= \"financialdata-sa\"\n",
    "news_external = \"RawNews/All_external.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "your 131072x1 screen size is bogus. expect trouble\n",
      "25/03/14 19:16:39 WARN Utils: Your hostname, Andres-F resolves to a loopback address: 127.0.1.1; using 10.255.255.254 instead (on interface lo)\n",
      "25/03/14 19:16:39 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "25/03/14 19:16:39 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/03/14 19:16:42 WARN MetricsConfig: Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.properties\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "news1 = s3U.get_csv_as_spark(bucket_name=bucket, s3_key=news_external)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+------------+--------------------+-----------------+------+-------+-----------+------------+----------------+---------------+\n",
      "|                Date|       Article_title|Stock_symbol|                 Url|        Publisher|Author|Article|Lsa_summary|Luhn_summary|Textrank_summary|Lexrank_summary|\n",
      "+--------------------+--------------------+------------+--------------------+-----------------+------+-------+-----------+------------+----------------+---------------+\n",
      "|2020-06-05 06:30:...|Stocks That Hit 5...|           A|https://www.benzi...|Benzinga Insights|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2020-06-03 06:45:...|Stocks That Hit 5...|           A|https://www.benzi...|Benzinga Insights|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2020-05-26 00:30:...|71 Biggest Movers...|           A|https://www.benzi...|       Lisa Levin|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2020-05-22 08:45:...|46 Stocks Moving ...|           A|https://www.benzi...|       Lisa Levin|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2020-05-22 07:38:...|B of A Securities...|           A|https://www.benzi...|       Vick Meyer|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "+--------------------+--------------------+------------+--------------------+-----------------+------+-------+-----------+------------+----------------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 2:====>                                                     (3 + 2) / 43]\r"
     ]
    }
   ],
   "source": [
    "news1.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "your 131072x1 screen size is bogus. expect trouble\n",
      "25/03/24 19:39:07 WARN Utils: Your hostname, Andres-F resolves to a loopback address: 127.0.1.1; using 10.255.255.254 instead (on interface lo)\n",
      "25/03/24 19:39:07 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/03/24 19:39:08 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName(\"Data Exploration\") \\\n",
    "    .config(\"spark.driver.memory\", \"8g\") \\\n",
    "    .config(\"spark.executor.memory\", \"8g\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_csv = spark.read \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"inferSchema\", \"true\") \\\n",
    "    .csv(\"../data/raw/nasdaq_exteral_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Unnamed: 0: string (nullable = true)\n",
      " |-- Date: string (nullable = true)\n",
      " |-- Article_title: string (nullable = true)\n",
      " |-- Stock_symbol: string (nullable = true)\n",
      " |-- Url: string (nullable = true)\n",
      " |-- Publisher: string (nullable = true)\n",
      " |-- Author: string (nullable = true)\n",
      " |-- Article: string (nullable = true)\n",
      " |-- Lsa_summary: string (nullable = true)\n",
      " |-- Luhn_summary: string (nullable = true)\n",
      " |-- Textrank_summary: string (nullable = true)\n",
      " |-- Lexrank_summary: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_csv.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+---------------+\n",
      "|          Unnamed: 0|                Date|       Article_title|        Stock_symbol|                 Url|           Publisher|              Author|             Article|         Lsa_summary|        Luhn_summary|    Textrank_summary|Lexrank_summary|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+---------------+\n",
      "|                 0.0|2023-12-16 23:00:...|Interesting A Put...|                   A|https://www.nasda...|                NULL|                NULL|Investors in Agil...|                NULL|                NULL|                NULL|           NULL|\n",
      "|The put contract ...| they are committ...| but will also co...| putting the cost...| that could repre...|                NULL|                NULL|                NULL|                NULL|                NULL|                NULL|           NULL|\n",
      "|Because the $125....| there is also th...| publishing a cha...| the premium woul...| or 5.45% annuali...|                NULL|                NULL|                NULL|                NULL|                NULL|                NULL|           NULL|\n",
      "|Below is a chart ...|                Inc.| and highlighting...|                NULL|                NULL|                NULL|                NULL|                NULL|                NULL|                NULL|                NULL|           NULL|\n",
      "|Turning to the ca...| the call contrac...| and then sell-to...|\"\" they are commi...| that would drive...| if any) of 13.75...| a lot of upside ...| which is why loo...|                Inc.| as well as study...| with the $150.00...|           NULL|\n",
      "|Considering the f...| there is also th...| in which case th...| Stock Options Ch...| the premium woul...| or 8.83% annualized| which we refer t...|                NULL|                NULL|                NULL|                NULL|           NULL|\n",
      "|The implied volat...| while the implie...|                NULL|                NULL|                NULL|                NULL|                NULL|                NULL|                NULL|                NULL|                NULL|           NULL|\n",
      "|           Meanwhile| we calculate the...| visit StockOptio...|                NULL|                NULL|                NULL|                NULL|                NULL|                NULL|                NULL|                NULL|           NULL|\n",
      "|Top YieldBoost Ca...|                NULL|                NULL|                NULL|                NULL|                NULL|                NULL|                NULL|                NULL|                NULL|                NULL|           NULL|\n",
      "|           Also see:|                NULL|                NULL|                NULL|                NULL|                NULL|                NULL|                NULL|                NULL|                NULL|                NULL|           NULL|\n",
      "| Canadian Stocks...|                NULL|                NULL|                NULL|                NULL|                NULL|                NULL|                NULL|                NULL|                NULL|                NULL|           NULL|\n",
      "| Funds Holding SNUG|                NULL|                NULL|                NULL|                NULL|                NULL|                NULL|                NULL|                NULL|                NULL|                NULL|           NULL|\n",
      "| CCE Insider Buying|                NULL|                NULL|                NULL|                NULL|                NULL|                NULL|                NULL|                NULL|                NULL|                NULL|           NULL|\n",
      "|The views and opi...|               Inc.\"|Because the $125....|The current analy...|Below is a chart ...|At Stock Options ...|                NULL|                NULL|                NULL|                NULL|                NULL|           NULL|\n",
      "|                 1.0|2023-12-12 00:00:...|Wolfe Research In...|                   A|https://www.nasda...|                NULL|                NULL|Fintel reports th...|                NULL|                NULL|                NULL|           NULL|\n",
      "|Analyst Price For...|                NULL|                NULL|                NULL|                NULL|                NULL|                NULL|                NULL|                NULL|                NULL|                NULL|           NULL|\n",
      "|   As of November 27|                2023| the average one-...|                NULL|                NULL|                NULL|                NULL|                NULL|                NULL|                NULL|                NULL|           NULL|\n",
      "|See our leaderboa...|                NULL|                NULL|                NULL|                NULL|                NULL|                NULL|                NULL|                NULL|                NULL|                NULL|           NULL|\n",
      "|The projected ann...|               130MM| an increase of 4...|                NULL|                NULL|                NULL|                NULL|                NULL|                NULL|                NULL|                NULL|           NULL|\n",
      "|Agilent Technolog...|                NULL|                NULL|                NULL|                NULL|                NULL|                NULL|                NULL|                NULL|                NULL|                NULL|           NULL|\n",
      "|      On November 15| 2023 the company...| 2024 will receiv...|    2024. Previously| the company paid...|                NULL|                NULL|                NULL|                NULL|                NULL|                NULL|           NULL|\n",
      "|At the current sh...| the stock's divi...|                NULL|                NULL|                NULL|                NULL|                NULL|                NULL|                NULL|                NULL|                NULL|           NULL|\n",
      "|Looking back five...| the average divi...| the lowest has b...| and the highest ...|                NULL|                NULL|                NULL|                NULL|                NULL|                NULL|                NULL|           NULL|\n",
      "|The current divid...|                NULL|                NULL|                NULL|                NULL|                NULL|                NULL|                NULL|                NULL|                NULL|                NULL|           NULL|\n",
      "|        Additionally| the company's di...| which typically ...| which translates...|                NULL|                NULL|                NULL|                NULL|                NULL|                NULL|                NULL|           NULL|\n",
      "|The company's 3-Y...| demonstrating th...|                NULL|                NULL|                NULL|                NULL|                NULL|                NULL|                NULL|                NULL|                NULL|           NULL|\n",
      "|What is the Fund ...|                NULL|                NULL|                NULL|                NULL|                NULL|                NULL|                NULL|                NULL|                NULL|                NULL|           NULL|\n",
      "|There are 1945 fu...| a decrease of 2....|        740K shares.|                NULL|                NULL|                NULL|                NULL|                NULL|                NULL|                NULL|                NULL|           NULL|\n",
      "|The put/call rati...| indicating a bea...|                NULL|                NULL|                NULL|                NULL|                NULL|                NULL|                NULL|                NULL|                NULL|           NULL|\n",
      "|What are Other Sh...|                NULL|                NULL|                NULL|                NULL|                NULL|                NULL|                NULL|                NULL|                NULL|                NULL|           NULL|\n",
      "|Massachusetts Fin...|076K shares repre...| the firm reporte...|         037K shares| representing an ...|                NULL|                NULL|                NULL|                NULL|                NULL|                NULL|           NULL|\n",
      "|Wellington Manage...|256K shares repre...| the firm reporte...|         736K shares| representing an ...|                NULL|                NULL|                NULL|                NULL|                NULL|                NULL|           NULL|\n",
      "|T. Rowe Price Inv...|122K shares repre...| the firm reporte...|         968K shares| representing an ...|                NULL|                NULL|                NULL|                NULL|                NULL|                NULL|           NULL|\n",
      "|VTSMX - Vanguard ...|113K shares repre...| the firm reporte...|         177K shares| representing a d...|                NULL|                NULL|                NULL|                NULL|                NULL|                NULL|           NULL|\n",
      "|Price T Rowe Asso...|386K shares repre...| the firm reporte...|         054K shares| representing a d...|                NULL|                NULL|                NULL|                NULL|                NULL|                NULL|           NULL|\n",
      "|Agilent Technolog...|                NULL|                NULL|                NULL|                NULL|                NULL|                NULL|                NULL|                NULL|                NULL|                NULL|           NULL|\n",
      "|(This description...|                NULL|                NULL|                NULL|                NULL|                NULL|                NULL|                NULL|                NULL|                NULL|                NULL|           NULL|\n",
      "|Agilent Technolog...|         diagnostics| and applied chem...| delivering insig...|            software|            services|           solutions| and people provi...|400 people worldw...|                NULL|                NULL|           NULL|\n",
      "|Fintel is one of ...|             traders|  financial advisors| and small hedge ...|                NULL|                NULL|                NULL|                NULL|                NULL|                NULL|                NULL|           NULL|\n",
      "|Our data covers t...| and includes fun...|     analyst reports| ownership data a...|   options sentiment|     insider trading|        options flow| unusual options ...| and much more. A...| our exclusive st...| backtested quant...|           NULL|\n",
      "| Click to Learn More|                NULL|                NULL|                NULL|                NULL|                NULL|                NULL|                NULL|                NULL|                NULL|                NULL|           NULL|\n",
      "|This story origin...|                NULL|                NULL|                NULL|                NULL|                NULL|                NULL|                NULL|                NULL|                NULL|                NULL|           NULL|\n",
      "|The views and opi...|               Inc.\"|Fintel reports th...|T. Rowe Price Inv...|Agilent Technolog...|The projected ann...|                NULL|                NULL|                NULL|                NULL|                NULL|           NULL|\n",
      "|                 2.0|2023-12-12 00:00:...|Agilent Technolog...|                   A|https://www.nasda...|                NULL|                NULL|In recent trading...|                NULL|                NULL|                NULL|           NULL|\n",
      "|There are 14 diff...|                Inc.| but the average ...| including one lo...|                NULL|                NULL|                NULL|                NULL|                NULL|                NULL|                NULL|           NULL|\n",
      "|But the whole rea...| putting together...| as opposed to wh...| investors in A h...| or has the valua...|               Inc.:|                NULL|                NULL|                NULL|                NULL|                NULL|           NULL|\n",
      "|RECENT A ANALYST ...|                NULL|                NULL|                NULL|                NULL|                NULL|                NULL|                NULL|                NULL|                NULL|                NULL|           NULL|\n",
      "|» Current 1 Month...|                NULL|                NULL|                NULL|                NULL|                NULL|                NULL|                NULL|                NULL|                NULL|                NULL|           NULL|\n",
      "|Strong buy rating...|                NULL|                NULL|                NULL|                NULL|                NULL|                NULL|                NULL|                NULL|                NULL|                NULL|           NULL|\n",
      "|Buy ratings: 0 0 0 0|                NULL|                NULL|                NULL|                NULL|                NULL|                NULL|                NULL|                NULL|                NULL|                NULL|           NULL|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+---------------+\n",
      "only showing top 50 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_csv.show(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "\n",
    "df_csv_5gb = spark.read \\\n",
    "    .format(\"csv\") \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"inferSchema\", \"true\") \\\n",
    "    .option(\"multiLine\", \"true\") \\\n",
    "    .option(\"escape\", \"\\\"\") \\\n",
    "    .option(\"quote\", \"\\\"\") \\\n",
    "    .option(\"delimiter\", \",\") \\\n",
    "    .option(\"mode\", \"PERMISSIVE\") \\\n",
    "    .load(\"../data/raw/All_external.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[summary: string, Article_title: string, Stock_symbol: string, Url: string, Publisher: string, Author: string, Article: string, Lsa_summary: string, Luhn_summary: string, Textrank_summary: string, Lexrank_summary: string]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_csv_5gb.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+------------+--------------------+--------------------+------+-------+-----------+------------+----------------+---------------+\n",
      "|                Date|       Article_title|Stock_symbol|                 Url|           Publisher|Author|Article|Lsa_summary|Luhn_summary|Textrank_summary|Lexrank_summary|\n",
      "+--------------------+--------------------+------------+--------------------+--------------------+------+-------+-----------+------------+----------------+---------------+\n",
      "|2020-06-05 06:30:...|Stocks That Hit 5...|           A|https://www.benzi...|   Benzinga Insights|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2020-06-03 06:45:...|Stocks That Hit 5...|           A|https://www.benzi...|   Benzinga Insights|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2020-05-26 00:30:...|71 Biggest Movers...|           A|https://www.benzi...|          Lisa Levin|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2020-05-22 08:45:...|46 Stocks Moving ...|           A|https://www.benzi...|          Lisa Levin|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2020-05-22 07:38:...|B of A Securities...|           A|https://www.benzi...|          Vick Meyer|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2020-05-22 07:23:...|CFRA Maintains Ho...|           A|https://www.benzi...|vishwanath@benzin...|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2020-05-22 05:36:...|UBS Maintains Neu...|           A|https://www.benzi...|vishwanath@benzin...|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2020-05-22 05:07:...|Agilent Technolog...|           A|https://www.benzi...|   Benzinga Newsdesk|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2020-05-22 04:37:...|Wells Fargo Maint...|           A|https://www.benzi...|vishwanath@benzin...|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2020-05-22 04:06:...|10 Biggest Price ...|           A|https://www.benzi...|          Lisa Levin|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2020-05-22 00:00:...|30 Stocks Moving ...|           A|https://www.benzi...|          Lisa Levin|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2020-05-22 00:00:...|SVB Leerink Maint...|           A|https://www.benzi...|vishwanath@benzin...|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2020-05-21 00:00:...|8 Stocks Moving I...|           A|https://www.benzi...|        Tyree Gorges|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2020-05-21 00:00:...|Agilent Technolog...|           A|https://www.benzi...|   Benzinga Newsdesk|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2020-05-21 00:00:...|Agilent Technolog...|           A|https://www.benzi...|   Benzinga Newsdesk|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2020-05-21 00:00:...|Earnings Schedule...|           A|https://www.benzi...|          Lisa Levin|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2020-05-18 00:00:...|Agilent Technolog...|           A|https://www.benzi...|       Luke J Jacobi|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2020-05-16 00:00:...|Q1 13F Roundup: H...|           A|https://www.benzi...|        Wayne Duggan|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2020-05-15 00:00:...|Pershing Square 1...|           A|https://www.benzi...|   Benzinga Newsdesk|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2020-05-08 00:00:...|How Bill Ackman S...|           A|https://www.benzi...|        Wayne Duggan|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2020-05-05 00:00:...|Shares of several...|           A|https://www.benzi...|   Benzinga Newsdesk|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2020-05-01 00:00:...|Shares of several...|           A|https://www.benzi...|   Benzinga Newsdesk|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2020-04-28 00:00:...|UBS Maintains Neu...|           A|https://www.benzi...|vishwanath@benzin...|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2020-04-23 00:00:...|Agilent Reports F...|           A|https://www.benzi...|   Benzinga Newsdesk|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2020-04-22 00:00:...|Agilent Reports H...|           A|https://www.benzi...|   Benzinga Newsdesk|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2020-04-14 00:00:...|Agilent Withdraws...|           A|https://www.benzi...|   Benzinga Newsdesk|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2020-04-08 00:00:...|Shares of several...|           A|https://www.benzi...|   Benzinga Newsdesk|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2020-04-06 00:00:...|Shares of several...|           A|https://www.benzi...|   Benzinga Newsdesk|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2020-04-02 00:00:...|Stifel Maintains ...|           A|https://www.benzi...|          Vick Meyer|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2020-04-01 00:00:...|Shares of several...|           A|https://www.benzi...|   Benzinga Newsdesk|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2020-03-31 00:00:...|Int'l. Air Transp...|           A|https://www.benzi...|   Benzinga Newsdesk|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2020-03-30 00:00:...|Wells Fargo Maint...|           A|https://www.benzi...|          Vick Meyer|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2020-03-30 00:00:...|Shares of several...|           A|https://www.benzi...|   Benzinga Newsdesk|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2020-03-27 00:00:...|Shares of several...|           A|https://www.benzi...|   Benzinga Newsdesk|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2020-03-26 00:00:...|Shares of several...|           A|https://www.benzi...|   Benzinga Newsdesk|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2020-03-26 00:00:...|Barclays Maintain...|           A|https://www.benzi...|          Vick Meyer|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2020-03-26 00:00:...|Ariel Chairman Jo...|           A|https://www.benzi...|   Shivdeep Dhaliwal|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2020-03-20 00:00:...|Citigroup Maintai...|           A|https://www.benzi...|          Vick Meyer|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2020-03-16 00:00:...|Stocks That Hit 5...|           A|https://www.benzi...|   Benzinga Newsdesk|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2020-03-16 00:00:...|Shares of several...|           A|https://www.benzi...|   Benzinga Newsdesk|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2020-03-13 00:00:...|Shares of several...|           A|https://www.benzi...|   Benzinga Newsdesk|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2020-03-12 00:00:...|Stocks That Hit 5...|           A|https://www.benzi...|          Lisa Levin|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2020-03-11 00:00:...|Shares of several...|           A|https://www.benzi...|   luke@benzinga.com|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2020-03-03 00:00:...|Agilent Technolog...|           A|https://www.benzi...|   luke@benzinga.com|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2020-03-02 00:00:...|Shares of several...|           A|https://www.benzi...|   Benzinga Newsdesk|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2020-02-24 00:00:...|Benzinga's Top Up...|           A|https://www.benzi...|          Lisa Levin|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2020-02-24 00:00:...|Shares of several...|           A|https://www.benzi...|   Benzinga Newsdesk|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2020-02-24 00:00:...|Needham Downgrade...|           A|https://www.benzi...|          Vick Meyer|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2020-02-19 00:00:...|UBS Maintains Neu...|           A|https://www.benzi...|          Vick Meyer|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2020-02-18 00:00:...|12 Stocks Moving ...|           A|https://www.benzi...|        Tyree Gorges|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2020-02-18 00:00:...|Agilent Technolog...|           A|https://www.benzi...|   Benzinga Newsdesk|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2020-02-18 00:00:...|Agilent Reaffirms...|           A|https://www.benzi...|   Benzinga Newsdesk|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2020-02-18 00:00:...|Agilent Technolog...|           A|https://www.benzi...|   Benzinga Newsdesk|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2020-02-18 00:00:...|Q4 13F Roundup: H...|           A|https://www.benzi...|        Wayne Duggan|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2020-02-18 00:00:...|9 Stocks To Watch...|           A|https://www.benzi...|          Lisa Levin|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2020-02-18 00:00:...|Earnings Schedule...|           A|https://www.benzi...|          Lisa Levin|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2020-02-14 00:00:...|Pershing Square 1...|           A|https://www.benzi...|   Benzinga Newsdesk|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2020-02-06 00:00:...|Twist Bioscience ...|           A|https://www.benzi...|   Benzinga Newsdesk|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2020-02-06 00:00:...|Cowen Says Views ...|           A|https://www.benzi...|   Benzinga Newsdesk|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2020-02-05 00:00:...|Pershing Square S...|           A|https://www.benzi...|   Benzinga Newsdesk|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2020-01-30 00:00:...|Agilent shares ar...|           A|https://www.benzi...|   Benzinga Newsdesk|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2020-01-22 00:00:...|Stocks That Hit 5...|           A|https://www.benzi...|          Lisa Levin|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2020-01-17 00:00:...|Stocks That Hit 5...|           A|https://www.benzi...|          Lisa Levin|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2020-01-16 00:00:...|Stocks That Hit 5...|           A|https://www.benzi...|          Lisa Levin|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2020-01-15 00:00:...|Stocks That Hit 5...|           A|https://www.benzi...|          Lisa Levin|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2020-01-10 00:00:...|Stocks That Hit 5...|           A|https://www.benzi...|          Lisa Levin|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2020-01-09 00:00:...|Stocks That Hit 5...|           A|https://www.benzi...|          Lisa Levin|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2020-01-08 00:00:...|Wells Fargo Initi...|           A|https://www.benzi...|   Benzinga_Newsdesk|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2020-01-07 00:00:...|Citigroup Initiat...|           A|https://www.benzi...|   Benzinga_Newsdesk|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2020-01-03 00:00:...|Benzinga's Top Up...|           A|https://www.benzi...|          Lisa Levin|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2019-12-27 00:00:...|Stocks That Hit 5...|           A|https://www.benzi...|          Lisa Levin|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2019-12-23 00:00:...|Stocks That Hit 5...|           A|https://www.benzi...|          Lisa Levin|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2019-12-20 00:00:...|Stocks That Hit 5...|           A|https://www.benzi...|          Lisa Levin|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2019-12-12 00:00:...|Stocks That Hit 5...|           A|https://www.benzi...|          Lisa Levin|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2019-12-11 00:00:...|There's A New Tra...|           A|https://www.benzi...|      Spencer Israel|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2019-12-10 00:00:...|Stocks That Hit 5...|           A|https://www.benzi...|          Lisa Levin|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2019-12-10 00:00:...|PreMarket Prep Re...|           A|https://www.benzi...|        Joel Elconin|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2019-12-10 00:00:...|41 Healthcare Sto...|           A|https://www.benzi...|          Lisa Levin|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2019-12-09 00:00:...|UPDATE: Bill Ackm...|           A|https://www.benzi...|   Benzinga Newsdesk|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2019-12-09 00:00:...|Hearing Pershing ...|           A|https://www.benzi...|   Benzinga Newsdesk|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2019-12-06 00:00:...|Stocks That Hit 5...|           A|https://www.benzi...|          Lisa Levin|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2019-11-26 00:00:...|UBS Maintains Neu...|           A|https://www.benzi...|          Vick Meyer|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2019-11-25 00:00:...|Aligent shares ar...|           A|https://www.benzi...|   Benzinga Newsdesk|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2019-11-25 00:00:...|Agilent Sees FY20...|           A|https://www.benzi...|   Benzinga Newsdesk|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2019-11-25 00:00:...|Agilent Sees Q1 A...|           A|https://www.benzi...|   Benzinga Newsdesk|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2019-11-25 00:00:...|Agilent Technolog...|           A|https://www.benzi...|   Benzinga Newsdesk|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2019-11-25 00:00:...|7 Stocks To Watch...|           A|https://www.benzi...|          Lisa Levin|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2019-11-25 00:00:...|Earnings Schedule...|           A|https://www.benzi...|          Lisa Levin|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2019-11-20 00:00:...|Agilent Raises Qt...|           A|https://www.benzi...|   Benzinga Newsdesk|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2019-11-15 00:00:...|Benzinga's Top Up...|           A|https://www.benzi...|          Lisa Levin|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2019-11-15 00:00:...|Stifel Nicolaus I...|           A|https://www.benzi...|          Vick Meyer|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2019-10-18 00:00:...|Benzinga's Top Up...|           A|https://www.benzi...|          Lisa Levin|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2019-10-18 00:00:...|A Peek Into The M...|           A|https://www.benzi...|          Lisa Levin|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2019-10-18 00:00:...|UBS Downgrades Ag...|           A|https://www.benzi...|          Vick Meyer|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2019-10-11 00:00:...|Shares of several...|           A|https://www.benzi...|   Benzinga Newsdesk|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2019-10-09 00:00:...|Barclays Maintain...|           A|https://www.benzi...|          Vick Meyer|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2019-10-08 00:00:...|Shares of several...|           A|https://www.benzi...|   Benzinga Newsdesk|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2019-10-02 00:00:...|Shares of several...|           A|https://www.benzi...|   Benzinga Newsdesk|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2019-09-05 00:00:...|Shares of several...|           A|https://www.benzi...|   Benzinga Newsdesk|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2019-09-03 00:00:...|Agilent Collabora...|           A|https://www.benzi...|   Benzinga Newsdesk|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2019-08-16 00:00:...|Top 10 Movers Via...|           A|https://www.benzi...|   Benzinga Newsdesk|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2019-08-16 00:00:...|75 Biggest Movers...|           A|https://www.benzi...|          Lisa Levin|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2019-08-15 00:00:...|46 Stocks Moving ...|           A|https://www.benzi...|          Lisa Levin|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2019-08-15 00:00:...|Agilent Technolog...|           A|https://www.benzi...|   Benzinga Newsdesk|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2019-08-15 00:00:...|A Peek Into The M...|           A|https://www.benzi...|          Lisa Levin|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2019-08-15 00:00:...|10 Stocks To Watc...|           A|https://www.benzi...|          Lisa Levin|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2019-08-14 00:00:...|Agilent Technolog...|           A|https://www.benzi...|   Benzinga Newsdesk|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2019-08-14 00:00:...|Agilent Technolog...|           A|https://www.benzi...|   Benzinga Newsdesk|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2019-08-14 00:00:...|Agilent Technolog...|           A|https://www.benzi...|   Benzinga Newsdesk|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2019-08-14 00:00:...|Q3 Earnings Previ...|           A|https://www.benzi...|   Benzinga Newsdesk|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2019-08-14 00:00:...|Earnings Schedule...|           A|https://www.benzi...|          Lisa Levin|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2019-08-06 00:00:...|Shares of diagnos...|           A|https://www.benzi...|   Benzinga Newsdesk|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2019-08-05 00:00:...|Shares of several...|           A|https://www.benzi...|   Benzinga Newsdesk|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2019-08-01 00:00:...|Agilent Announces...|           A|https://www.benzi...|       Charles Gross|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2019-07-31 00:00:...|Agilent Shares Un...|           A|https://www.benzi...|   Benzinga Newsdesk|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2019-07-16 00:00:...|Benzinga Pro's To...|           A|https://www.benzi...|   Benzinga Newsdesk|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2019-07-16 00:00:...|Benzinga's Top Up...|           A|https://www.benzi...|          Lisa Levin|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2019-07-16 00:00:...|Bank of America D...|           A|https://www.benzi...|   Benzinga_Newsdesk|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2019-07-15 00:00:...|Barclays Downgrad...|           A|https://www.benzi...|          Vick Meyer|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2019-07-11 00:00:...|Agilent Will Acqu...|           A|https://www.benzi...|      Tanzeel Akhtar|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2019-07-11 00:00:...|Agilent To Purcha...|           A|https://www.benzi...|   Benzinga Newsdesk|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2019-06-11 00:00:...|Benzinga's Top Up...|           A|https://www.benzi...|          Lisa Levin|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2019-06-11 00:00:...|Agilent Companion...|           A|https://www.benzi...|   Benzinga Newsdesk|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2019-06-11 00:00:...|Piper Jaffray Ini...|           A|https://www.benzi...|          Vick Meyer|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2019-05-16 00:00:...|Shares of many He...|           A|https://www.benzi...|   Benzinga Newsdesk|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2019-05-16 00:00:...|60 Biggest Movers...|           A|https://www.benzi...|          Lisa Levin|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2019-05-15 00:00:...|44 Stocks Moving ...|           A|https://www.benzi...|          Lisa Levin|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2019-05-15 00:00:...|Benzinga Pro's To...|           A|https://www.benzi...|   Benzinga Newsdesk|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2019-05-15 00:00:...|Bank of America M...|           A|https://www.benzi...|          Vick Meyer|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2019-05-15 00:00:...|Agilent Technolog...|           A|https://www.benzi...|  Benzinga  Newsdesk|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2019-05-15 00:00:...|Deutsche Bank Mai...|           A|https://www.benzi...|          Vick Meyer|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2019-05-15 00:00:...|Barclays Maintain...|           A|https://www.benzi...|          Vick Meyer|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2019-05-15 00:00:...|A Peek Into The M...|           A|https://www.benzi...|          Lisa Levin|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2019-05-15 00:00:...|8 Stocks To Watch...|           A|https://www.benzi...|          Lisa Levin|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2019-05-14 00:00:...|5 Stocks Moving I...|           A|https://www.benzi...|      Brett Hershman|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2019-05-14 00:00:...|Agilent Technolog...|           A|https://www.benzi...|          Hal Lindon|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2019-05-14 00:00:...|Agilent Technolog...|           A|https://www.benzi...|   Benzinga Newsdesk|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2019-05-14 00:00:...|Agilent Technolog...|           A|https://www.benzi...|   Benzinga Newsdesk|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2019-05-14 00:00:...|Shares of several...|           A|https://www.benzi...|   Benzinga Newsdesk|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2019-05-14 00:00:...|6 Stocks To Watch...|           A|https://www.benzi...|          Lisa Levin|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2019-05-14 00:00:...|Earnings Schedule...|           A|https://www.benzi...|          Lisa Levin|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2019-05-10 00:00:...|Shares of several...|           A|https://www.benzi...|   Benzinga Newsdesk|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2019-03-26 00:00:...|10 Biggest Price ...|           A|https://www.benzi...|          Lisa Levin|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2019-03-26 00:00:...|Cowen & Co. Maint...|           A|https://www.benzi...|          Vick Meyer|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2019-03-15 00:00:...|Benzinga's Top Up...|           A|https://www.benzi...|          Lisa Levin|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2019-03-15 00:00:...|UBS Initiates Cov...|           A|https://www.benzi...|          Vick Meyer|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2019-02-21 00:00:...|Barclays Maintain...|           A|https://www.benzi...|          Vick Meyer|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2019-02-20 00:00:...|UPDATE: Agilent R...|           A|https://www.benzi...|   Benzinga Newsdesk|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2019-02-20 00:00:...|Agilent Sees Q2 A...|           A|https://www.benzi...|   Benzinga Newsdesk|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2019-02-20 00:00:...|Agilent Technolog...|           A|https://www.benzi...|   Benzinga Newsdesk|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2019-02-20 00:00:...|10 Stocks To Watc...|           A|https://www.benzi...|          Lisa Levin|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2019-02-20 00:00:...|Earnings Schedule...|           A|https://www.benzi...|          Lisa Levin|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2019-02-14 00:00:...|JANA 13F Shows Li...|           A|https://www.benzi...|   Benzinga Newsdesk|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2019-02-12 00:00:...|8 Biggest Price T...|           A|https://www.benzi...|          Lisa Levin|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2019-02-12 00:00:...|Deutsche Bank Mai...|           A|https://www.benzi...|          Vick Meyer|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2019-01-29 00:00:...|Agilent Technolog...|           A|https://www.benzi...|       Charles Gross|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2019-01-03 00:00:...|Needham Initiates...|           A|https://www.benzi...|          Vick Meyer|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2018-11-21 00:00:...|50 Biggest Movers...|           A|https://www.benzi...|          Lisa Levin|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2018-11-20 00:00:...|36 Stocks Moving ...|           A|https://www.benzi...|          Lisa Levin|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2018-11-20 00:00:...|Shares of Agilent...|           A|https://www.benzi...|   Benzinga Newsdesk|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2018-11-20 00:00:...|Morgan Stanley Ma...|           A|https://www.benzi...|          Vick Meyer|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2018-11-20 00:00:...|26 Stocks Moving ...|           A|https://www.benzi...|          Lisa Levin|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2018-11-20 00:00:...|10 Stocks To Watc...|           A|https://www.benzi...|          Lisa Levin|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2018-11-19 00:00:...|6 Stocks Moving I...|           A|https://www.benzi...|      Brett Hershman|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2018-11-19 00:00:...|Agilent Sees Q1 A...|           A|https://www.benzi...|   Benzinga Newsdesk|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2018-11-19 00:00:...|Agilent Sees FY19...|           A|https://www.benzi...|   Benzinga Newsdesk|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2018-11-19 00:00:...|Agilent Technolog...|           A|https://www.benzi...|   Benzinga Newsdesk|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2018-11-19 00:00:...|8 Stocks To Watch...|           A|https://www.benzi...|          Lisa Levin|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2018-11-19 00:00:...|Earnings Schedule...|           A|https://www.benzi...|          Lisa Levin|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2018-11-14 00:00:...|13F From JANA Sho...|           A|https://www.benzi...|   Benzinga Newsdesk|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2018-10-29 00:00:...|Agilent Highlight...|           A|https://www.benzi...|   Benzinga Newsdesk|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2018-10-10 00:00:...|Morgan Stanley Ma...|           A|https://www.benzi...|          Vick Meyer|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2018-09-26 00:00:...|A Peek Into The M...|           A|https://www.benzi...|          Lisa Levin|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2018-09-26 00:00:...|Agilent Technolog...|           A|https://www.benzi...|   Benzinga_Newsdesk|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2018-09-26 00:00:...|Agilent to Acquir...|           A|https://www.benzi...|       Charles Gross|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2018-09-17 00:00:...|A Life Science To...|           A|https://www.benzi...|    Shanthi Rexaline|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2018-08-21 00:00:...|Agilent Companion...|           A|https://www.benzi...|   Benzinga_Newsdesk|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2018-08-15 00:00:...|Deutsche Bank Mai...|           A|https://www.benzi...|          Vick Meyer|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2018-08-15 00:00:...|30 Stocks Moving ...|           A|https://www.benzi...|          Lisa Levin|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2018-08-15 00:00:...|Morgan Stanley Ma...|           A|https://www.benzi...|          Vick Meyer|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2018-08-15 00:00:...|A Peek Into The M...|           A|https://www.benzi...|          Lisa Levin|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2018-08-15 00:00:...|10 Stocks To Watc...|           A|https://www.benzi...|          Lisa Levin|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2018-08-14 00:00:...|Agilent Technolog...|           A|https://www.benzi...|   Benzinga Newsdesk|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2018-08-14 00:00:...|13F Filing From T...|           A|https://www.benzi...|   Benzinga Newsdesk|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2018-08-14 00:00:...|Jana Partners 13F...|           A|https://www.benzi...|   Benzinga Newsdesk|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2018-08-14 00:00:...|Agilent Technolog...|           A|https://www.benzi...|   Benzinga Newsdesk|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2018-08-14 00:00:...|Earnings Schedule...|           A|https://www.benzi...|          Lisa Levin|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2018-08-14 00:00:...|10 Stocks To Watc...|           A|https://www.benzi...|          Lisa Levin|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2018-07-31 00:00:...|Agilent Announces...|           A|https://www.benzi...|   Benzinga Newsdesk|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2018-07-17 00:00:...|Waters Has Limite...|           A|https://www.benzi...|    Shanthi Rexaline|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2018-07-09 00:00:...|Agilent, Nanyang ...|           A|https://www.benzi...|    Benzinga Newdesk|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2018-06-12 00:00:...|Agilent Companion...|           A|https://www.benzi...|   Benzinga Newsdesk|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2018-05-30 00:00:...|Agilent to Acquir...|           A|https://www.benzi...|   Benzinga Newsdesk|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2018-05-24 00:00:...|Agilent, Universi...|           A|https://www.benzi...|   Benzinga Newsdesk|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2018-05-23 00:00:...|Agilent Signs Agr...|           A|https://www.benzi...|    Benzinga Newdesk|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2018-05-18 00:00:...|Pot Stocks, ETFs,...|           A|https://www.benzi...|        Javier Hasse|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2018-05-16 00:00:...|45 Biggest Movers...|           A|https://www.benzi...|          Lisa Levin|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2018-05-15 00:00:...|37 Stocks Moving ...|           A|https://www.benzi...|          Lisa Levin|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2018-05-15 00:00:...|Cowen & Co. Upgra...|           A|https://www.benzi...|   Benzinga Newsdesk|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2018-05-15 00:00:...|Traders Circulati...|           A|https://www.benzi...|   Benzinga Newsdesk|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "+--------------------+--------------------+------------+--------------------+--------------------+------+-------+-----------+------------+----------------+---------------+\n",
      "only showing top 200 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_csv_5gb.show(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 22:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------------+------------+--------------------+--------------+----------+--------------------+-----------+------------+----------------+---------------+\n",
      "|               Date|       Article_title|Stock_symbol|                 Url|     Publisher|    Author|             Article|Lsa_summary|Luhn_summary|Textrank_summary|Lexrank_summary|\n",
      "+-------------------+--------------------+------------+--------------------+--------------+----------+--------------------+-----------+------------+----------------+---------------+\n",
      "|1914-09-16 00:00:00|1914. Русские вой...|        NULL|https://lenta.ru/...|Первая мировая|Библиотека|Бои у Сопоцкина и...|       NULL|        NULL|            NULL|           NULL|\n",
      "|1914-09-16 00:00:00|1914. Праздновани...|        NULL|https://lenta.ru/...|Первая мировая|Библиотека|Министерство наро...|       NULL|        NULL|            NULL|           NULL|\n",
      "|1914-09-17 00:00:00|1914. Das ist Nes...|        NULL|https://lenta.ru/...|Первая мировая|Библиотека|Штабс-капитан П. ...|       NULL|        NULL|            NULL|           NULL|\n",
      "|1914-09-17 00:00:00|1914. Бульдог-гон...|        NULL|https://lenta.ru/...|Первая мировая|Библиотека|Фотограф-корреспо...|       NULL|        NULL|            NULL|           NULL|\n",
      "|1914-09-18 00:00:00|1914. Под Люблино...|        NULL|https://lenta.ru/...|Первая мировая|Библиотека|Лица, приехавшие ...|       NULL|        NULL|            NULL|           NULL|\n",
      "|1969-12-31 01:00:00|Montpelier Re Hol...|         MRH|http://www.zacks....|         Zacks|      NULL|                NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|1999-08-31 02:00:00|Космонавты сомнев...|        NULL|https://lenta.ru/...|           Все|    Россия|Как стало известн...|       NULL|        NULL|            NULL|           NULL|\n",
      "|1999-08-31 02:00:00|Взрыв в центре Мо...|        NULL|https://lenta.ru/...|           Все|    Россия|В зале игровых ав...|       NULL|        NULL|            NULL|           NULL|\n",
      "|1999-08-31 02:00:00|Япония кредитует ...|        NULL|https://lenta.ru/...|           Все|    Россия|Япония приняла ре...|       NULL|        NULL|            NULL|           NULL|\n",
      "|1999-08-31 02:00:00|Британцы отмечают...|        NULL|https://lenta.ru/...|           Все|       Мир|Британцы отмечают...|       NULL|        NULL|            NULL|           NULL|\n",
      "|1999-08-31 02:00:00|Отмытые через Ban...|        NULL|https://lenta.ru/...|           Все|    Россия|В понедельник дир...|       NULL|        NULL|            NULL|           NULL|\n",
      "|1999-08-31 02:00:00|C 1 сентября ввод...|        NULL|https://lenta.ru/...|           Все|    Россия|С 1 сентября на в...|       NULL|        NULL|            NULL|           NULL|\n",
      "|1999-08-31 02:00:00|Создан департамен...|        NULL|https://lenta.ru/...|           Все|    Россия|Указом президента...|       NULL|        NULL|            NULL|           NULL|\n",
      "|1999-08-31 02:00:00|Южно-Сахалинск об...|        NULL|https://lenta.ru/...|           Все|    Россия|Сегодня областной...|       NULL|        NULL|            NULL|           NULL|\n",
      "|1999-08-31 02:00:00|Леворадикалы созд...|        NULL|https://lenta.ru/...|           Все|    Россия|Бывший шеф Службы...|       NULL|        NULL|            NULL|           NULL|\n",
      "|1999-08-31 02:00:00|Еще одно землетря...|        NULL|https://lenta.ru/...|           Все|       Мир|подземный толчок ...|       NULL|        NULL|            NULL|           NULL|\n",
      "|1999-08-31 02:00:00|В горах Дагестана...|        NULL|https://lenta.ru/...|           Все|    Россия|Сегодня утром в р...|       NULL|        NULL|            NULL|           NULL|\n",
      "|1999-08-31 02:00:00|Карачаево-Черкеси...|        NULL|https://lenta.ru/...|           Все|    Россия|Намеченная на сег...|       NULL|        NULL|            NULL|           NULL|\n",
      "|1999-08-31 02:00:00|Коржаков готов ра...|        NULL|https://lenta.ru/...|           Все|    Россия|На состоявшейся с...|       NULL|        NULL|            NULL|           NULL|\n",
      "|1999-08-31 02:00:00|Российские национ...|        NULL|https://lenta.ru/...|           Все|       Мир|15 представителей...|       NULL|        NULL|            NULL|           NULL|\n",
      "|1999-08-31 02:00:00|Киргизия ведет бо...|        NULL|https://lenta.ru/...|           Все|       Мир|На юге Киргизии, ...|       NULL|        NULL|            NULL|           NULL|\n",
      "|1999-08-31 02:00:00|Литва засудила уч...|        NULL|https://lenta.ru/...|           Все|       Мир|Россия крайне нег...|       NULL|        NULL|            NULL|           NULL|\n",
      "|1999-08-31 02:00:00|Референдум по воп...|        NULL|https://lenta.ru/...|           Все|       Мир|По сведениям мисс...|       NULL|        NULL|            NULL|           NULL|\n",
      "|1999-09-01 02:00:00|США заплатили Кит...|        NULL|https://lenta.ru/...|           Все|       Мир|Соединенные Штаты...|       NULL|        NULL|            NULL|           NULL|\n",
      "|1999-09-01 02:00:00|Илюхин и Исаков о...|        NULL|https://lenta.ru/...|           Все|    Россия|\"Женщины России\" ...|       NULL|        NULL|            NULL|           NULL|\n",
      "|1999-09-01 02:00:00|Паколли: Дель Пон...|        NULL|https://lenta.ru/...|           Все|       Мир|Скандал по поводу...|       NULL|        NULL|            NULL|           NULL|\n",
      "|1999-09-01 02:00:00|ФБР готовится к к...|        NULL|https://lenta.ru/...|           Все|       Мир|Хотя до 2000 года...|       NULL|        NULL|            NULL|           NULL|\n",
      "|1999-09-01 02:00:00|В \"Bank of New Yo...|        NULL|https://lenta.ru/...|           Все|       Мир|Следствие по делу...|       NULL|        NULL|            NULL|           NULL|\n",
      "|1999-09-01 02:00:00|Федеральные силы ...|        NULL|https://lenta.ru/...|           Все|    Россия|Касаясь на сегодн...|       NULL|        NULL|            NULL|           NULL|\n",
      "|1999-09-01 02:00:00|В Киргизии освобо...|        NULL|https://lenta.ru/...|           Все|       Мир|Трое заложников о...|       NULL|        NULL|            NULL|           NULL|\n",
      "|1999-09-01 02:00:00|На ММВБ произошел...|        NULL|https://lenta.ru/...|           Все|    Россия|В среду 1 сентябр...|       NULL|        NULL|            NULL|           NULL|\n",
      "|1999-09-01 02:00:00|Американские миро...|        NULL|https://lenta.ru/...|           Все|       Мир|МИД РФ в распрост...|       NULL|        NULL|            NULL|           NULL|\n",
      "|1999-09-01 02:00:00|На ММВБ перестану...|        NULL|https://lenta.ru/...|           Все|    Россия|Московская межбан...|       NULL|        NULL|            NULL|           NULL|\n",
      "|1999-09-01 02:00:00|Швейцарец создал ...|        NULL|https://lenta.ru/...|           Все|       Мир|Бывший швейцарски...|       NULL|        NULL|            NULL|           NULL|\n",
      "|1999-09-01 02:00:00|В центре Буэнос-А...|        NULL|https://lenta.ru/...|           Все|       Мир|Сегодня, примерно...|       NULL|        NULL|            NULL|           NULL|\n",
      "|1999-09-01 02:00:00|США хотят сделать...|        NULL|https://lenta.ru/...|           Все|    Россия|США  выступают пр...|       NULL|        NULL|            NULL|           NULL|\n",
      "|1999-09-01 02:00:00|Минюст готовится ...|        NULL|https://lenta.ru/...|           Все|    Россия|Министр юстиции  ...|       NULL|        NULL|            NULL|           NULL|\n",
      "|1999-09-01 02:00:00|Убит абхазский та...|        NULL|https://lenta.ru/...|           Все|       Мир|Одинсотрудник абх...|       NULL|        NULL|            NULL|           NULL|\n",
      "|1999-09-01 02:00:00|Компания Apple вы...|        NULL|https://lenta.ru/...|           Все|       Мир|Компания Apple об...|       NULL|        NULL|            NULL|           NULL|\n",
      "|1999-09-01 02:00:00|Взрыв на Манежной...|        NULL|https://lenta.ru/...|           Все|    Россия|Всего в результат...|       NULL|        NULL|            NULL|           NULL|\n",
      "|1999-09-01 02:00:00|\"Окружение презид...|        NULL|https://lenta.ru/...|           Все|    Россия|Бывший генеральны...|       NULL|        NULL|            NULL|           NULL|\n",
      "|1999-09-01 02:00:00|Восточный Тимор п...|        NULL|https://lenta.ru/...|           Все|       Мир|Вооруженные отряд...|       NULL|        NULL|            NULL|           NULL|\n",
      "|1999-09-02 02:00:00|Колокола, похищен...|        NULL|https://lenta.ru/...|           Все|       Мир|Три похищенных из...|       NULL|        NULL|            NULL|           NULL|\n",
      "|1999-09-02 02:00:00|Курс доллара выро...|        NULL|https://lenta.ru/...|           Все|    Россия|Курс доллара на е...|       NULL|        NULL|            NULL|           NULL|\n",
      "|1999-09-02 02:00:00|Боевики вытеснены...|        NULL|https://lenta.ru/...|           Все|    Россия|Село Карамахи, од...|       NULL|        NULL|            NULL|           NULL|\n",
      "|1999-09-02 02:00:00|На Павелецком вок...|        NULL|https://lenta.ru/...|           Все|    Россия|Не успели утихнут...|       NULL|        NULL|            NULL|           NULL|\n",
      "|1999-09-02 02:00:00|В Чечне отключили...|        NULL|https://lenta.ru/...|           Все|    Россия|Со среды в Чечне ...|       NULL|        NULL|            NULL|           NULL|\n",
      "|1999-09-02 02:00:00|CША не будут блок...|        NULL|https://lenta.ru/...|           Все|    Россия|Агентство ИТАР-ТА...|       NULL|        NULL|            NULL|           NULL|\n",
      "|1999-09-02 02:00:00|Авиакатастрофа в ...|        NULL|https://lenta.ru/...|           Все|       Мир|Десять американск...|       NULL|        NULL|            NULL|           NULL|\n",
      "|1999-09-02 02:00:00|КНДР переносит св...|        NULL|https://lenta.ru/...|           Все|       Мир|В переданном ИТАР...|       NULL|        NULL|            NULL|           NULL|\n",
      "|1999-09-02 02:00:00|Минпечати запрети...|        NULL|https://lenta.ru/...|           Все|    Россия|С 0 часов 2 сентя...|       NULL|        NULL|            NULL|           NULL|\n",
      "|1999-09-02 02:00:00|Курдская рабочая ...|        NULL|https://lenta.ru/...|           Все|       Мир|Брат приговоренно...|       NULL|        NULL|            NULL|           NULL|\n",
      "|1999-09-02 02:00:00|В Баткенском райо...|        NULL|https://lenta.ru/...|           Все|       Мир|По сведениям ИТАР...|       NULL|        NULL|            NULL|           NULL|\n",
      "|1999-09-02 02:00:00|Ценные приборы с ...|        NULL|https://lenta.ru/...|           Все|    Россия|Демонтаж и достав...|       NULL|        NULL|            NULL|           NULL|\n",
      "|1999-09-02 02:00:00|Возле еврейской ш...|        NULL|https://lenta.ru/...|           Все|    Россия|Как передало аген...|       NULL|        NULL|            NULL|           NULL|\n",
      "|1999-09-02 02:00:00|ФБР виновно в гиб...|        NULL|https://lenta.ru/...|           Все|       Мир|Вчера в США с нов...|       NULL|        NULL|            NULL|           NULL|\n",
      "|1999-09-02 02:00:00|В Москве повышают...|        NULL|https://lenta.ru/...|           Все|    Россия|Сообщение агентст...|       NULL|        NULL|            NULL|           NULL|\n",
      "|1999-09-02 02:00:00|Ущерб от взрыва н...|        NULL|https://lenta.ru/...|           Все|    Россия|Директор ФСБ Нико...|       NULL|        NULL|            NULL|           NULL|\n",
      "|1999-09-02 02:00:00|Глобальное таяние...|        NULL|https://lenta.ru/...|           Все|       Мир|Глобальное потепл...|       NULL|        NULL|            NULL|           NULL|\n",
      "|1999-09-03 02:00:00|Экипажи двух росс...|        NULL|https://lenta.ru/...|           Все|       Мир|Экипажи двух росс...|       NULL|        NULL|            NULL|           NULL|\n",
      "+-------------------+--------------------+------------+--------------------+--------------+----------+--------------------+-----------+------------+----------------+---------------+\n",
      "only showing top 60 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_csv_5gb.sort(asc(\"Date\")).show(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Date: timestamp (nullable = true)\n",
      " |-- Article_title: string (nullable = true)\n",
      " |-- Stock_symbol: string (nullable = true)\n",
      " |-- Url: string (nullable = true)\n",
      " |-- Publisher: string (nullable = true)\n",
      " |-- Author: string (nullable = true)\n",
      " |-- Article: string (nullable = true)\n",
      " |-- Lsa_summary: string (nullable = true)\n",
      " |-- Luhn_summary: string (nullable = true)\n",
      " |-- Textrank_summary: string (nullable = true)\n",
      " |-- Lexrank_summary: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_csv_5gb.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 27:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+\n",
      "|           min_date|           max_date|\n",
      "+-------------------+-------------------+\n",
      "|1914-09-16 00:00:00|2020-06-11 15:12:35|\n",
      "+-------------------+-------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_csv_5gb.select(min(\"Date\").alias(\"min_date\"), max(\"Date\").alias(\"max_date\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 30:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------+\n",
      "|Stock_symbol|ticker_count|\n",
      "+------------+------------+\n",
      "|        NULL|     9804627|\n",
      "|           A|        2369|\n",
      "|          AA|        2953|\n",
      "|         AAC|         379|\n",
      "|        AADR|          32|\n",
      "|         AAL|         494|\n",
      "|        AAMC|         132|\n",
      "|        AAME|          87|\n",
      "|         AAN|        1309|\n",
      "|        AAOI|         452|\n",
      "|        AAON|         326|\n",
      "|         AAP|        2214|\n",
      "|        AAPL|         473|\n",
      "|         AAU|          85|\n",
      "|         AAV|         127|\n",
      "|        AAVL|         191|\n",
      "|        AAWW|         322|\n",
      "|        AAXJ|          76|\n",
      "|          AB|        1065|\n",
      "|        ABAC|          72|\n",
      "|        ABAX|         100|\n",
      "|         ABB|        1433|\n",
      "|        ABBV|         753|\n",
      "|         ABC|         722|\n",
      "|        ABCB|          20|\n",
      "|        ABCD|         130|\n",
      "|        ABCO|         408|\n",
      "|        ABCW|          37|\n",
      "|        ABDC|         116|\n",
      "|        ABEV|         309|\n",
      "|         ABG|         323|\n",
      "|        ABGB|         204|\n",
      "|        ABIO|         100|\n",
      "|         ABM|         139|\n",
      "|        ABMD|         239|\n",
      "|         ABR|         771|\n",
      "|        ABTL|         386|\n",
      "|         ABX|        2867|\n",
      "|         ABY|         238|\n",
      "|        ACAD|         985|\n",
      "|        ACAS|         569|\n",
      "|        ACAT|         471|\n",
      "|         ACC|         667|\n",
      "|        ACCO|         576|\n",
      "|        ACCU|          15|\n",
      "|         ACE|         925|\n",
      "|        ACET|         372|\n",
      "|        ACFC|          81|\n",
      "|        ACFN|         132|\n",
      "|         ACG|          55|\n",
      "+------------+------------+\n",
      "only showing top 50 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_csv_5gb.groupBy(\"Stock_symbol\").agg(count(\"*\").alias(\"ticker_count\")) \\\n",
    "       .orderBy(\"Stock_symbol\", ascending=True) \\\n",
    "       .show(50)  # Show top 50 tickers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 33:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-----+\n",
      "|              month|count|\n",
      "+-------------------+-----+\n",
      "|1914-09-01 00:00:00|    5|\n",
      "|1969-12-01 00:00:00|    1|\n",
      "|1999-08-01 00:00:00|   17|\n",
      "|1999-09-01 00:00:00|  580|\n",
      "|1999-10-01 00:00:00|  726|\n",
      "|1999-11-01 00:00:00|  853|\n",
      "|1999-12-01 00:00:00|  905|\n",
      "|2000-01-01 00:00:00|  682|\n",
      "|2000-02-01 00:00:00| 1004|\n",
      "|2000-03-01 00:00:00| 1226|\n",
      "|2000-04-01 00:00:00| 1202|\n",
      "|2000-05-01 00:00:00| 1166|\n",
      "|2000-06-01 00:00:00| 1283|\n",
      "|2000-07-01 00:00:00| 1277|\n",
      "|2000-08-01 00:00:00| 1336|\n",
      "|2000-09-01 00:00:00| 1590|\n",
      "|2000-10-01 00:00:00| 1781|\n",
      "|2000-11-01 00:00:00| 1835|\n",
      "|2000-12-01 00:00:00| 1794|\n",
      "|2001-01-01 00:00:00| 1676|\n",
      "+-------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_csv_5gb.groupby(date_trunc(\"month\", \"date\").alias(\"month\")) \\\n",
    "       .count() \\\n",
    "       .orderBy(\"month\") \\\n",
    "       .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------------+------------+--------------------+--------------------+------+-------+-----------+------------+----------------+---------------+-------------------+\n",
      "|               Date|       Article_title|Stock_symbol|                 Url|           Publisher|Author|Article|Lsa_summary|Luhn_summary|Textrank_summary|Lexrank_summary|        Date_parsed|\n",
      "+-------------------+--------------------+------------+--------------------+--------------------+------+-------+-----------+------------+----------------+---------------+-------------------+\n",
      "|2020-06-05 08:30:54|Stocks That Hit 5...|           A|https://www.benzi...|   Benzinga Insights|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|2020-06-05 08:30:54|\n",
      "|2020-06-03 08:45:20|Stocks That Hit 5...|           A|https://www.benzi...|   Benzinga Insights|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|2020-06-03 08:45:20|\n",
      "|2020-05-26 02:30:07|71 Biggest Movers...|           A|https://www.benzi...|          Lisa Levin|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|2020-05-26 02:30:07|\n",
      "|2020-05-22 10:45:06|46 Stocks Moving ...|           A|https://www.benzi...|          Lisa Levin|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|2020-05-22 10:45:06|\n",
      "|2020-05-22 09:38:59|B of A Securities...|           A|https://www.benzi...|          Vick Meyer|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|2020-05-22 09:38:59|\n",
      "|2020-05-22 09:23:25|CFRA Maintains Ho...|           A|https://www.benzi...|vishwanath@benzin...|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|2020-05-22 09:23:25|\n",
      "|2020-05-22 07:36:20|UBS Maintains Neu...|           A|https://www.benzi...|vishwanath@benzin...|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|2020-05-22 07:36:20|\n",
      "|2020-05-22 07:07:04|Agilent Technolog...|           A|https://www.benzi...|   Benzinga Newsdesk|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|2020-05-22 07:07:04|\n",
      "|2020-05-22 06:37:59|Wells Fargo Maint...|           A|https://www.benzi...|vishwanath@benzin...|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|2020-05-22 06:37:59|\n",
      "|2020-05-22 06:06:17|10 Biggest Price ...|           A|https://www.benzi...|          Lisa Levin|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|2020-05-22 06:06:17|\n",
      "+-------------------+--------------------+------------+--------------------+--------------------+------+-------+-----------+------------+----------------+---------------+-------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 36:>   (0 + 1) / 1][Stage 37:>   (0 + 1) / 1][Stage 38:>   (0 + 1) / 1]\r"
     ]
    }
   ],
   "source": [
    "df_csv_5gb.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cheaper heuristic to validate the language of the news "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "def is_likely_english(text, threshold=0.75):\n",
    "    if text is None:\n",
    "        # Here we \"pass\" the row through\n",
    "        return True\n",
    "    if not text:\n",
    "        return False\n",
    "    # Keep only letters for ratio calc, or all chars.\n",
    "    total_chars = len(text)\n",
    "    if total_chars == 0:\n",
    "        return False\n",
    "    \n",
    "    # Count how many are \"basic ASCII\" or in the [A-Za-z] range\n",
    "    ascii_letters = sum(ch in string.printable for ch in text)\n",
    "    \n",
    "    ratio = ascii_letters / total_chars\n",
    "    return ratio >= threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_english_udf = udf(lambda text: is_likely_english(text, 0.9), BooleanType())\n",
    "\n",
    "df_filtered = (\n",
    "  df_csv_5gb\n",
    "    .withColumn(\"likely_en_title\", is_english_udf(col(\"Article_title\")))\n",
    "    .withColumn(\"likely_en_article\", is_english_udf(col(\"Article\")))\n",
    "    # Keep the row if either condition is True\n",
    "    .filter(\"likely_en_title = true AND likely_en_article = true\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_filtered.write.mode(\"overwrite\").parquet(\"../data/raw/english_only.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_english_only = spark.read.parquet(\"../data/raw/english_only.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 7:======================================>                   (8 + 4) / 12]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------------+------------+--------------------+---------+--------------------+--------------------+-----------+------------+----------------+---------------+---------------+-----------------+\n",
      "|               Date|       Article_title|Stock_symbol|                 Url|Publisher|              Author|             Article|Lsa_summary|Luhn_summary|Textrank_summary|Lexrank_summary|likely_en_title|likely_en_article|\n",
      "+-------------------+--------------------+------------+--------------------+---------+--------------------+--------------------+-----------+------------+----------------+---------------+---------------+-----------------+\n",
      "|1969-12-31 01:00:00|Montpelier Re Hol...|         MRH|http://www.zacks....|    Zacks|                NULL|                NULL|       NULL|        NULL|            NULL|           NULL|           true|             true|\n",
      "|2006-10-20 02:00:00|Inco's Net Soars ...|        NULL|http://www.bloomb...|     NULL|         Dale Crofts|Inco Ltd., the Ca...|       NULL|        NULL|            NULL|           NULL|           true|             true|\n",
      "|2006-10-21 02:00:00|Jim Cramer: Diage...|        NULL|http://www.bloomb...|     NULL|       Steven Bodzin|Jim Cramer  recom...|       NULL|        NULL|            NULL|           NULL|           true|             true|\n",
      "|2006-10-23 02:00:00|Ex-Plant Worker S...|        NULL|http://www.bloomb...|     NULL|        David Glovin|A former worker a...|       NULL|        NULL|            NULL|           NULL|           true|             true|\n",
      "|2006-10-23 02:00:00|EU Energy Chief B...|        NULL|http://www.bloomb...|     NULL|        Thomas Bauer|European Union En...|       NULL|        NULL|            NULL|           NULL|           true|             true|\n",
      "|2006-10-24 02:00:00|Huaneng Power's T...|        NULL|http://www.bloomb...|     NULL|      Wing-Gar Cheng|Huaneng Power Int...|       NULL|        NULL|            NULL|           NULL|           true|             true|\n",
      "|2006-10-24 02:00:00|Vale Buys Control...|        NULL|http://www.bloomb...|     NULL|     Heloiza Canassa|Cia.  Vale  do Ri...|       NULL|        NULL|            NULL|           NULL|           true|             true|\n",
      "|2006-10-24 02:00:00|Russia, Ukraine E...|        NULL|http://www.bloomb...|     NULL| Daryna Krasnolutska|Russia 's state-r...|       NULL|        NULL|            NULL|           NULL|           true|             true|\n",
      "|2006-10-24 02:00:00|Jim Cramer: Bare ...|        NULL|http://www.bloomb...|     NULL|       Steven Bodzin|Bare Escentuals I...|       NULL|        NULL|            NULL|           NULL|           true|             true|\n",
      "|2006-10-25 02:00:00|Wheeling-Pitt, De...|        NULL|http://www.bloomb...|     NULL|         Dale Crofts|Wheeling-Pittsbur...|       NULL|        NULL|            NULL|           NULL|           true|             true|\n",
      "|2006-10-25 02:00:00|Ambac 3rd-Quarter...|        NULL|http://www.bloomb...|     NULL|   Christine Richard|Ambac Financial G...|       NULL|        NULL|            NULL|           NULL|           true|             true|\n",
      "|2006-10-27 02:00:00|Singapore Airline...|        NULL|http://www.bloomb...|     NULL|       Chan Sue Ling|Singapore Airline...|       NULL|        NULL|            NULL|           NULL|           true|             true|\n",
      "|2006-10-27 02:00:00|Balda Says Invest...|        NULL|http://www.bloomb...|     NULL|      Stefanie Haxel|Balda AG (BAF) , ...|       NULL|        NULL|            NULL|           NULL|           true|             true|\n",
      "|2006-10-27 02:00:00|MPC Third-Quarter...|        NULL|http://www.bloomb...|     NULL|     Aaron Kirchfeld|MPC Capital AG, a...|       NULL|        NULL|            NULL|           NULL|           true|             true|\n",
      "|2006-10-27 02:00:00|Baoshan's 3rd-Qua...|        NULL|http://www.bloomb...|     NULL|           Janet Ong|Baoshan Iron & St...|       NULL|        NULL|            NULL|           NULL|           true|             true|\n",
      "|2006-10-30 01:00:00|U.S. Newspapers L...|        NULL|http://www.bloomb...|     NULL|       Cecile Daurat|U.S. daily newspa...|       NULL|        NULL|            NULL|           NULL|           true|             true|\n",
      "|2006-10-30 01:00:00|Amerigroup Defrau...|        NULL|http://www.bloomb...|     NULL|       Andrew Harris|Amerigroup Corp. ...|       NULL|        NULL|            NULL|           NULL|           true|             true|\n",
      "|2006-10-30 01:00:00|Porter to Begin F...|        NULL|http://www.bloomb...|     NULL|      Doug Alexander|Porter Airlines I...|       NULL|        NULL|            NULL|           NULL|           true|             true|\n",
      "|2006-11-01 01:00:00|ACE Must Lift Pay...|        NULL|http://www.bloomb...|     NULL|      Doug Alexander|ACE Aviation Hold...|       NULL|        NULL|            NULL|           NULL|           true|             true|\n",
      "|2006-11-01 01:00:00|Comstar to Spend ...|        NULL|http://www.bloomb...|     NULL|      Lyubov Pronina|OAO Comstar Unite...|       NULL|        NULL|            NULL|           NULL|           true|             true|\n",
      "|2006-11-01 01:00:00|Russian Stocks Ga...|        NULL|http://www.bloomb...|     NULL|      Maria Ermakova|Russian stocks ro...|       NULL|        NULL|            NULL|           NULL|           true|             true|\n",
      "|2006-11-02 01:00:00|Coles Myer Raises...|        NULL|http://www.bloomb...|     NULL|       Robert Fenner|Coles Myer Ltd., ...|       NULL|        NULL|            NULL|           NULL|           true|             true|\n",
      "|2006-11-02 01:00:00|Korea Electric Ne...|        NULL|http://www.bloomb...|     NULL|       Meeyoung Song|Korea Electric Po...|       NULL|        NULL|            NULL|           NULL|           true|             true|\n",
      "|2006-11-03 01:00:00|Schneider Shares ...|        NULL|http://www.bloomb...|     NULL|     Nicolas Johnson|Shares of  Schnei...|       NULL|        NULL|            NULL|           NULL|           true|             true|\n",
      "|2006-11-03 01:00:00|N. Korea Cargo-Sc...|        NULL|http://www.bloomb...|     NULL|          Jeff Bliss|The radiation det...|       NULL|        NULL|            NULL|           NULL|           true|             true|\n",
      "|2006-11-03 01:00:00|Nielsen Postpones...|        NULL|http://www.bloomb...|     NULL|       Michael White|Nielsen Media Res...|       NULL|        NULL|            NULL|           NULL|           true|             true|\n",
      "|2006-11-07 01:00:00|Ceridian Wins Ten...|        NULL|http://www.bloomb...|     NULL|        Susan Decker|A Ceridian Corp. ...|       NULL|        NULL|            NULL|           NULL|           true|             true|\n",
      "|2006-11-07 01:00:00|Shimao Hires Gold...|        NULL|http://www.bloomb...|     NULL|        Patricia Kuo|Shimao Property H...|       NULL|        NULL|            NULL|           NULL|           true|             true|\n",
      "|2006-11-07 01:00:00|Stillwater Posts ...|        NULL|http://www.bloomb...|     NULL|     Choy Leng Yeong|Stillwater Mining...|       NULL|        NULL|            NULL|           NULL|           true|             true|\n",
      "|2006-11-07 01:00:00|Russia May Cancel...|        NULL|http://www.bloomb...|     NULL|         Todd Prince|Russian Prosecuto...|       NULL|        NULL|            NULL|           NULL|           true|             true|\n",
      "|2006-11-08 01:00:00|Qatar Petroleum O...|        NULL|http://www.bloomb...|     NULL|        Trisha Huang|Qatar Petroleum ,...|       NULL|        NULL|            NULL|           NULL|           true|             true|\n",
      "|2006-11-08 01:00:00|Russian Stocks Dr...|        NULL|http://www.bloomb...|     NULL|       Michael Heath|Russian stocks fe...|       NULL|        NULL|            NULL|           NULL|           true|             true|\n",
      "|2006-11-08 01:00:00|Dynegy Reports Th...|        NULL|http://www.bloomb...|     NULL|        Edward Klump|Dynegy Inc., owne...|       NULL|        NULL|            NULL|           NULL|           true|             true|\n",
      "|2006-11-08 01:00:00|Namibian Investor...|        NULL|http://www.bloomb...|     NULL|      Vernon Wessels|Namibian investor...|       NULL|        NULL|            NULL|           NULL|           true|             true|\n",
      "|2006-11-09 01:00:00|FirstRand Says La...|        NULL|http://www.bloomb...|     NULL|      Vernon Wessels|First National Ba...|       NULL|        NULL|            NULL|           NULL|           true|             true|\n",
      "|2006-11-09 01:00:00|China Stocks Will...|        NULL|http://www.bloomb...|     NULL|       Zhang Shidong|China's stock mar...|       NULL|        NULL|            NULL|           NULL|           true|             true|\n",
      "|2006-11-09 01:00:00|Vale Third-Quarte...|        NULL|http://www.bloomb...|     NULL|          Jeb Blount|Cia. Vale do Rio ...|       NULL|        NULL|            NULL|           NULL|           true|             true|\n",
      "|2006-11-10 01:00:00|Evraz's Raspadska...|        NULL|http://www.bloomb...|     NULL|    Samantha Shields|OAO Raspadskaya, ...|       NULL|        NULL|            NULL|           NULL|           true|             true|\n",
      "|2006-11-10 01:00:00|Mills Sets Shareh...|        NULL|http://www.bloomb...|     NULL|   Sharon L. Crenson|Mills Corp., a U....|       NULL|        NULL|            NULL|           NULL|           true|             true|\n",
      "|2006-11-10 01:00:00|Wheeling-Pittsbur...|        NULL|http://www.bloomb...|     NULL|Christopher Donville|A union represent...|       NULL|        NULL|            NULL|           NULL|           true|             true|\n",
      "|2006-11-13 01:00:00|Sacyr Shares Post...|        NULL|http://www.bloomb...|     NULL|           Joao Lima|Shares of  Sacyr ...|       NULL|        NULL|            NULL|           NULL|           true|             true|\n",
      "|2006-11-13 01:00:00|Baltika Nine-Mont...|        NULL|http://www.bloomb...|     NULL|      Maria Ermakova|OAO Baltika Brewe...|       NULL|        NULL|            NULL|           NULL|           true|             true|\n",
      "|2006-11-13 01:00:00|EU Outlines Expan...|        NULL|http://www.bloomb...|     NULL|    Jonathan Stearns|The European Unio...|       NULL|        NULL|            NULL|           NULL|           true|             true|\n",
      "|2006-11-13 01:00:00|Malone's Starz Un...|        NULL|http://www.bloomb...|     NULL|       Cecile Daurat|Billionaire John ...|       NULL|        NULL|            NULL|           NULL|           true|             true|\n",
      "|2006-11-14 01:00:00|CSN Boosts Wheeli...|        NULL|http://www.bloomb...|     NULL|     Choy Leng Yeong|Cia. Siderurgica ...|       NULL|        NULL|            NULL|           NULL|           true|             true|\n",
      "|2006-11-14 01:00:00|Temasek Acted in ...|        NULL|http://www.bloomb...|     NULL|       Chan Sue Ling|Singapore  said t...|       NULL|        NULL|            NULL|           NULL|           true|             true|\n",
      "|2006-11-15 01:00:00|N.Z. Oil & Gas Ge...|        NULL|http://www.bloomb...|     NULL|         Gavin Evans|New Zealand Oil &...|       NULL|        NULL|            NULL|           NULL|           true|             true|\n",
      "|2006-11-16 01:00:00|Nationwide Profit...|        NULL|http://www.bloomb...|     NULL|         Ben Livesey|Nationwide Buildi...|       NULL|        NULL|            NULL|           NULL|           true|             true|\n",
      "|2006-11-16 01:00:00|Wheeling-Pittsbur...|        NULL|http://www.bloomb...|     NULL|         Dale Crofts|Wheeling-Pittsbur...|       NULL|        NULL|            NULL|           NULL|           true|             true|\n",
      "|2006-11-17 01:00:00|Bank of Communica...|        NULL|http://www.bloomb...|     NULL|             Luo Jun|Bank of Communica...|       NULL|        NULL|            NULL|           NULL|           true|             true|\n",
      "|2006-11-20 01:00:00|Ameristar Casino ...|        NULL|http://www.bloomb...|     NULL|[bn:PRSN=15017728...|Shares of  Ameris...|       NULL|        NULL|            NULL|           NULL|           true|             true|\n",
      "|2006-11-20 01:00:00|Peru August Gold ...|        NULL|http://www.bloomb...|     NULL|[bn:PRSN=6685378]...|Peru 's  gold pro...|       NULL|        NULL|            NULL|           NULL|           true|             true|\n",
      "|2006-11-20 01:00:00|Real Madrid Agree...|        NULL|http://www.bloomb...|     NULL|           Alex Duff|Real Madrid, socc...|       NULL|        NULL|            NULL|           NULL|           true|             true|\n",
      "|2006-11-21 01:00:00|Russian Stocks Ri...|        NULL|http://www.bloomb...|     NULL|[bn:PRSN=3629307]...|Russian stocks ad...|       NULL|        NULL|            NULL|           NULL|           true|             true|\n",
      "|2006-11-21 01:00:00|BP's Russian Unit...|        NULL|http://www.bloomb...|     NULL|[bn:PRSN=6963266]...|TNK-BP (TNBP) , B...|       NULL|        NULL|            NULL|           NULL|           true|             true|\n",
      "|2006-11-21 01:00:00|News Corp. Sells ...|        NULL|http://www.bloomb...|     NULL|[bn:PRSN=3224909]...|News Corp. (NWSA)...|       NULL|        NULL|            NULL|           NULL|           true|             true|\n",
      "|2006-11-22 01:00:00|Exxon, Chevron Am...|        NULL|http://www.bloomb...|     NULL|        Yuriy Humber|Russia will limit...|       NULL|        NULL|            NULL|           NULL|           true|             true|\n",
      "|2006-11-22 01:00:00|Norilsk Wants Taj...|        NULL|http://www.bloomb...|     NULL|    Samantha Shields|OAO GMK Norilsk N...|       NULL|        NULL|            NULL|           NULL|           true|             true|\n",
      "|2006-11-23 01:00:00|Bank of China Con...|        NULL|http://www.bloomb...|     NULL|            Susan Li|Bank of China Ltd...|       NULL|        NULL|            NULL|           NULL|           true|             true|\n",
      "|2006-11-23 01:00:00|Remy to Exit Dist...|        NULL|http://www.bloomb...|     NULL|      Ladka Bauerova|Remy Cointreau SA...|       NULL|        NULL|            NULL|           NULL|           true|             true|\n",
      "+-------------------+--------------------+------------+--------------------+---------+--------------------+--------------------+-----------+------------+----------------+---------------+---------------+-----------------+\n",
      "only showing top 60 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_english_only.sort(asc(\"Date\")).show(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+\n",
      "|           min_date|           max_date|\n",
      "+-------------------+-------------------+\n",
      "|1969-12-31 01:00:00|2020-06-11 15:12:35|\n",
      "+-------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_english_only.select(min(\"Date\").alias(\"min_date\"), max(\"Date\").alias(\"max_date\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = df_english_only.drop(\"Date_parsed\").drop(\"likely_en_title\").drop(\"likely_en_article\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------------+------------+--------------------+--------------------+------+-------+-----------+------------+----------------+---------------+\n",
      "|               Date|       Article_title|Stock_symbol|                 Url|           Publisher|Author|Article|Lsa_summary|Luhn_summary|Textrank_summary|Lexrank_summary|\n",
      "+-------------------+--------------------+------------+--------------------+--------------------+------+-------+-----------+------------+----------------+---------------+\n",
      "|2020-06-05 08:30:54|Stocks That Hit 5...|           A|https://www.benzi...|   Benzinga Insights|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2020-06-03 08:45:20|Stocks That Hit 5...|           A|https://www.benzi...|   Benzinga Insights|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2020-05-26 02:30:07|71 Biggest Movers...|           A|https://www.benzi...|          Lisa Levin|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2020-05-22 10:45:06|46 Stocks Moving ...|           A|https://www.benzi...|          Lisa Levin|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2020-05-22 09:38:59|B of A Securities...|           A|https://www.benzi...|          Vick Meyer|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2020-05-22 09:23:25|CFRA Maintains Ho...|           A|https://www.benzi...|vishwanath@benzin...|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2020-05-22 07:36:20|UBS Maintains Neu...|           A|https://www.benzi...|vishwanath@benzin...|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2020-05-22 07:07:04|Agilent Technolog...|           A|https://www.benzi...|   Benzinga Newsdesk|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2020-05-22 06:37:59|Wells Fargo Maint...|           A|https://www.benzi...|vishwanath@benzin...|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "|2020-05-22 06:06:17|10 Biggest Price ...|           A|https://www.benzi...|          Lisa Levin|  NULL|   NULL|       NULL|        NULL|            NULL|           NULL|\n",
      "+-------------------+--------------------+------------+--------------------+--------------------+------+-------+-----------+------------+----------------+---------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_final.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_time = df_final.withColumn(\"date_day\", to_date(\"Date\", \"yyyy-MM-dd\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_time_count = df_time.groupBy(\"date_day\").agg(count(\"*\").alias(\"articles_count\")) \\\n",
    "                      .orderBy(\"date_day\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "pdf_time = df_time_count.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distribution of articles over time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(pdf_time[\"date_day\"], pdf_time[\"articles_count\"])\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Number of articles\")\n",
    "plt.title(\"Daily Article Volume Over Time\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distribution of tickers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ticker_count = df_final.groupBy(\"Stock_symbol\").agg(count(\"*\").alias(\"ticker_count\")) \\\n",
    "                   .orderBy(\"ticker_count\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ticker_count_notnull = df_ticker_count.filter(\"Stock_symbol IS NOT NULL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_ticker_notnull = df_ticker_count_notnull.limit(20).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkQAAAHNCAYAAAD/t2TXAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAYJlJREFUeJzt3XdUFNffBvBnl7IgzYYUQUBREXuJSqICNiSoMWIsMYqKGg3Gltjyiz2JvUdjEgU0IRoxxsSKqIANa8SClVijgjEWEBUE7vuHh3ld+i67FOf5nLPnuHNn7353BfbZmXvvKIQQAkREREQypiztAoiIiIhKGwMRERERyR4DEREREckeAxERERHJHgMRERERyR4DEREREckeAxERERHJHgMRERERyR4DEREREckeAxERFUihUGDGjBkaPSY0NBQKhQInT57UT1HFdOPGDSgUCixcuLC0Sym2QYMGwdnZWePHOTs7Y9CgQTqvh6i8YiAiwqsP/aLcoqOj9VrH7du3MXPmTLRs2RKVKlVC1apV4eXlhb179+a5/+PHjzF8+HBYW1vDzMwM3t7e+Ouvvwp8juywUthNmw9Zyt+qVaugUCjQqlUrjR979+5dzJgxA3FxcbovTMd+//13+Pr6omrVqjA2Noa9vT169+6N/fv3l3ZpAMrXe0kly7C0CyAqC3766Se1++vXr0dkZGSu7fXq1dNrHX/88QfmzZuHHj16ICAgABkZGVi/fj06deqE4OBgDB48WNo3KysLfn5+OHPmDCZMmICqVati1apV8PLywqlTp1C7du08n6Ndu3a5XtfQoUPRsmVLDB8+XNpmbm4OAHj+/DkMDfmnorjCwsLg7OyM48ePIyEhAa6urkV+7N27dzFz5kw4OzujSZMmam0//vgjsrKydFyt5oQQGDJkCEJDQ9G0aVOMHz8etra2uHfvHn7//Xd06NABhw8fxttvv12qdRb0XpLMCSLKJSgoSJTGr8f58+fFv//+q7btxYsXws3NTTg4OKht//XXXwUAER4eLm27f/++qFixoujXr59Gz2tmZiYCAgK0rjunkJAQAUCcOHFCZ32+LjMzUzx//lzrx1+/fl0AEAsWLNBhVfm7du2aACC2bNkirK2txYwZM4r0uJcvX4q0tDRx4sQJAUCEhITorCYnJyed/p8vWLBAABBjx44VWVlZudrXr18vjh07prPn05Y+3kt6M/CUGVERpaam4rPPPoOjoyNUKhXq1q2LhQsXQgihtp9CocCoUaMQFhaGunXrwsTEBM2bN8eBAwcKfY769eujatWqattUKhXeffdd/PPPP0hJSZG2b968GTY2NujZs6e0zdraGr1798Yff/yBtLS0Yr7i/389OccQ3blzB4GBgbC3t4dKpYKLiwtGjhyJ9PT0fPt59OgRWrZsCQcHB1y+fBkAkJaWhunTp8PV1RUqlQqOjo6YOHFirtpff0/r168PlUqF3bt3AwA2btyI5s2bw8LCApaWlmjYsCGWLVtW5Ne3ZMkSODk5wdTUFJ6enjh//rzUFhISAoVCgdOnT+d63DfffAMDAwPcuXOn0OcICwtDpUqV4Ofnh169eiEsLCzXPq+Pa1q6dClq1aoFlUqFVatW4a233gIADB48WDqlGRoaCiDvMURZWVlYtmwZGjZsCBMTE1hbW6NLly6Fjul6/Pgxxo4dK/2Mu7q6Yt68eYUegXr+/DnmzJkDNzc3LFy4EAqFItc+AwYMQMuWLaX7165dwwcffIDKlSujQoUKaN26NXbs2KH2mOzTuzdu3FDbHh0dnesUtpeXFxo0aIALFy7A29sbFSpUQPXq1TF//ny1xxX0XpK88Tg4UREIIdC9e3dERUUhMDAQTZo0QUREBCZMmIA7d+5gyZIlavvHxMTg119/xejRo6UPtS5duuD48eNo0KCBxs+fmJiIChUqoEKFCtK206dPo1mzZlAq1b/XtGzZEj/88AOuXLmChg0baveCC3D37l20bNlSGr/k5uaGO3fuYPPmzXj27BmMjY1zPebBgwfo1KkTHj58iJiYGNSqVQtZWVno3r07Dh06hOHDh6NevXo4d+4clixZgitXrmDr1q1qfezfvx+bNm3CqFGjULVqVTg7OyMyMhL9+vVDhw4dMG/ePADAxYsXcfjwYYwZM6bQ17J+/XqkpKQgKCgIL168wLJly9C+fXucO3cONjY26NWrF4KCghAWFoamTZuqPTYsLAxeXl6oXr16oc8TFhaGnj17wtjYGP369cN3332HEydOSB/OrwsJCcGLFy8wfPhwqFQqvP/++0hJScG0adMwfPhwtG3bFgAKPPUUGBiI0NBQ+Pr6YujQocjIyMDBgwdx9OhRtGjRIs/HPHv2DJ6enrhz5w4+/vhj1KhRA0eOHMGUKVNw7949LF26NN/nO3ToEB4+fIixY8fCwMCg0PcjKSkJb7/9Np49e4bRo0ejSpUqWLduHbp3747Nmzfj/fffL7SPvDx69AhdunRBz5490bt3b2zevBmTJk1Cw4YN4evri3r16mHWrFkavZckI6V9iIqoLMp5ymzr1q0CgPjqq6/U9uvVq5dQKBQiISFB2gZAABAnT56Utt28eVOYmJiI999/X+Narl69KkxMTMSAAQPUtpuZmYkhQ4bk2n/Hjh0CgNi9e3eRn6OgU2YAxPTp06X7AwcOFEqlMs/TYdmnSl4/ZXbv3j1Rv359UbNmTXHjxg1p359++kkolUpx8OBBtT5Wr14tAIjDhw+r1aBUKkV8fLzavmPGjBGWlpYiIyOjyK9ViP8/ZWZqair++ecfafuxY8cEADFu3DhpW79+/YS9vb3IzMyUtv31119FPu1y8uRJAUBERkYKIV69Rw4ODmLMmDF51mRpaSnu37+v1lbQaZ6AgADh5OQk3d+/f78AIEaPHp1r39dPZeU8ZTZ79mxhZmYmrly5ovaYyZMnCwMDA3Hr1q18X+OyZcsEAPH777/nu8/rxo4dKwCo/d+npKQIFxcX4ezsLL3X2T9H169fV3t8VFSUACCioqKkbZ6engKAWL9+vbQtLS1N2NraCn9/f2kbT5lRfnjKjKgIdu7cCQMDA4wePVpt+2effQYhBHbt2qW23cPDA82bN5fu16hRA++99x4iIiKQmZlZ5Od99uwZPvjgA5iammLu3Llqbc+fP4dKpcr1GBMTE6ld17KysrB161Z069YtzyMNOU+V/PPPP/D09MTLly9x4MABODk5SW3h4eGoV68e3Nzc8ODBA+nWvn17AEBUVJRaX56ennB3d1fbVrFiRaSmpiIyMlKr19OjRw+1IzwtW7ZEq1atsHPnTmnbwIEDcffuXbV6wsLCYGpqCn9//0KfIywsDDY2NvD29gbw6j3q06cPNm7cmOfPgr+/P6ytrbV6PQDw22+/QaFQYPr06bna8jqVlS08PBxt27ZFpUqV1P4/OnbsiMzMzAJP+SYnJwMALCwsilTjzp070bJlS7Rp00baZm5ujuHDh+PGjRu4cOFCkfrJydzcHB999JF039jYGC1btsS1a9e06o/khYGIqAhu3rwJe3v7XH/ws2ed3bx5U217XjO86tSpg2fPnuHff/8t0nNmZmaib9++uHDhAjZv3gx7e3u1dlNT0zzHCb148UJq17V///0XycnJRT7tN2DAANy/fx8xMTG5Ti1dvXoV8fHxsLa2VrvVqVMHAHD//n21/V1cXHL1/8knn6BOnTrw9fWFg4MDhgwZIo0tKor8/p9eH7PSqVMn2NnZSeN+srKysGHDBrz33nuFBoDMzExs3LgR3t7euH79OhISEpCQkIBWrVohKSkJ+/bty/WYvF6nJv7++2/Y29ujcuXKGj3u6tWr2L17d67/j44dOwLI/f/xOktLSwBQG+NWkJs3b6Ju3bq5tuf3+1RUDg4OuUJfpUqV8OjRI636I3nhGCKiMmrYsGHYvn07wsLCpKMmr7Ozs8O9e/dybc/eljNAlYaePXti/fr1WLZsGebMmaPWlpWVhYYNG2Lx4sV5PtbR0VHtfl4Br1q1aoiLi0NERAR27dqFXbt2ISQkBAMHDsS6det08hoMDAzw4Ycf4scff8SqVatw+PBh3L17V+1IRH7279+Pe/fuYePGjdi4cWOu9rCwMHTu3Fltmz6CbFFkZWWhU6dOmDhxYp7t2UE1L25ubgCAc+fOoUePHjqrKb8jWvkdZc1v/JLIMfGBKC8MRERF4OTkhL179yIlJUXtqMClS5ek9tddvXo1Vx9XrlxBhQoVinQ6ZMKECQgJCcHSpUvRr1+/PPdp0qQJDh48iKysLLWB1ceOHUOFChUK/ADTlrW1NSwtLdVmYhXk008/haurK6ZNmwYrKytMnjxZaqtVqxbOnDmDDh06FHgqpzDGxsbo1q0bunXrhqysLHzyySf4/vvvMXXq1ELX+snv/ynnrK2BAwdi0aJF2LZtG3bt2gVra2v4+PgUWltYWBiqVauGlStX5mrbsmULfv/9d6xevbrQEKTJ+1OrVi1ERETg4cOHGh0lqlWrFp4+fSodEdJEmzZtUKlSJWzYsAFffPFFoQOrnZycpJmGr8v5+1SpUiUAr2a/vU7bI0iAZu8lyQtPmREVwbvvvovMzEx8++23atuXLFkChUIBX19fte2xsbFqK0bfvn0bf/zxBzp37lzoh8WCBQuwcOFCfPHFFwXOlOrVqxeSkpKwZcsWaduDBw8QHh6Obt265Tm+qLiUSiV69OiBbdu25TmFO69v4lOnTsXnn3+OKVOm4LvvvpO29+7dG3fu3MGPP/6Y6zHPnz9HampqofX8999/uepr1KgRABRp2YGtW7eqTZs/fvw4jh07luv/s1GjRmjUqBHWrFmD3377DX379i10scrnz59jy5Yt6Nq1K3r16pXrNmrUKKSkpODPP/8stE4zMzMAuYNBXvz9/SGEwMyZM3O1FXSkpHfv3oiNjUVERESutsePHyMjIyPfx1aoUAGTJk3CxYsXMWnSpDyf5+eff8bx48cBvPp9On78OGJjY6X21NRU/PDDD3B2dpbGitWqVQsA1MYvZWZm4ocffsi3lsJo8l6SvPAIEVERdOvWDd7e3vjf//6HGzduoHHjxtizZw/++OMPjB07VvrDna1Bgwbw8fFRm3YPIM8Pqdf9/vvvmDhxImrXro169erh559/Vmvv1KkTbGxsALwKRK1bt8bgwYNx4cIFaaXqzMzMQp+nOL755hvs2bMHnp6e0nT5e/fuITw8HIcOHULFihVzPWbBggV48uQJgoKCYGFhgY8++ggDBgzApk2bMGLECERFReGdd95BZmYmLl26hE2bNiEiIiLfKeLZhg4diocPH6J9+/ZwcHDAzZs3sWLFCjRp0qRIq4q7urqiTZs2GDlyJNLS0rB06VJUqVIlz9NGAwcOxOeffw4ARTpd9ueffyIlJQXdu3fPs71169awtrZGWFgY+vTpU2BftWrVQsWKFbF69WpYWFjAzMwMrVq1ynO8kbe3NwYMGIDly5fj6tWr6NKlC7KysnDw4EF4e3tj1KhReT7HhAkT8Oeff6Jr164YNGgQmjdvjtTUVJw7dw6bN2/GjRs3cq2RlfPx8fHxWLRoEaKiotCrVy/Y2toiMTERW7duxfHjx3HkyBEAwOTJk7Fhwwb4+vpi9OjRqFy5MtatW4fr16/jt99+k4541q9fH61bt8aUKVOkI14bN24sMJwVRpP3kmSmNKe4EZVVea1UnZKSIsaNGyfs7e2FkZGRqF27tliwYEGuVXkBiKCgIPHzzz+L2rVrC5VKJZo2bao2RTg/06dPl6bt53XL2cfDhw9FYGCgqFKliqhQoYLw9PTUanVoTabdC/FqGYGBAwcKa2troVKpRM2aNUVQUJBIS0sTQuS9UnVmZqbo16+fMDQ0FFu3bhVCCJGeni7mzZsn6tevL1QqlahUqZJo3ry5mDlzpnjy5IlaDUFBQblq27x5s+jcubOoVq2aMDY2FjVq1BAff/yxuHfvXoGv9/WVqhctWiQcHR2FSqUSbdu2FWfOnMnzMffu3RMGBgaiTp06BfadrVu3bsLExESkpqbmu8+gQYOEkZGRePDgQaGrZ//xxx/C3d1dGBoaqk0bzzntXgghMjIyxIIFC4Sbm5swNjYW1tbWwtfXV5w6dUraJ6+VqlNSUsSUKVOEq6urMDY2FlWrVhVvv/22WLhwoUhPTy/S687+P6lcubIwNDQUdnZ2ok+fPiI6Olptv7///lv06tVLVKxYUZiYmIiWLVuK7du35+rv77//Fh07dhQqlUrY2NiIL774QkRGRuY57b5+/fq5Hp/X+5Pfe0nyphCCo82IdEmhUCAoKCjX6TUq3x48eAA7OztMmzYNU6dOLe1yiEjHOIaIiKgIQkNDkZmZiQEDBpR2KUSkBxxDRERUgP379+PChQv4+uuv0aNHj1wz0IjozcBARERUgFmzZuHIkSN45513sGLFitIuh4j0hGOIiIiISPY4hoiIiIhkj4GIiIiIZI9jiIogKysLd+/ehYWFBZd9JyIiKieEEEhJSYG9vb3aJY7ywkBUBHfv3s11oUkiIiIqH27fvg0HB4cC92EgKoLsi3nevn0blpaWpVwNERERFUVycjIcHR3VLsqdHwaiIsg+TWZpaclAREREVM4UZbgLB1UTERGR7DEQERERkewxEBEREZHsMRARERGR7DEQERERkewxEBEREZHsMRARERGR7DEQERERkewxEBEREZHsMRARERGR7DEQERERkewxEBEREZHsMRARERGR7DEQERERkewxEBEREZHsGZZ2AQQ4T96hk35uzPXTST9ERERywyNEREREJHsMRERERCR7DEREREQke6UaiGbMmAGFQqF2c3Nzk9pfvHiBoKAgVKlSBebm5vD390dSUpJaH7du3YKfnx8qVKiAatWqYcKECcjIyFDbJzo6Gs2aNYNKpYKrqytCQ0NL4uURERFROVHqR4jq16+Pe/fuSbdDhw5JbePGjcO2bdsQHh6OmJgY3L17Fz179pTaMzMz4efnh/T0dBw5cgTr1q1DaGgopk2bJu1z/fp1+Pn5wdvbG3FxcRg7diyGDh2KiIiIEn2dREREVHaV+iwzQ0ND2Nra5tr+5MkTrF27Fr/88gvat28PAAgJCUG9evVw9OhRtG7dGnv27MGFCxewd+9e2NjYoEmTJpg9ezYmTZqEGTNmwNjYGKtXr4aLiwsWLVoEAKhXrx4OHTqEJUuWwMfHp0RfKxEREZVNpX6E6OrVq7C3t0fNmjXRv39/3Lp1CwBw6tQpvHz5Eh07dpT2dXNzQ40aNRAbGwsAiI2NRcOGDWFjYyPt4+Pjg+TkZMTHx0v7vN5H9j7ZfeQlLS0NycnJajciIiJ6c5VqIGrVqhVCQ0Oxe/dufPfdd7h+/Tratm2LlJQUJCYmwtjYGBUrVlR7jI2NDRITEwEAiYmJamEouz27raB9kpOT8fz58zzrmjNnDqysrKSbo6OjLl4uERERlVGlesrM19dX+nejRo3QqlUrODk5YdOmTTA1NS21uqZMmYLx48dL95OTkxmKiIiI3mClPobodRUrVkSdOnWQkJCATp06IT09HY8fP1Y7SpSUlCSNObK1tcXx48fV+siehfb6PjlnpiUlJcHS0jLf0KVSqaBSqXT1skoVV8EmIiIqXKmPIXrd06dP8ffff8POzg7NmzeHkZER9u3bJ7VfvnwZt27dgoeHBwDAw8MD586dw/3796V9IiMjYWlpCXd3d2mf1/vI3ie7DyIiIqJSDUSff/45YmJicOPGDRw5cgTvv/8+DAwM0K9fP1hZWSEwMBDjx49HVFQUTp06hcGDB8PDwwOtW7cGAHTu3Bnu7u4YMGAAzpw5g4iICHz55ZcICgqSjvCMGDEC165dw8SJE3Hp0iWsWrUKmzZtwrhx40rzpRMREVEZUqqnzP755x/069cP//33H6ytrdGmTRscPXoU1tbWAIAlS5ZAqVTC398faWlp8PHxwapVq6THGxgYYPv27Rg5ciQ8PDxgZmaGgIAAzJo1S9rHxcUFO3bswLhx47Bs2TI4ODhgzZo1nHJPREREEoUQQpR2EWVdcnIyrKys8OTJE1haWuq8f32O8+EYIiIikitNPr/L1BgiIiIiotLAQERERESyx0BEREREssdARERERLLHQERERESyx0BEREREssdARERERLLHQERERESyx0BEREREssdARERERLLHQERERESyx0BEREREssdARERERLLHQERERESyx0BEREREssdARERERLLHQERERESyx0BEREREssdARERERLJnWNoFUPnkPHmHzvq6MddPZ30RERFpg0eIiIiISPYYiIiIiEj2GIiIiIhI9hiIiIiISPYYiIiIiEj2GIiIiIhI9jjtnsocXU3p53R+IiIqKh4hIiIiItljICIiIiLZ4ykzkhWejiMiorzwCBERERHJHo8QEemIPo8+8cgWEZF+MRARyRgv0ktE9ApPmREREZHsMRARERGR7PGUGRHpBcc9EVF5wiNEREREJHsMRERERCR7DEREREQkewxEREREJHscVE1E5Q4HbBORrvEIEREREckejxAREb2GR5+I5IlHiIiIiEj2GIiIiIhI9hiIiIiISPYYiIiIiEj2OKiaiKgE6GqwNsAB20T6wCNEREREJHs8QkREVM5xqQCi4uMRIiIiIpI9BiIiIiKSPZ4yIyKifPF0HMkFjxARERGR7DEQERERkezxlBkREZUKfZ6O46k+0hSPEBEREZHsMRARERGR7JWZQDR37lwoFAqMHTtW2vbixQsEBQWhSpUqMDc3h7+/P5KSktQed+vWLfj5+aFChQqoVq0aJkyYgIyMDLV9oqOj0axZM6hUKri6uiI0NLQEXhERERGVF2UiEJ04cQLff/89GjVqpLZ93Lhx2LZtG8LDwxETE4O7d++iZ8+eUntmZib8/PyQnp6OI0eOYN26dQgNDcW0adOkfa5fvw4/Pz94e3sjLi4OY8eOxdChQxEREVFir4+IiIjKtlIPRE+fPkX//v3x448/olKlStL2J0+eYO3atVi8eDHat2+P5s2bIyQkBEeOHMHRo0cBAHv27MGFCxfw888/o0mTJvD19cXs2bOxcuVKpKenAwBWr14NFxcXLFq0CPXq1cOoUaPQq1cvLFmypFReLxEREZU9pT7LLCgoCH5+fujYsSO++uorafupU6fw8uVLdOzYUdrm5uaGGjVqIDY2Fq1bt0ZsbCwaNmwIGxsbaR8fHx+MHDkS8fHxaNq0KWJjY9X6yN7n9VNzOaWlpSEtLU26n5ycrINXSkRE5Z2uZq8BuWewcWZc6SrVQLRx40b89ddfOHHiRK62xMREGBsbo2LFimrbbWxskJiYKO3zehjKbs9uK2if5ORkPH/+HKamprmee86cOZg5c6bWr4uIiIjKl1ILRLdv38aYMWMQGRkJExOT0iojT1OmTMH48eOl+8nJyXB0dCzFioiIiLTHo0+FK7UxRKdOncL9+/fRrFkzGBoawtDQEDExMVi+fDkMDQ1hY2OD9PR0PH78WO1xSUlJsLW1BQDY2trmmnWWfb+wfSwtLfM8OgQAKpUKlpaWajciIiJ6c5VaIOrQoQPOnTuHuLg46daiRQv0799f+reRkRH27dsnPeby5cu4desWPDw8AAAeHh44d+4c7t+/L+0TGRkJS0tLuLu7S/u83kf2Ptl9EBEREZXaKTMLCws0aNBAbZuZmRmqVKkibQ8MDMT48eNRuXJlWFpa4tNPP4WHhwdat24NAOjcuTPc3d0xYMAAzJ8/H4mJifjyyy8RFBQElUoFABgxYgS+/fZbTJw4EUOGDMH+/fuxadMm7Nihu4FxREREcvWmnI4r9VlmBVmyZAmUSiX8/f2RlpYGHx8frFq1Smo3MDDA9u3bMXLkSHh4eMDMzAwBAQGYNWuWtI+Liwt27NiBcePGYdmyZXBwcMCaNWvg4+NTGi+JiIiIyqAyFYiio6PV7puYmGDlypVYuXJlvo9xcnLCzp07C+zXy8sLp0+f1kWJRERE9AYq9YUZiYiIiEobAxERERHJHgMRERERyR4DEREREckeAxERERHJHgMRERERyR4DEREREckeAxERERHJHgMRERERyR4DEREREckeAxERERHJHgMRERERyR4DEREREckeAxERERHJHgMRERERyR4DEREREckeAxERERHJHgMRERERyR4DEREREckeAxERERHJXrEDUWZmJuLi4vDo0SNd1ENERERU4jQORGPHjsXatWsBvApDnp6eaNasGRwdHREdHa3r+oiIiIj0TuNAtHnzZjRu3BgAsG3bNly/fh2XLl3CuHHj8L///U/nBRIRERHpm8aB6MGDB7C1tQUA7Ny5Ex988AHq1KmDIUOG4Ny5czovkIiIiEjfNA5ENjY2uHDhAjIzM7F792506tQJAPDs2TMYGBjovEAiIiIifTPU9AGDBw9G7969YWdnB4VCgY4dOwIAjh07Bjc3N50XSERERKRvGgeiGTNmoEGDBrh9+zY++OADqFQqAICBgQEmT56s8wKJiIiI9E3jQAQAvXr1AgC8ePFC2hYQEKCbioiIiIhKmMZjiDIzMzF79mxUr14d5ubmuHbtGgBg6tSp0nR8IiIiovJE40D09ddfIzQ0FPPnz4exsbG0vUGDBlizZo1OiyMiIiIqCRoHovXr1+OHH35A//791WaVNW7cGJcuXdJpcUREREQlQeNAdOfOHbi6uubanpWVhZcvX+qkKCIiIqKSpHEgcnd3x8GDB3Nt37x5M5o2baqTooiIiIhKksazzKZNm4aAgADcuXMHWVlZ2LJlCy5fvoz169dj+/bt+qiRiIiISK80PkL03nvvYdu2bdi7dy/MzMwwbdo0XLx4Edu2bZNWrSYiIiIqT7Rah6ht27aIjIzUdS1EREREpULjI0REREREb5oiHSGqVKkSFApFkTp8+PBhsQoiIiIiKmlFCkRLly7VcxlEREREpadIgYjXKSMiIqI3mcZjiHbu3ImIiIhc2/fs2YNdu3bppCgiIiKikqRxIJo8eTIyMzNzbc/KysLkyZN1UhQRERFRSdI4EF29ehXu7u65tru5uSEhIUEnRRERERGVJI0DkZWVFa5du5Zre0JCAszMzHRSFBEREVFJ0mql6rFjx+Lvv/+WtiUkJOCzzz5D9+7ddVocERERUUnQOBDNnz8fZmZmcHNzg4uLC1xcXFCvXj1UqVIFCxcu1EeNRERERHql8aU7rKyscOTIEURGRuLMmTMwNTVFo0aN0K5dO33UR0RERKR3Wl3LTKFQoHPnzujcubOu6yEiIiIqcUUKRMuXL8fw4cNhYmKC5cuXF7jv6NGjdVIYERERUUkpUiBasmQJ+vfvDxMTEyxZsiTf/RQKBQMRERERlTtFCkTXr1/P899EREREbwKNZ5nNmjULz549y7X9+fPnmDVrlk6KIiIiIipJGgeimTNn4unTp7m2P3v2DDNnztRJUUREREQlSeNAJISAQqHItf3MmTOoXLmyTooiIiIiKklFnnZfqVIlKBQKKBQK1KlTRy0UZWZm4unTpxgxYoReiiQiIiLSpyIHoqVLl0IIgSFDhmDmzJmwsrKS2oyNjeHs7AwPDw+9FElERESkT0UORAEBAcjIyIBCoUD79u3h6Oioz7qIiIiISoxGY4gMDQ0xcuRIZGVl6eTJv/vuOzRq1AiWlpawtLSEh4cHdu3aJbW/ePECQUFBqFKlCszNzeHv74+kpCS1Pm7dugU/Pz9UqFAB1apVw4QJE5CRkaG2T3R0NJo1awaVSgVXV1eEhobqpH4iIiJ6M2g8qLply5Y4ffq0Tp7cwcEBc+fOxalTp3Dy5Em0b98e7733HuLj4wEA48aNw7Zt2xAeHo6YmBjcvXsXPXv2lB6fmZkJPz8/pKen48iRI1i3bh1CQ0Mxbdo0aZ/r16/Dz88P3t7eiIuLw9ixYzF06FBERETo5DUQERFR+afxtcw++eQTfPbZZ/jnn3/QvHlzmJmZqbU3atSoyH1169ZN7f7XX3+N7777DkePHoWDgwPWrl2LX375Be3btwcAhISEoF69ejh69Chat26NPXv24MKFC9i7dy9sbGzQpEkTzJ49G5MmTcKMGTNgbGyM1atXw8XFBYsWLQIA1KtXD4cOHcKSJUvg4+Oj6csnIiKiN5DGgahv374A1K9ZplAopOn4mZmZWhWSmZmJ8PBwpKamwsPDA6dOncLLly/RsWNHaR83NzfUqFEDsbGxaN26NWJjY9GwYUPY2NhI+/j4+GDkyJGIj49H06ZNERsbq9ZH9j5jx47Vqk4iIiJ682gciHR96Y5z587Bw8MDL168gLm5OX7//Xe4u7sjLi4OxsbGqFixotr+NjY2SExMBAAkJiaqhaHs9uy2gvZJTk7G8+fPYWpqmqumtLQ0pKWlSfeTk5OL/TqJiIio7NI4EDk5Oem0gLp16yIuLg5PnjzB5s2bERAQgJiYGJ0+h6bmzJnDVbeJiIhkRONAlO3ChQu4desW0tPT1bZ3795do36MjY3h6uoKAGjevDlOnDiBZcuWoU+fPkhPT8fjx4/VjhIlJSXB1tYWAGBra4vjx4+r9Zc9C+31fXLOTEtKSoKlpWWeR4cAYMqUKRg/frx0Pzk5mcsMEBERvcE0DkTXrl3D+++/j3PnzkljhwBIK1drO4YoW1ZWFtLS0tC8eXMYGRlh37598Pf3BwBcvnwZt27dkhaA9PDwwNdff4379++jWrVqAIDIyEhYWlrC3d1d2mfnzp1qzxEZGVngIpIqlQoqlapYr4OIiIjKD42n3Y8ZMwYuLi64f/8+KlSogPj4eBw4cAAtWrRAdHS0Rn1NmTIFBw4cwI0bN3Du3DlMmTIF0dHR6N+/P6ysrBAYGIjx48cjKioKp06dwuDBg+Hh4YHWrVsDADp37gx3d3cMGDAAZ86cQUREBL788ksEBQVJgWbEiBG4du0aJk6ciEuXLmHVqlXYtGkTxo0bp+lLJyIiojeUxkeIYmNjsX//flStWhVKpRJKpRJt2rTBnDlzMHr0aI3WKLp//z4GDhyIe/fuwcrKCo0aNUJERAQ6deoEAFiyZAmUSiX8/f2RlpYGHx8frFq1Snq8gYEBtm/fjpEjR8LDwwNmZmYICAjArFmzpH1cXFywY8cOjBs3DsuWLYODgwPWrFnDKfdEREQk0TgQZWZmwsLCAgBQtWpV3L17F3Xr1oWTkxMuX76sUV9r164tsN3ExAQrV67EypUr893Hyckp1ymxnLy8vHS2mCQRERG9eTQORA0aNMCZM2fg4uKCVq1aYf78+TA2NsYPP/yAmjVr6qNGIiIiIr3SOBB9+eWXSE1NBQDMmjULXbt2Rdu2bVGlShX8+uuvOi+QiIiISN80DkSvj71xdXXFpUuX8PDhQ1SqVEmaaUZERERUnmi9DtHrKleurItuiIiIiEqFxtPuiYiIiN40DEREREQkewxEREREJHtFCkTNmjXDo0ePALyaWfbs2TO9FkVERERUkooUiC5evChNtZ85cyaePn2q16KIiIiISlKRZpk1adIEgwcPRps2bSCEwMKFC2Fubp7nvtOmTdNpgURERET6VqRAFBoaiunTp2P79u1QKBTYtWsXDA1zP1ShUDAQERERUblTpEBUt25dbNy4EQCgVCqxb98+VKtWTa+FEREREZUUjRdmzMrK0kcdRERERKVGq5Wq//77byxduhQXL14EALi7u2PMmDGoVauWTosjIiIiKgkar0MUEREBd3d3HD9+HI0aNUKjRo1w7Ngx1K9fH5GRkfqokYiIiEivND5CNHnyZIwbNw5z587NtX3SpEno1KmTzoojIiIiKgkaHyG6ePEiAgMDc20fMmQILly4oJOiiIiIiEqSxoHI2toacXFxubbHxcVx5hkRERGVSxqfMhs2bBiGDx+Oa9eu4e233wYAHD58GPPmzcP48eN1XiARERGRvmkciKZOnQoLCwssWrQIU6ZMAQDY29tjxowZGD16tM4LJCIiItI3jQORQqHAuHHjMG7cOKSkpAAALCwsdF4YERERUUnRah2ibAxCRERE9CbQeFA1ERER0ZuGgYiIiIhkj4GIiIiIZE+jQPTy5Ut06NABV69e1Vc9RERERCVOo0BkZGSEs2fP6qsWIiIiolKh8Smzjz76CGvXrtVHLURERESlQuNp9xkZGQgODsbevXvRvHlzmJmZqbUvXrxYZ8URERERlQSNA9H58+fRrFkzAMCVK1fU2hQKhW6qIiIiIipBGgeiqKgofdRBREREVGq0nnafkJCAiIgIPH/+HAAghNBZUUREREQlSeNA9N9//6FDhw6oU6cO3n33Xdy7dw8AEBgYiM8++0znBRIRERHpm8aBaNy4cTAyMsKtW7dQoUIFaXufPn2we/dunRZHREREVBI0HkO0Z88eREREwMHBQW177dq1cfPmTZ0VRkRERFRSND5ClJqaqnZkKNvDhw+hUql0UhQRERFRSdI4ELVt2xbr16+X7isUCmRlZWH+/Pnw9vbWaXFEREREJUHjU2bz589Hhw4dcPLkSaSnp2PixImIj4/Hw4cPcfjwYX3USERERKRXGh8hatCgAa5cuYI2bdrgvffeQ2pqKnr27InTp0+jVq1a+qiRiIiISK80PkIEAFZWVvjf//6n61qIiIiISoVWgejRo0dYu3YtLl68CABwd3fH4MGDUblyZZ0WR0RERFQSND5lduDAATg7O2P58uV49OgRHj16hOXLl8PFxQUHDhzQR41EREREeqXxEaKgoCD06dMH3333HQwMDAAAmZmZ+OSTTxAUFIRz587pvEgiIiIifdL4CFFCQgI+++wzKQwBgIGBAcaPH4+EhASdFkdERERUEjQORM2aNZPGDr3u4sWLaNy4sU6KIiIiIipJRTpldvbsWenfo0ePxpgxY5CQkIDWrVsDAI4ePYqVK1di7ty5+qmSiIiISI+KFIiaNGkChUIBIYS0beLEibn2+/DDD9GnTx/dVUdERERUAooUiK5fv67vOoiIiIhKTZECkZOTk77rICIiIio1Wi3MePfuXRw6dAj3799HVlaWWtvo0aN1UhgRERFRSdE4EIWGhuLjjz+GsbExqlSpAoVCIbUpFAoGIiIiIip3NA5EU6dOxbRp0zBlyhQolRrP2iciIiIqczRONM+ePUPfvn0ZhoiIiOiNoXGqCQwMRHh4uD5qISIiIioVGp8ymzNnDrp27Yrdu3ejYcOGMDIyUmtfvHixzoojIiIiKglaBaKIiAjUrVsXAHINqiYiIiIqbzQORIsWLUJwcDAGDRqkh3KIiIiISp7GY4hUKhXeeecdfdRCREREVCo0DkRjxozBihUrdPLkc+bMwVtvvQULCwtUq1YNPXr0wOXLl9X2efHiBYKCglClShWYm5vD398fSUlJavvcunULfn5+qFChAqpVq4YJEyYgIyNDbZ/o6Gg0a9YMKpUKrq6uCA0N1clrICIiovJP41Nmx48fx/79+7F9+3bUr18/16DqLVu2FLmvmJgYBAUF4a233kJGRga++OILdO7cGRcuXICZmRkAYNy4cdixYwfCw8NhZWWFUaNGoWfPnjh8+DAAIDMzE35+frC1tcWRI0dw7949DBw4EEZGRvjmm28AvLoWm5+fH0aMGIGwsDDs27cPQ4cOhZ2dHXx8fDR9C4iIiOgNo3EgqlixInr27KmTJ9+9e7fa/dDQUFSrVg2nTp1Cu3bt8OTJE6xduxa//PIL2rdvDwAICQlBvXr1cPToUbRu3Rp79uzBhQsXsHfvXtjY2KBJkyaYPXs2Jk2ahBkzZsDY2BirV6+Gi4sLFi1aBACoV68eDh06hCVLljAQERERkeaBKCQkRB91AACePHkCAKhcuTIA4NSpU3j58iU6duwo7ePm5oYaNWogNjYWrVu3RmxsLBo2bAgbGxtpHx8fH4wcORLx8fFo2rQpYmNj1frI3mfs2LF51pGWloa0tDTpfnJysq5eIhEREZVBZWa56aysLIwdOxbvvPMOGjRoAABITEyEsbExKlasqLavjY0NEhMTpX1eD0PZ7dltBe2TnJyM58+f56plzpw5sLKykm6Ojo46eY1ERERUNml8hMjFxaXA9YauXbumVSFBQUE4f/48Dh06pNXjdWnKlCkYP368dD85OZmhiIiI6A2mcSDKeZrp5cuXOH36NHbv3o0JEyZoVcSoUaOwfft2HDhwAA4ODtJ2W1tbpKen4/Hjx2pHiZKSkmBrayvtc/z4cbX+smehvb5PzplpSUlJsLS0hKmpaa56VCoVVCqVVq+FiIiIyh+NA9GYMWPy3L5y5UqcPHlSo76EEPj000/x+++/Izo6Gi4uLmrtzZs3h5GREfbt2wd/f38AwOXLl3Hr1i14eHgAADw8PPD111/j/v37qFatGgAgMjISlpaWcHd3l/bZuXOnWt+RkZFSH0RERCRvOhtD5Ovri99++02jxwQFBeHnn3/GL7/8AgsLCyQmJiIxMVEa12NlZYXAwECMHz8eUVFROHXqFAYPHgwPDw+0bt0aANC5c2e4u7tjwIABOHPmDCIiIvDll18iKChIOsozYsQIXLt2DRMnTsSlS5ewatUqbNq0CePGjdPVyyciIqJyTGeBaPPmzdLssKL67rvv8OTJE3h5ecHOzk66/frrr9I+S5YsQdeuXeHv74927drB1tZWba0jAwMDbN++HQYGBvDw8MBHH32EgQMHYtasWdI+Li4u2LFjByIjI9G4cWMsWrQIa9as4ZR7IiIiAqDFKbOmTZuqDaoWQiAxMRH//vsvVq1apVFfQohC9zExMcHKlSuxcuXKfPdxcnLKdUosJy8vL5w+fVqj+oiIiEgeNA5EPXr0ULuvVCphbW0NLy8vuLm56aouIiIiohKjcSCaPn26PuogIiIiKjVlZmFGIiIiotJS5CNESqWywAUZAUChUOS6yjwRERFRWVfkQPT777/n2xYbG4vly5cjKytLJ0URERERlaQiB6L33nsv17bLly9j8uTJ2LZtG/r376821Z2IiIiovNBqDNHdu3cxbNgwNGzYEBkZGYiLi8O6devg5OSk6/qIiIiI9E6jQPTkyRNMmjQJrq6uiI+Px759+7Bt2zbp6vRERERE5VGRT5nNnz8f8+bNg62tLTZs2JDnKTQiIiKi8qjIgWjy5MkwNTWFq6sr1q1bh3Xr1uW53+uX1SAiIiIqD4ociAYOHFjotHsiIiKi8qjIgSg0NFSPZRARERGVHq5UTURERLLHQERERESyx0BEREREssdARERERLLHQERERESyx0BEREREssdARERERLLHQERERESyx0BEREREssdARERERLLHQERERESyx0BEREREssdARERERLLHQERERESyx0BEREREssdARERERLLHQERERESyx0BEREREssdARERERLLHQERERESyx0BEREREssdARERERLLHQERERESyx0BEREREssdARERERLLHQERERESyx0BEREREssdARERERLLHQERERESyx0BEREREssdARERERLLHQERERESyx0BEREREssdARERERLLHQERERESyx0BEREREssdARERERLLHQERERESyx0BEREREssdARERERLLHQERERESyx0BEREREssdARERERLLHQERERESyx0BEREREssdARERERLJXqoHowIED6NatG+zt7aFQKLB161a1diEEpk2bBjs7O5iamqJjx464evWq2j4PHz5E//79YWlpiYoVKyIwMBBPnz5V2+fs2bNo27YtTExM4OjoiPnz5+v7pREREVE5UqqBKDU1FY0bN8bKlSvzbJ8/fz6WL1+O1atX49ixYzAzM4OPjw9evHgh7dO/f3/Ex8cjMjIS27dvx4EDBzB8+HCpPTk5GZ07d4aTkxNOnTqFBQsWYMaMGfjhhx/0/vqIiIiofDAszSf39fWFr69vnm1CCCxduhRffvkl3nvvPQDA+vXrYWNjg61bt6Jv3764ePEidu/ejRMnTqBFixYAgBUrVuDdd9/FwoULYW9vj7CwMKSnpyM4OBjGxsaoX78+4uLisHjxYrXgRERERPJVZscQXb9+HYmJiejYsaO0zcrKCq1atUJsbCwAIDY2FhUrVpTCEAB07NgRSqUSx44dk/Zp164djI2NpX18fHxw+fJlPHr0KM/nTktLQ3JystqNiIiI3lxlNhAlJiYCAGxsbNS229jYSG2JiYmoVq2aWruhoSEqV66stk9efbz+HDnNmTMHVlZW0s3R0bH4L4iIiIjKrDIbiErTlClT8OTJE+l2+/bt0i6JiIiI9KjMBiJbW1sAQFJSktr2pKQkqc3W1hb3799Xa8/IyMDDhw/V9smrj9efIyeVSgVLS0u1GxEREb25ymwgcnFxga2tLfbt2ydtS05OxrFjx+Dh4QEA8PDwwOPHj3Hq1Clpn/379yMrKwutWrWS9jlw4ABevnwp7RMZGYm6deuiUqVKJfRqiIiIqCwr1UD09OlTxMXFIS4uDsCrgdRxcXG4desWFAoFxo4di6+++gp//vknzp07h4EDB8Le3h49evQAANSrVw9dunTBsGHDcPz4cRw+fBijRo1C3759YW9vDwD48MMPYWxsjMDAQMTHx+PXX3/FsmXLMH78+FJ61URERFTWlOq0+5MnT8Lb21u6nx1SAgICEBoaiokTJyI1NRXDhw/H48eP0aZNG+zevRsmJibSY8LCwjBq1Ch06NABSqUS/v7+WL58udRuZWWFPXv2ICgoCM2bN0fVqlUxbdo0TrknIiIiSakGIi8vLwgh8m1XKBSYNWsWZs2ale8+lStXxi+//FLg8zRq1AgHDx7Uuk4iIiJ6s5XZMUREREREJYWBiIiIiGSPgYiIiIhkj4GIiIiIZI+BiIiIiGSPgYiIiIhkj4GIiIiIZI+BiIiIiGSPgYiIiIhkj4GIiIiIZI+BiIiIiGSPgYiIiIhkj4GIiIiIZI+BiIiIiGSPgYiIiIhkj4GIiIiIZI+BiIiIiGSPgYiIiIhkj4GIiIiIZI+BiIiIiGSPgYiIiIhkj4GIiIiIZI+BiIiIiGSPgYiIiIhkj4GIiIiIZI+BiIiIiGSPgYiIiIhkj4GIiIiIZI+BiIiIiGSPgYiIiIhkj4GIiIiIZI+BiIiIiGSPgYiIiIhkj4GIiIiIZI+BiIiIiGSPgYiIiIhkj4GIiIiIZI+BiIiIiGSPgYiIiIhkj4GIiIiIZI+BiIiIiGSPgYiIiIhkj4GIiIiIZI+BiIiIiGSPgYiIiIhkj4GIiIiIZI+BiIiIiGSPgYiIiIhkj4GIiIiIZI+BiIiIiGSPgYiIiIhkj4GIiIiIZI+BiIiIiGSPgYiIiIhkj4GIiIiIZI+BiIiIiGSPgYiIiIhkT1aBaOXKlXB2doaJiQlatWqF48ePl3ZJREREVAbIJhD9+uuvGD9+PKZPn46//voLjRs3ho+PD+7fv1/apREREVEpk00gWrx4MYYNG4bBgwfD3d0dq1evRoUKFRAcHFzapREREVEpk0UgSk9Px6lTp9CxY0dpm1KpRMeOHREbG1uKlREREVFZYFjaBZSEBw8eIDMzEzY2NmrbbWxscOnSpVz7p6WlIS0tTbr/5MkTAEBycrJe6stKe6aTfvKqT19966pfffZdku9Hee2b/498rwvql33z/7G0+9ZVn0KIwncWMnDnzh0BQBw5ckRt+4QJE0TLli1z7T99+nQBgDfeeOONN954ewNut2/fLjQryOIIUdWqVWFgYICkpCS17UlJSbC1tc21/5QpUzB+/HjpflZWFh4+fIgqVapAoVDovd6ckpOT4ejoiNu3b8PS0lL2fZfHmstr3+WxZvZdcv2y75Lrl31rRwiBlJQU2NvbF7qvLAKRsbExmjdvjn379qFHjx4AXoWcffv2YdSoUbn2V6lUUKlUatsqVqxYApUWzNLSUm8/TOWx7/JYc3ntuzzWzL5Lrl/2XXL9sm/NWVlZFWk/WQQiABg/fjwCAgLQokULtGzZEkuXLkVqaioGDx5c2qURERFRKZNNIOrTpw/+/fdfTJs2DYmJiWjSpAl2796da6A1ERERyY9sAhEAjBo1Ks9TZGWdSqXC9OnTc53Gk2vf5bHm8tp3eayZfZdcv+y75Ppl3/qnEKIoc9GIiIiI3lyyWJiRiIiIqCAMRERERCR7DEREREQkewxEREQkaw8fPiztEqgMYCAiIqI3lpeXF27cuJFv+5YtW1C/fn2t+j5//ryWVVFZxEBUDj1//rxYjxdC4OTJk9i8eTN+++03/PXXX0W78N0b6MCBA8jIyCjtMkqdt7c32rdvX+CtQ4cOpV3mG+PRo0dYsWJFnhezfPLkSb5tpS0jIwMLFixAs2bNYG5uDnNzczRr1gwLFy7Ey5cvte43ICAA69evx61bt3RY7SsWFhZo1KgRvv/+e7XtDx8+RN++fdG/f3+MHj1aq74bNWqEVq1a4ccff0RKSoouypXcv3+/0H0OHjyoVd9FqTUmJkarvosiMzNTb30XB6fdlyNpaWn49ttvsWDBAiQmJmrVR1RUFAIDA3Hz5k0pBCkUCri4uCA4OBjt2rXTZck6cfbs2UL3MTQ0hK2tLSpXrqxR3wYGBrh37x6qVaumbXmFevDgAW7cuAGFQgFnZ2dUqVJFb88FvHq/WrRogfT09CI/Zty4cfm2paSk4JdffkFaWlqx/pDt3bsXHTt2zLc9KysL33zzDb788kuN+s3v58PKygo1atQo1vUH9VXz7NmzcfbsWYSHh+fZ3rt3bzRu3Bj/+9//NOoXeBVuC3vNCoUC+/bt06jf58+fo1OnToiNjUXHjh1Rr149AMDFixexd+9evPPOO9izZw9MTEw0rtnLywvHjh1Deno6nJ2d4e3tLYV0Ozs7jfvLKTg4GOPHj0fr1q2xZs0anDhxAiNHjoSDgwNCQ0PRoEEDrfo9ePAgQkJCsHnzZmRlZcHf3x9Dhw5F27Zti11ztWrVsGrVKvTq1StX2/PnzzFp0iSsXr1ao9/zbF5eXoiIiMh3XaCYmBh07dpV5yHvypUrWLNmDX766Sfcu3dPp33rRLEvJU869eLFCzF58mTRvHlz4eHhIX7//XchhBDBwcHCzs5OODg4iLlz52rV99WrV0WFChWEt7e32Lp1q7h06ZK4ePGi+O2334Snp6cwMzMTf//9t1Z9jxs3rkg3bSgUCqFUKoVCoSjwplQqRdOmTcW5c+c06jspKUmrugpz/vx50bZtW6FUKtVu3t7e4tKlS3p5TiGEiIuLE0qlstj9vHz5UixdulRYW1sLV1dXsWHDhmL1Z2RkJIKCgkRqamqutnPnzolmzZoJe3t7jfvN7+dDqVSKChUqiC+++EJkZGSUqZobN24s9u7dm2/73r17RZMmTTTuVwghxo4dm+8tMDBQmJqaavXzMW3aNFGjRg1x5syZXG1xcXGiRo0aYvr06VrVLMSrv3379+8X06ZNE+3atRMqlUoolUpRt25dMWLECLFp0yat+xZCiJs3bwpPT09hamoqVCqVmDVrltY/Fzk9ffpUBAcHi3bt2gmFQiFq164t5s6dK+7du6d1nwsXLhSmpqaib9++4uHDh9L2AwcOiFq1aonatWuLQ4cOadV3gwYNRPfu3UVmZmautpiYGGFmZiZGjRqlde2vS01NFcHBwaJNmzbCwMBAtGrVSsyfP18nfesaA1EZM3HiRGFlZSX8/f2FnZ2dMDQ0FMOGDRMNGzYUGzZsKNYvcFBQkGjfvn2ebVlZWaJ9+/Za/xJ4eXmp3QwNDUWrVq3Utnl7e2vV940bNwq9Xbt2TcTGxoqePXuKNm3aFLlvhUIh7t+/r1VdBbl3756oUqWKcHNzE0uXLhW7d+8Wu3btEosWLRJubm7C2tpab0FMF4Ho559/FjVr1hR2dnZi5cqV4uXLl8Wu6+jRo8LNzU24urpKf8gzMzPF7NmzhbGxsejXr5/aH/6iyu9nIi4uTqxdu1bY29uLBQsWlKmazc3Nxc2bN/Ntv3nzprCwsNCq5rzoItzWqVNHbN68Od/2TZs2idq1axenTDXPnz8X+/btE59//rmwtLQs9s90RESEcHBwEDVq1BDGxsbiq6++yjMQFNfVq1fFF198IRwdHYWRkZHo1q2b1n3Fx8eLFi1aCDs7OxEeHi5Gjx4tDA0NxaeffiqePXumdb937twRNWvWFAMGDFDbfuDAAWFhYSE++eQTrfvOFhsbKwIDA4WlpaVo0KCBMDAwEAcOHCh2v/rEQFTGuLi4iD/++EMI8eobqEKhEIMHDxZZWVnF7rt+/frizz//zLf9zz//FPXr1y/28wjx6g++tkebiiP7KFhRKRQK8e6774r333+/wJumJk6cKJo1ayaeP3+eq+3Zs2eiWbNmYvLkyRr3WxTFCUS7du0SjRs3FpaWlmLWrFni6dOnOq3t+fPnYsyYMdKRl+bNm4tq1aqJ3377TafP87rw8HDRoEEDrR+vj5qtrKxEbGxsvu2xsbHCyspK6/5fp6twq1KpxK1bt/Jtv3XrllCpVNqWKUlLSxPR0dFixowZwtPTU5iYmIiaNWuKwYMHa9Xf06dPxbBhw4SxsbGYMWOGePnypdixY4eoXr26aNGihbhw4UKxa87rOb///ntRuXLlYge5jIwM0adPH6FUKoW5ubmIjo7WSY0JCQnCzs5OjB49WgghxMGDB4W5ubn4+OOPi9XvwoULhbu7u6hevbr4/PPPRVxcnBBCCENDQxEfH1/suvWJgaiMMTIyEv/8849038TERJw9e1YnfVtYWIjr16/n237t2jVhbm6uk+fSZSCqUaOGGDRokFi3bl2Bf5CFePXHI/sXsCgUCoXo06ePGDRoUIE3TTVt2lT8+uuv+bZv2LBBNG3aVON+hRDiyZMnBd4OHjyo8R/hY8eOCS8vL2FiYiLGjh0r/v33X61qK4qsrCzRr18/oVAohLm5uV5PHwrx6ufazMysWH3oumYvLy8xadKkfNsnTpwovLy8ivUcug631tbW4uTJk/m2Hz9+XFStWlWrvmNiYsTMmTOFl5eXMDU1FXXr1hXDhw8XYWFh4vbt29qWLIQQwtnZWTRs2FCcOnVKbfujR49E//79hYmJidbDEHKKiYkRAQEBwtzcXFhaWoqhQ4cWGHwLk56eLqZMmSKMjIxEv379RKVKlUTnzp2L/Z5kO3PmjKhUqZIICAgQlpaWYtiwYcXu08DAIM/T1AxEpDGlUql2Csfc3Fxcu3ZNJ30XNl4mMTFRJ2NPhNBtIJo+fbr0TVGpVIpatWqJoUOHil9++aVY5+iF0N8YIisrK3H16tV8269evar1EYDs8TH53bLbNe2zQoUKYuzYsWLZsmX53oorISFBtGnTRtjY2Ijvv/9etG7dWtja2oqtW7cWu+/8HDlyRDg7O2v9eH3UvHnzZmFoaChWrFih9sGRkZEhli9fLoyMjER4eLhWfesr3Pbu3Vv07Nkz3/aePXuKDz74QKu+FQqFcHJyEqtWrRKJiYnalpinSZMmibS0tHzbt2zZImxsbLTu/86dO+Lrr78WtWvXFgqFQrzzzjsiODi42AH09OnTokGDBsLFxUXs379fCCHEP//8I3x9fYWVlZVYs2aN1n2//gVq586dQqVSiT59+ojHjx+rtWnjm2++EbVr1xaOjo5i4sSJ0pjO8hCIOMusjFEqlfD19ZVG/2/btg3t27eHmZmZ2n5btmzRqu/9+/fnOxPrwYMH6NSpk06mRFpYWODMmTOoWbNmsfvKlpaWhsOHDyMmJgbR0dE4duwYXr58iTp16qB9+/ZYuXKlxn3qa5ZZYf0mJSWhevXqWk35L+p0WE9PzyL36ezsXKSZSdeuXStynzl9++23mDx5Mnx8fLB69WpYW1sjKysLCxYswIwZM9CrVy+sWLECFStW1Po5cvr333/Rr18/1KhRA8HBwWWq5v/973+YM2cOLCwspN+Ta9eu4enTp5gwYQLmzp2rcZ/Aq99zU1NTDB8+HC4uLvnup+lU8wsXLqBVq1aoX78+xo8fDzc3NwghcPHiRSxZsgQXLlzA0aNHtVrTZ/LkyYiOjsbp06dRt25deHp6wsvLC56enqhatarG/Wnqv//+02r2p6+vL/bu3YuqVati4MCBGDJkCOrWrSu1P378GDt37sSHH36ocd8qlQoBAQFYvHgxzM3N1drWrFmDzz77DO+88w527typcd9KpVLt9128NuM4+75CoSjWZ0FMTAyCg4OxefNmuLq6Ij4+HjExMXjnnXe07lPfGIjKmMGDBxe6T0pKCjZv3qxx39m/BHn9l2dv1/aXIOfU57fffhubNm2Cg4OD2vZGjRpp3Hd+Hj16hEWLFmHFihV4+vSpVnUrlUokJibqJRBduXIF1tbWebYnJSXBzc1Nq5rv3r0Le3v74pZY4ipXrowVK1agf//+udri4+MREBCAe/fu4c6dOxr127Rp0zzD3JMnT/DPP/+gbt262LNnD2xtbctMzdmOHz+OsLAwJCQkQAiBOnXq4MMPP0TLli216g/Qb7g9evQoAgMDcfHiRbUPTzc3N6xduxYeHh5a1Zzt6dOnOHjwIKKjo6WAVKdOHXh6esLb2zvPKeiFCQgIQIcOHeDl5YUaNWoUq76cunfvjsDAQHTt2hUGBga52s+cOYNmzZpp9Xu+a9cu+Pr65tt+8+ZNDB06FJGRkRr3rY8vVfnJXrYjODgYp06dQsuWLdGrVy+MHz++2H3rGgNRGbNkyZJC14Tp0qULDh8+rHHfN2/eLNJ+Tk5OGvetz7CVLT09HbGxsdIfy2PHjqF69epo164dPD09MXDgQI37zP7GYmhoqHVdecn5DSyn4rwflSpVwsqVK7X61pmf69evF3g0QRfu3btX4JoymZmZ+OabbzB16lSN+p05c2ae2y0tLVG3bl34+Pjk+WFVFIXVnJGRgTlz5mhcc3kXFxeHK1euAADq1KmDJk2a6OV5Hj58iMWLFxfrS4++1zgqSHECUWl69uwZ4uLi8Pbbb+u033PnzmHt2rX45ZdfirTwZEljICpjTE1N8f333+f54Z6amgofHx88ePAAly5d0vlzF+fwrj7D1qxZs6QA5OTkJAUgT09PnRwpycrKQmhoKLZs2SItoOji4oJevXphwIABWi3sp89vYKtWrcKkSZPQpUsXrF69WicLPSqVSjg5OUkfFt7e3rmO7pVnmZmZWocifbp69Sr++OMP6eeuZs2aeO+994p9qlkIgYSEBKSnp6Nu3bo6D/z6kpWVhRMnTkhfeg4fPoynT5+iRo0a8Pb2RkhIiFb9pqWl4ciRI2pfpl6+fInatWtL4eiDDz7Q8aspXiB68OABUlNT1f5mxsfHY+HChUhNTUWPHj10+qXodcWp+91338WGDRtgZWUFAJg7dy5GjBghnVb+77//0KpVKyQkJOiyZN0o4TFLVIjw8HBhYmIiTb3PlpKSIt555x1Ru3ZtcefOHb08t64W9NO17AGX3333nXjw4IFO+87KyhJ+fn5CoVCIJk2aiL59+4o+ffqIRo0aCYVCId577z2t+i1sJlhxBi0K8WrmlLe3t7CxsSlwKYWiioqKyjV43dXVVQwfPlxs2LBBZwNdMzMzxdq1a4Wfn5+oX7++aNCggejWrZtYt26dTpaWyOny5ctiwoQJwtbWVqvH79u3T9SrVy/P/6vHjx8Ld3d3rddW+eabb4ShoaFQKpXC1tZW2NjYCKVSKYyMjLReN0mIVz8bDRo0kAbZOzo6iuPHj2vdX7ZHjx6JVatWSfc//PBDtaUpevXqJR49eqRV3/PmzRO+vr7C0tJSKBQK4eDgID766COxdu1anU0qeZ2u1zjKT3H+pvbt21eMHz9eup+UlCQqVaok6tevL7p37y6MjIzE+vXrdVWqmuLUrVQq1SaqWFhYqE2w0eXkHV1jICqDfvzxR1GhQgURFRUlhHi1pkWbNm2Eq6ur3sKQEMX7Jfj333/FjRs31LadP39eDBo0SHzwwQciLCxM67p2794tJk2aJFq1aiWMjY1FgwYNxKhRo0R4eHixF1UMDg4WFhYW0iyO1+3bt09YWFiIdevWadxvYTPBsm/FtWLFCmFoaCgaNmwomjZtqnbTVvaHxdSpU0Xbtm2lFYPd3d2LVau+wmdOulwZt1u3bmLx4sX5ti9btkz06NFD4373798vlEqlmD59utrCjv/995+YOnWqMDAwEDExMVrV7O/vL9zc3MQvv/witmzZIt5++23RrFkzrfp63fz588WHH34o3Tc3Nxf+/v7S0hR169bVeqVqOzs70a9fP/HDDz8UODuzuHS9xlFBMzKXLVsmJk6cqPXvubOzs9qaQwsWLBC1atWS1pFasGCBaNWqlVZ9F6Y4nwU5Z+7mnHHMQEQamzdvnrC0tBRRUVGibdu2ombNmjpbeyI/5eHbTHJystixY4eYOHGieOutt4SxsbFwd3cXQUFBWvXXqVMnMWfOnHzbv/76a9G5c2eN+42OjpZuUVFRwtTUVISFhaltL+4Cazdu3BDe3t7C2tpafPnll2LGjBlqt+JKS0sT+/fvFxMmTNDJt2h9hc9s+lgZt0aNGgUu3Hfx4kXh6Oiocb+9e/cWw4cPz7d92LBhom/fvhr3K4QQNjY24uDBg9L9u3fvCqVSWexp4C1bthSRkZHS/ZwfdFu2bNH6ciP6pO81jopy04aJiYnal0xfX18xYcIE6f7ly5dF5cqVi1V/fhiIqMyZNGmSUCqVombNmoUuSKgLxfklKOlvMxkZGeLIkSNi8uTJxfqwtrGxEadPn863/a+//irWGiXZdL1y9w8//CAsLCzE+++/r7NLj6SlpYmYmBgxY8YM6cOjTp06YujQoWL9+vUFXmqiKPQVPvW5Mq5KpSp0PSkTExON+3V2dlYLLTkdOHBA6w9ShUKR6xSnmZlZsU89Va1aVe3vUPPmzdUCxd9//631Apg3b94s0k0b+lzjSJ+qVaumtshslSpV1C6dcuXKFa3f7z/++KPA29KlS4t1yqygtfTKciAqHyPtZKRnz55q942MjFC1alWMGTNGbbs26xAtX768wHZtpw4DQGJiIpydnaX7+/fvR8+ePaXBnN27d8ecOXO07j8rKwsnT55EVFSUNNgyNTUVDg4OeP/99+Ht7a1Vvw8fPoSNjU2+7TY2Nnj06JG2ZetFly5dcOzYMXz77bdazazLS/v27XHs2DG4uLjA09MTH3/8MX755RedzsI5e/Ys5s+fn2+7r69voT+jeZk0aRImTZqEWbNm6XzgdPXq1XH+/Hm4urrm2X727Fmt3qOkpCS135ecXFxckJiYqHG/wKtZnU+fPoWpqam0TalUIiUlBcnJydI2S0tLjfpNTU3FkydP4OjoCAA4efJkrvasrCytan59hqPIsSZO9jZtZ2VOnDgR0dHRGDt2LL777judrnEUGxuL//77D127dpW2rV+/HtOnT5cGPq9YsSLfq8oXpHXr1li+fDl+/PFHbNmyBSkpKWjfvr3UfuXKFen/QlM9evQodB9tJpMAr/6vBg0aJL3mFy9eYMSIEdJaemlpaVr1WxIYiMqY7JH52fr166ezvpcsWVLoPtqu02FpaYnHjx9LMyKOHz+OwMBAqV2hUGj9i+Dr64sjR44gJSUF9vb28Pb2xpIlS+Dt7V3s2TiZmZkFzsAxMDDQavFEfcrMzMT58+dRvXp1nfV58OBB2NnZoX379tKHhS5mr71OX+Fz9uzZCAkJwU8//YR+/fphwIABaNCgQXFKlbz77ruYOnUqunTpAhMTE7W258+fY/r06WofhkX14sULGBsb59tuZGSE9PR0jfsFIK1nlHNb06ZNpX9rEy5q1qyJv/76K9/39uTJk1ov3aBQKODg4IBBgwahW7duOp0Vl73A5etrHM2fPx/9+vUr9hpHM2fOhLe3t/QzcO7cOQQGBmLQoEGoV68eFixYAHt7e8yYMUPjvmfNmoWOHTvi559/RkZGBr744gtUqlRJat+4caPW6wRpG1yLIiAgQO3+Rx99lGsfXX2R0zVOuyedeO+991C1alXp20z//v2RmJgo/QLv2LEDn3/+OS5evKhx3/369ZOmgteuXVundedcGTyntLQ07N69u9jriFhYWODs2bM6Wetn0KBBUCqVhe6nycrMqamp0odFVFQU4uLipA+L7ICU3yKTRWVgYIDExMQCF6u0t7fX+r3Wx8q4SUlJaNasGQwMDDBq1ChpFeJLly5h5cqVyMzMxF9//VVg0MuLUqnEV199lWsF4mwpKSmYNm2aVu+FvpZ8mDp1KtatW4cTJ07ker2JiYlo2bIlBg4ciK+++kqjfrMfv27dOoSEhODx48f46KOPEBgYiHr16mncV1HpYo0jOzs7bNu2DS1atADwavXxmJgYHDp0CAAQHh6O6dOn48KFC1rV+ODBAxw+fBi2trZo1aqVWtvOnTtRr169Yv1NeX2F7tu3b+PHH3/Eixcv0K1bN7Rt21brfssrBiLSibNnz6JDhw5ITk6Wvs3Mnj1bah8wYADMzMywevVqjfsuyroWbdu21eqPzqBBg4p0aFjT9U9ynvrU9SVYnJyc0LRp0zwXwsz2+++/a9x3tpSUFBw6dEg6RXnmzBnUrl0b58+f17rPkgqful4Z9+bNmxg5ciQiIiLUTuf4+Phg5cqVWn0gFWU1aeDVgpllRUpKClq1aoV//vkHAwYMkI5CXb58GT///DOqV6+O48ePw8LColjPc+jQIYSEhCA8PBzu7u4IDAxEYGBgkb4EFEQfaxyZmJjg6tWr0qmrNm3awNfXF//73/8AADdu3EDDhg2RkpKicd/79+/HqFGjcPTo0VynN588eYK3334bq1ev1iq4nDt3Dt26dcPt27dRu3ZtbNy4EV26dEFqaiqUSiVSU1OxefPmIp1ae5MwEMlIUcdnaHqNo2wFfZvZsWMH3N3dtfrwyHldMEtLS8TFxUmny4p7ZEEfinIJFkDzoAUAQUFB2LBhA5ycnDB48GB89NFH+V6fTlvZHx5RUVGIiorCoUOH8OLFi2K9x/oKnwUp7sq4165dg4uLCxQKBR49eiRdYqN27dpqpy80VRIrg+fnr7/+wrRp07B9+3aNH/vo0SNMmTIFmzZtwuPHjwEAFStWRO/evfHNN9/o9OcwKSkJ/fr1Q0xMDP7991+t+54/f74UgFJSUlC9enV4eXlJR52L8//g5OSEn376Ce3atUN6ejoqVqyIbdu2oUOHDgBe/fx5enri4cOHGvfdvXt3eHt753vlguXLlyMqKkqrLz6+vr4wNDTE5MmT8dNPP2H79u3w8fHBjz/+CAD49NNPcerUKRw9elTjvsszBiIZKcovfnEv4KkPOa83lvPCscUJREOGDCl0H4VCgbVr12rctz6lpaVhy5YtCA4OxpEjR+Dn54fAwEB07txZq8GQ2YPWs0+ZZQ9ar169utrq1dqsNJ7t2rVrcHZ2LvY3fW28fPkSRkZGGj8uZxjv06cPli9frvEpspxeXxm8ffv28Pb21umYsIiICERGRsLY2BhDhw5FzZo1cenSJUyePBnbtm2Dj4+PVhcFzSaEwL///gsAsLa21noAbl6OHDmC4OBghIeHo27duhgyZAiGDx+u9c+Nvb29WgDKb4C8NkaOHIkzZ85g3rx52Lp1K9atW4e7d+9K48PCwsKwdOlSnDhxQuO+nZycsHv37nxPG166dAmdO3fGrVu3NO67atWq2L9/Pxo1aoSnT5/C0tISJ06cQPPmzaW+W7duLYVeueCgahnR5+F3fR990pfQ0NAinX4qa1QqFfr164d+/frh5s2bCA0NxSeffIKMjAzEx8fnOzYlPxUrVsTTp09hZ2cnDVr38vJCrVq1dFZz7dq19RIu9HlqIefPxM6dO4s1WzLb/v37pVM3GzZsQHp6OmrWrCmFI29vb63fl7Vr12LYsGGoXLkyHj16hDVr1mDx4sX49NNP0adPH5w/f16rsTktWrTA0KFD8eGHH8LS0lKnF0S+d+8e1q9fj5CQEDx69Aj9+/fH4cOHdTI4/uOPP8aECRNQoUIFHVSqbvbs2ejZsyc8PT1hbm6OdevWqQ2WDw4ORufOnbXqOykpqcAQb2hoKIVSTT18+FC62LG5uTnMzMzUjnhWqlRJq9N85R0DkYy8ePECe/fulWZETJkyRW3ml6GhIWbNmpVrNk1RFGUGm0Kh0CoQKRSKXN9AdfWNdOTIkdiwYQOuX7+ut9NP+vb6hXW1PaW1YMECeHt755qdpEv6ChdLly7FsGHD8pxGbmVlhY8//hiLFy8uU4NEvby84OXlBeDV7+Xr19lat24dXr58CTc3N8THx2vc97JlyzBv3jxMmDABv/32Gz744AOsWrUK586dK9b16Ro3boyJEyfis88+Q8+ePREYGCi9huKqUaMGqlevjoCAAHTv3h1GRkbIysrC2bNn1fZr1KiRxn3PmjULI0eO1Esgqlq1Kg4cOIAnT57A3Nw817IP4eHhGn85yaavJR+y6etvannGU2Yysnr1auzYsQPbtm0D8OrUU/369aX1Si5duoQJEyZoPfhUX3IOxs05QLm4g3F1ffqpJLxe86FDh9C1a1cMHjwYXbp00erUwvvvv1/oazU0NIStrS06deqEbt26afwchZ361JY+Ty3knBmny9mCOaWnp+Pw4cPYtWsXvv/+e61nPpmZmSE+Ph7Ozs4QQkClUiEqKqpYs+2yPXv2DJs2bUJoaCgOHjwIFxcXDBkyBAEBAcU65ff6z2z2z2HOjyZt1yHK+XNXXnz66aeIjo7GiRMn8lzyoWXLlvD29tZq7S59/00trxiIZKRt27aYOHGi9GGW8wPp559/xsqVKxEbG6tV/3ldNb5mzZrw9/fX+qrxgH4HKOeUffpp/fr1Wp9+0rdPPvkEGzduhKOjI4YMGYL+/fsXe4G5orzHWVlZuH//PmJiYvD5559j1qxZGj2HvsKFiYlJgd+kExIS0LBhQzx//lzjvgv74MimzWzB9PR0HD16VJrJd+zYMTg6OqJdu3Zo164dPD09tVoXTF/BM6e///5bWv/p7t276Ny5MwIDA3PNsCyK8+fPF2l2mjZj2JRKJZKSkoq9bERJ09eSD0DJ/k0tTxiIZMTOzg6xsbHSCrnW1tY4ceKEdP/KlSt466238OTJE437FkKga9eu2LVrFxo3bgw3NzcIIXDx4kWcO3cO3bt3x9atW3X3YvTk9u3bCAkJQWhoKNLT03Hp0qUyF4iUSiVq1KiBpk2bFhgytfmQLort27fjk08+0fiIi77CRa1atbBo0aJ8pwhv2bIFn3/+uVaTBfT1wZFzZfC2bdvC09NTJyuD51zjaNKkSZgwYUKu0Kyr8XxCCPz222/4+OOP8fjxY62P4rz11lsYOnQo+vbtW+yp+zn7trKyKvQLmTYzwfRNH0s+UP4YiGTE1NQUcXFx0jeNnC5duoQmTZrgxYsXGvcdEhKCMWPG4I8//sh1GY39+/ejR48eOr3UhC7p+vSTvpXG9PXXPX78GEOGDNE4uOgrXOjz1IK+GBkZwc7ODj169ND5yuBFWeNIV7NJo6OjERISgt9++w2Ghobo27evVmuNHTx4ECEhIdi8eTOysrLg7++PoUOH6mTcl1KpxNKlS3NdBSCnnCsslyW6XPKB8sdAJCO1a9fG3Llz4e/vn2f7pk2b8MUXXyAhIUHjvjt37oz27dtj8uTJebZ/8803iImJQUREhMZ965M+Tj9RydLnqQV9KYmVwfXln3/+QWhoKEJDQ3Ht2jW0bdsWgYGB+OCDD9Sun6aN1NRUtTFKrq6uCAwMREBAgDQrSlPldQwRlTwGIhkZM2YM9u7di1OnTuX5TbpFixbo2LEjli1bpnHftra22L17N5o0aZJn++nTp+Hr66v1BSv1pbRPP5FulPdTC7pcGVxfs0k3bdqE4OBg7Nu3D9WqVUNAQACGDBmiNnbr/PnzOruOXEJCgjRGKTExEV26dMGff/6pcT8515Iiyg8DkYwkJSWhSZMmMDY2xqhRo9SW3v/222+RkZGB06dPa/VN2tjYGDdv3sx3DMTdu3fh4uJS5q50XNqnn6j49LWadEnS5crg+ppNamxsLM3AfPfdd6XTySkpKdiwYQPWrFmDU6dO6XRmUmpqKsLCwjBlypRijU/iESIqEkGycu3aNeHj4yOUSqVQKBRCoVAIpVIpfHx8xN9//611v0qlUty/fz/f9sTERKFUKrXunyg/SqVSJCUlSfd79+4tEhMTS7GiwmVmZopjx46JefPmiS5duggLCwuhVCqFo6OjGDhwoAgJCRE3btzQqu82bdqIP//8U7pvbm6u9rv9008/idatW2vc7+vvsRBCxMTEiIEDBwozMzNRu3ZtMWnSJHH8+HGtas4pJiZGBAQECHNzc2FpaSmGDh0qYmNjddI3UX54hEimHj58KI0VcnV1LfZihCV14U6inEpqmrkuWVpaIjU1Fba2ttLK1LpaGVyfs0kTExMRGhqKtWvXIjk5Gb1798bq1atx5swZuLu7F6vuu3fvSmOTEhIS8PbbbyMwMBC9e/fONRORSB+4UrVMVa5cGS1bttRZf0WZoVEWZ5gRlQZ9rgz++PFjtVPTOS/vkJWVpdWp627duuHAgQPw8/PD0qVL0aVLFxgYGGg1qywnX19f7N27F1WrVsXAgQMxZMiQfGfDEukLAxHpBMfYUGnR56Vd9OXjjz/WW98ODg44f/58voHi7NmzWl3CY9euXRg9ejRGjhyJ2rVrF7dMNUZGRti8eTO6du2a6/IXRCWFgYiIyjUhBAYNGiSdrn3x4gVGjBihk9Wky6N3330X06ZNg5+fX56zSWfOnAk/Pz+N+z106BDWrl2L5s2bo169ehgwYAD69u2rk5q1mT1GpGscQ0RE5RovQ6BOn7NJgVczv3799VcEBwfj+PHjyMzMxOLFizFkyBCdrjBNVNIYiIiI3jDXr1/HyJEjERkZqbYuU6dOnbBq1SqdDTi/fPky1q5di59++gmPHz9Gp06deLSHyi0GIiKiN5SuZ5PmJzMzE9u2bUNwcDADEZVbDEREREQke2XvypVEREREJYyBiIiIiGSPgYiIiIhkj4GIiIiIZI+BiIiIiGSPgYiIiIhkj4GIiIiIZI+BiIiIiGTv/wBvKBJZ6zyQngAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(pdf_ticker_notnull[\"Stock_symbol\"], pdf_ticker_notnull[\"ticker_count\"])\n",
    "plt.xticks(rotation=90)\n",
    "plt.ylabel(\"Number of articles\")\n",
    "plt.title(\"Top 20 Tickers by Article Count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ticker_count_asc = df_final.groupBy(\"Stock_symbol\").agg(count(\"*\").alias(\"ticker_count\")) \\\n",
    "                   .orderBy(\"ticker_count\", ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ticker_count_notnull_asc = df_ticker_count_asc.filter(\"Stock_symbol IS NOT NULL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_ticker_notnull_asc = df_ticker_count_notnull_asc.limit(20).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(pdf_ticker_notnull_asc[\"Stock_symbol\"], pdf_ticker_notnull_asc[\"ticker_count\"])\n",
    "plt.xticks(rotation=90)\n",
    "plt.ylabel(\"Number of articles\")\n",
    "plt.title(\"Bottom 20 Tickers by Article Count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 48:===================================================>    (12 + 1) / 13]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|       article_len|\n",
      "+-------+------------------+\n",
      "|  count|            447307|\n",
      "|   mean|2784.9296366924727|\n",
      "| stddev| 2676.569892247614|\n",
      "|    min|                26|\n",
      "|    max|             87928|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_len = df_final.withColumn(\"article_len\", length(\"Article\"))\n",
    "# For a quick stats\n",
    "df_len.describe([\"article_len\"]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "pdf_len = df_len.select(\"article_len\").sample(fraction=0.1, seed=42).toPandas()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/03/24 16:48:46 WARN HeartbeatReceiver: Removing executor driver with no recent heartbeats: 14983182 ms exceeds timeout 120000 ms\n",
      "25/03/24 16:48:47 WARN NettyRpcEnv: Ignored message: true\n",
      "25/03/24 16:48:47 WARN SparkContext: Killing executors is not supported by current scheduler.\n",
      "25/03/24 16:48:47 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.199.92:33967\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/03/24 16:48:47 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.199.92:33967\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/03/24 16:48:47 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.199.92:33967\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/03/24 16:48:47 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.199.92:33967\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/03/24 16:48:48 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.199.92:33967\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/03/24 16:48:48 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.199.92:33967\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/03/24 16:48:48 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.199.92:33967\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/03/24 16:48:48 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.199.92:33967\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/03/24 16:48:48 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.199.92:33967\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/03/24 16:48:48 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.199.92:33967\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/03/24 16:48:48 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.199.92:33967\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/03/24 16:48:48 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.199.92:33967\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/03/24 16:48:48 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.199.92:33967\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "25/03/24 16:48:48 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.199.92:33967\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "25/03/24 16:48:48 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.199.92:33967\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/03/24 16:48:48 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.199.92:33967\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/03/24 16:48:48 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.199.92:33967\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "25/03/24 16:48:48 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.199.92:33967\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "25/03/24 16:48:48 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.199.92:33967\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/03/24 16:48:48 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.199.92:33967\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/03/24 16:48:48 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.199.92:33967\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/03/24 16:48:48 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.199.92:33967\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/03/24 16:48:48 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.199.92:33967\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/03/24 16:48:48 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.199.92:33967\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/03/24 16:48:48 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.199.92:33967\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/03/24 16:48:48 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.199.92:33967\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/03/24 16:48:48 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.199.92:33967\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/03/24 16:48:48 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.199.92:33967\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/03/24 16:48:48 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.199.92:33967\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/03/24 16:48:48 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.199.92:33967\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/03/24 16:48:49 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.199.92:33967\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/03/24 16:48:49 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.199.92:33967\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/03/24 16:48:49 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.199.92:33967\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/03/24 16:48:49 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.199.92:33967\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/03/24 16:48:49 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.199.92:33967\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/03/24 16:48:49 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.199.92:33967\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/03/24 16:48:49 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.199.92:33967\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/03/24 16:48:49 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.199.92:33967\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/03/24 16:48:49 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.199.92:33967\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/03/24 16:48:49 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.199.92:33967\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/03/24 16:48:49 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.199.92:33967\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/03/24 16:48:49 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.199.92:33967\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/03/24 16:48:49 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.199.92:33967\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/03/24 16:48:49 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.199.92:33967\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/03/24 16:48:49 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.199.92:33967\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/03/24 16:48:49 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.199.92:33967\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/03/24 16:48:49 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.199.92:33967\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/03/24 16:48:49 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.199.92:33967\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/03/24 16:48:49 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.199.92:33967\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/03/24 16:48:49 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.199.92:33967\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/03/24 16:48:49 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.199.92:33967\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/03/24 16:48:49 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.199.92:33967\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/03/24 16:48:49 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.199.92:33967\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/03/24 16:48:49 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.199.92:33967\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/03/24 16:48:49 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.199.92:33967\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/03/24 16:48:49 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.199.92:33967\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/03/24 16:48:49 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.199.92:33967\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/03/24 16:48:49 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.199.92:33967\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/03/24 16:48:49 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.199.92:33967\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/03/24 16:48:49 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.199.92:33967\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/03/24 16:48:49 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.199.92:33967\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/03/24 16:48:49 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.199.92:33967\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/03/24 16:48:49 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.199.92:33967\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/03/24 16:48:49 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.199.92:33967\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/03/24 16:48:49 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.199.92:33967\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/03/24 16:48:49 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.199.92:33967\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/03/24 16:48:49 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.199.92:33967\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/03/24 16:48:49 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.199.92:33967\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/03/24 16:48:49 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.199.92:33967\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/03/24 16:48:49 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.199.92:33967\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/03/24 16:48:49 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.199.92:33967\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/03/24 16:48:49 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.199.92:33967\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/03/24 16:48:49 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.199.92:33967\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/03/24 16:48:49 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.199.92:33967\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/03/24 16:48:49 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.199.92:33967\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/03/24 16:48:49 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.199.92:33967\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/03/24 16:48:49 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.199.92:33967\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/03/24 16:48:49 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.199.92:33967\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/03/24 16:48:49 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.199.92:33967\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/03/24 16:48:49 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.199.92:33967\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/03/24 16:48:49 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.199.92:33967\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "25/03/24 16:48:49 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.199.92:33967\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "25/03/24 16:48:49 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.199.92:33967\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/03/24 16:48:49 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.199.92:33967\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/03/24 16:48:49 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.199.92:33967\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/03/24 16:48:49 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.199.92:33967\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/03/24 16:48:49 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.199.92:33967\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/03/24 16:48:49 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.199.92:33967\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/03/24 16:48:49 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.199.92:33967\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/03/24 16:48:49 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.199.92:33967\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/03/24 16:48:49 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.199.92:33967\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/03/24 16:48:49 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.199.92:33967\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/03/24 16:48:49 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.199.92:33967\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/03/24 16:48:49 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.199.92:33967\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/03/24 16:48:49 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.199.92:33967\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/03/24 16:48:49 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.199.92:33967\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/03/24 16:48:50 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.199.92:33967\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/03/24 16:48:50 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.199.92:33967\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/03/24 16:48:50 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.199.92:33967\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/03/24 16:48:50 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.199.92:33967\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/03/24 16:48:50 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.199.92:33967\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/03/24 16:48:50 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.199.92:33967\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/03/24 16:48:50 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.199.92:33967\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/03/24 16:48:50 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.199.92:33967\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/03/24 16:48:50 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.199.92:33967\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/03/24 16:48:50 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.199.92:33967\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/03/24 16:48:50 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.199.92:33967\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/03/24 16:48:50 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.199.92:33967\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/03/24 16:48:50 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.199.92:33967\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/03/24 16:48:50 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.199.92:33967\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/03/24 16:48:50 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.199.92:33967\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/03/24 16:48:50 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.199.92:33967\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/03/24 16:48:50 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.199.92:33967\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/03/24 16:48:50 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.199.92:33967\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/03/24 16:48:50 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.199.92:33967\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "25/03/24 16:48:50 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.199.92:33967\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "25/03/24 16:48:50 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.199.92:33967\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/03/24 16:48:50 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.199.92:33967\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/03/24 16:48:50 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.199.92:33967\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/03/24 16:48:50 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.19.199.92:33967\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/03/24 16:48:50 ERROR Executor: Exit as unable to send heartbeats to driver more than 60 times\n"
     ]
    }
   ],
   "source": [
    "# sample 10% \n",
    "plt.hist(pdf_len[\"article_len\"], bins=100)\n",
    "plt.xlabel(\"Article Length\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.xlim(0, 10000)\n",
    "plt.title(\"Distribution of Article Lengths (sample)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quick word frecuency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 12:===================================================>    (11 + 1) / 12]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------+\n",
      "|     token|  count|\n",
      "+----------+-------+\n",
      "|        to|2844152|\n",
      "|         -|2052595|\n",
      "|        of|2007760|\n",
      "|        in|1814985|\n",
      "|       and|1608322|\n",
      "|       for|1555018|\n",
      "|       the|1452256|\n",
      "|        on|1309777|\n",
      "| announces| 648942|\n",
      "|      with| 634377|\n",
      "|        at| 631021|\n",
      "|       new| 615642|\n",
      "|       net| 570333|\n",
      "|          | 563248|\n",
      "|     asset| 548324|\n",
      "|         a| 528126|\n",
      "|  value(s)| 492053|\n",
      "|       reg| 477041|\n",
      "|        as| 475652|\n",
      "|    update| 456075|\n",
      "|   results| 455003|\n",
      "|    stocks| 387096|\n",
      "|  earnings| 386659|\n",
      "|      from| 373110|\n",
      "|      inc.| 369470|\n",
      "|         &| 366737|\n",
      "|    market| 354724|\n",
      "|      u.s.| 347582|\n",
      "|      says| 343051|\n",
      "|   quarter| 341497|\n",
      "|   reports| 325261|\n",
      "|        by| 321581|\n",
      "|    shares| 306234|\n",
      "|       plc| 296278|\n",
      "|     group| 294330|\n",
      "|        up| 290741|\n",
      "| financial| 266195|\n",
      "|       etf| 259865|\n",
      "|  research| 259020|\n",
      "|        is| 247386|\n",
      "|    global| 236389|\n",
      "|     sales| 234781|\n",
      "|     first| 229997|\n",
      "|     stock| 226567|\n",
      "|     after| 221530|\n",
      "|      bank| 221143|\n",
      "|conference| 219063|\n",
      "|   analyst| 213929|\n",
      "|    energy| 213640|\n",
      "|    report| 212429|\n",
      "+----------+-------+\n",
      "only showing top 50 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_words = df_final.withColumn(\"title_lower\", lower(\"Article_title\")) \\\n",
    "             .withColumn(\"title_tokens\", split(\"title_lower\", \"\\\\s+\")) \\\n",
    "             .select(explode(\"title_tokens\").alias(\"token\"))\n",
    "\n",
    "df_token_count = df_words.groupBy(\"token\").count().orderBy(\"count\", ascending=False)\n",
    "df_token_count.show(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Date vs Ticker Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ticker_day = df_time.groupBy(\"date_day\", \"Stock_symbol\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "pdf_ticker_day = df_ticker_day.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivoted = pdf_ticker_day.pivot(index=\"date_day\", columns=\"Stock_symbol\", values=\"count\").fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(pivoted.values, aspect='auto')\n",
    "plt.xlabel(\"Ticker\")\n",
    "plt.ylabel(\"Date\")\n",
    "plt.title(\"News Coverage Heatmap\")\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "top 20 tickers by total coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_tickers = (\n",
    "    df_time.groupBy(\"Stock_symbol\")\n",
    "      .agg(count(\"*\").alias(\"cnt\"))\n",
    "      .orderBy(\"cnt\", ascending=False)\n",
    "      .limit(20)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "top_ticker_list = [row[\"Stock_symbol\"] for row in top_tickers.collect()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub = df_time.filter(df_time[\"Stock_symbol\"].isin(top_ticker_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ticker_day_top20 = df_sub.groupBy(\"date_day\", \"Stock_symbol\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "pdf_ticker_day_top = df_ticker_day_top20.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivoted_top = pdf_ticker_day_top.pivot(index=\"date_day\", columns=\"Stock_symbol\", values=\"count\").fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(pivoted_top.values, aspect='auto')\n",
    "plt.xlabel(\"Ticker\")\n",
    "plt.ylabel(\"Date\")\n",
    "plt.title(\"News Coverage Heatmap\")\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivoted_top = pdf_ticker_day_top.pivot(index=\"date_day\", columns=\"Stock_symbol\", values=\"count\").fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12239783"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_english_only.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More heavier but accurate function based language detection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_lang(text):\n",
    "    try:\n",
    "        return langdetect.detect(text)\n",
    "    except:\n",
    "        return \"unknown\"\n",
    "\n",
    "detect_lang_udf = udf(detect_lang, StringType())\n",
    "\n",
    "df_lang = df_csv_5gb.withColumn(\"detected_lang\", detect_lang_udf(df_csv_5gb[\"Article_title\"]))\n",
    "\n",
    "df_english_only = df_lang.filter(df_lang[\"detected_lang\"] == \"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_english_only.write.mode(\"overwrite\").parquet(\"../data/raw/english_only.parquet\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bigDatavenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
