{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Setup path for custom modules\n",
    "project_root = os.path.abspath(\"..\")\n",
    "src_path = os.path.join(project_root, \"src\")\n",
    "if src_path not in sys.path:\n",
    "    sys.path.append(src_path)\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "\n",
    "# Safe imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import StringType, BooleanType\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.ml.feature import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "your 131072x1 screen size is bogus. expect trouble\n",
      "25/04/11 14:10:08 WARN Utils: Your hostname, SSMRS3-048E9600 resolves to a loopback address: 127.0.1.1; using 10.255.255.254 instead (on interface lo)\n",
      "25/04/11 14:10:08 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Ivy Default Cache set to: /home/pipe/.ivy2/cache\n",
      "The jars for the packages stored in: /home/pipe/.ivy2/jars\n",
      "com.johnsnowlabs.nlp#spark-nlp_2.12 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-e7f7aaf8-6de0-4ff2-b6bf-9a86a900f8e5;1.0\n",
      "\tconfs: [default]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/opt/spark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tfound com.johnsnowlabs.nlp#spark-nlp_2.12;5.5.3 in central\n",
      "\tfound com.typesafe#config;1.4.2 in central\n",
      "\tfound org.rocksdb#rocksdbjni;6.29.5 in central\n",
      "\tfound com.amazonaws#aws-java-sdk-s3;1.12.500 in central\n",
      "\tfound com.amazonaws#aws-java-sdk-kms;1.12.500 in central\n",
      "\tfound com.amazonaws#aws-java-sdk-core;1.12.500 in central\n",
      "\tfound commons-logging#commons-logging;1.1.3 in central\n",
      "\tfound commons-codec#commons-codec;1.15 in central\n",
      "\tfound org.apache.httpcomponents#httpclient;4.5.13 in central\n",
      "\tfound org.apache.httpcomponents#httpcore;4.4.13 in central\n",
      "\tfound software.amazon.ion#ion-java;1.0.2 in central\n",
      "\tfound joda-time#joda-time;2.8.1 in central\n",
      "\tfound com.amazonaws#jmespath-java;1.12.500 in central\n",
      "\tfound com.github.universal-automata#liblevenshtein;3.0.0 in central\n",
      "\tfound com.google.protobuf#protobuf-java-util;3.0.0-beta-3 in central\n",
      "\tfound com.google.protobuf#protobuf-java;3.0.0-beta-3 in central\n",
      "\tfound com.google.code.gson#gson;2.3 in central\n",
      "\tfound it.unimi.dsi#fastutil;7.0.12 in central\n",
      "\tfound org.projectlombok#lombok;1.16.8 in central\n",
      "\tfound com.google.cloud#google-cloud-storage;2.20.1 in central\n",
      "\tfound com.google.guava#guava;31.1-jre in central\n",
      "\tfound com.google.guava#failureaccess;1.0.1 in central\n",
      "\tfound com.google.guava#listenablefuture;9999.0-empty-to-avoid-conflict-with-guava in central\n",
      "\tfound com.google.errorprone#error_prone_annotations;2.18.0 in central\n",
      "\tfound com.google.j2objc#j2objc-annotations;1.3 in central\n",
      "\tfound com.google.http-client#google-http-client;1.43.0 in central\n",
      "\tfound io.opencensus#opencensus-contrib-http-util;0.31.1 in central\n",
      "\tfound com.google.http-client#google-http-client-jackson2;1.43.0 in central\n",
      "\tfound com.google.http-client#google-http-client-gson;1.43.0 in central\n",
      "\tfound com.google.api-client#google-api-client;2.2.0 in central\n",
      "\tfound com.google.oauth-client#google-oauth-client;1.34.1 in central\n",
      "\tfound com.google.http-client#google-http-client-apache-v2;1.43.0 in central\n",
      "\tfound com.google.apis#google-api-services-storage;v1-rev20220705-2.0.0 in central\n",
      "\tfound com.google.code.gson#gson;2.10.1 in central\n",
      "\tfound com.google.cloud#google-cloud-core;2.12.0 in central\n",
      "\tfound io.grpc#grpc-context;1.53.0 in central\n",
      "\tfound com.google.auto.value#auto-value-annotations;1.10.1 in central\n",
      "\tfound com.google.auto.value#auto-value;1.10.1 in central\n",
      "\tfound javax.annotation#javax.annotation-api;1.3.2 in central\n",
      "\tfound com.google.cloud#google-cloud-core-http;2.12.0 in central\n",
      "\tfound com.google.http-client#google-http-client-appengine;1.43.0 in central\n",
      "\tfound com.google.api#gax-httpjson;0.108.2 in central\n",
      "\tfound com.google.cloud#google-cloud-core-grpc;2.12.0 in central\n",
      "\tfound io.grpc#grpc-alts;1.53.0 in central\n",
      "\tfound io.grpc#grpc-grpclb;1.53.0 in central\n",
      "\tfound org.conscrypt#conscrypt-openjdk-uber;2.5.2 in central\n",
      "\tfound io.grpc#grpc-auth;1.53.0 in central\n",
      "\tfound io.grpc#grpc-protobuf;1.53.0 in central\n",
      "\tfound io.grpc#grpc-protobuf-lite;1.53.0 in central\n",
      "\tfound io.grpc#grpc-core;1.53.0 in central\n",
      "\tfound com.google.api#gax;2.23.2 in central\n",
      "\tfound com.google.api#gax-grpc;2.23.2 in central\n",
      "\tfound com.google.auth#google-auth-library-credentials;1.16.0 in central\n",
      "\tfound com.google.auth#google-auth-library-oauth2-http;1.16.0 in central\n",
      "\tfound com.google.api#api-common;2.6.2 in central\n",
      "\tfound io.opencensus#opencensus-api;0.31.1 in central\n",
      "\tfound com.google.api.grpc#proto-google-iam-v1;1.9.2 in central\n",
      "\tfound com.google.protobuf#protobuf-java;3.21.12 in central\n",
      "\tfound com.google.protobuf#protobuf-java-util;3.21.12 in central\n",
      "\tfound com.google.api.grpc#proto-google-common-protos;2.14.2 in central\n",
      "\tfound org.threeten#threetenbp;1.6.5 in central\n",
      "\tfound com.google.api.grpc#proto-google-cloud-storage-v2;2.20.1-alpha in central\n",
      "\tfound com.google.api.grpc#grpc-google-cloud-storage-v2;2.20.1-alpha in central\n",
      "\tfound com.google.api.grpc#gapic-google-cloud-storage-v2;2.20.1-alpha in central\n",
      "\tfound com.google.code.findbugs#jsr305;3.0.2 in central\n",
      "\tfound io.grpc#grpc-api;1.53.0 in central\n",
      "\tfound io.grpc#grpc-stub;1.53.0 in central\n",
      "\tfound org.checkerframework#checker-qual;3.31.0 in central\n",
      "\tfound io.perfmark#perfmark-api;0.26.0 in central\n",
      "\tfound com.google.android#annotations;4.1.1.4 in central\n",
      "\tfound org.codehaus.mojo#animal-sniffer-annotations;1.22 in central\n",
      "\tfound io.opencensus#opencensus-proto;0.2.0 in central\n",
      "\tfound io.grpc#grpc-services;1.53.0 in central\n",
      "\tfound com.google.re2j#re2j;1.6 in central\n",
      "\tfound io.grpc#grpc-netty-shaded;1.53.0 in central\n",
      "\tfound io.grpc#grpc-googleapis;1.53.0 in central\n",
      "\tfound io.grpc#grpc-xds;1.53.0 in central\n",
      "\tfound com.navigamez#greex;1.0 in central\n",
      "\tfound dk.brics.automaton#automaton;1.11-8 in central\n",
      "\tfound org.jsoup#jsoup;1.18.2 in central\n",
      "\tfound jakarta.mail#jakarta.mail-api;2.1.3 in central\n",
      "\tfound jakarta.activation#jakarta.activation-api;2.1.3 in central\n",
      "\tfound org.eclipse.angus#angus-mail;2.0.3 in central\n",
      "\tfound org.eclipse.angus#angus-activation;2.0.2 in central\n",
      "\tfound org.apache.poi#poi-ooxml;4.1.2 in central\n",
      "\tfound org.apache.poi#poi;4.1.2 in central\n",
      "\tfound org.apache.commons#commons-collections4;4.4 in central\n",
      "\tfound org.apache.commons#commons-math3;3.6.1 in central\n",
      "\tfound com.zaxxer#SparseBitSet;1.2 in central\n",
      "\tfound org.apache.poi#poi-ooxml-schemas;4.1.2 in central\n",
      "\tfound org.apache.xmlbeans#xmlbeans;3.1.0 in central\n",
      "\tfound org.apache.commons#commons-compress;1.19 in central\n",
      "\tfound com.github.virtuald#curvesapi;1.06 in central\n",
      "\tfound org.apache.poi#poi-scratchpad;4.1.2 in central\n",
      "\tfound com.johnsnowlabs.nlp#tensorflow-cpu_2.12;0.4.4 in central\n",
      "\tfound com.microsoft.onnxruntime#onnxruntime;1.19.2 in central\n",
      "\tfound com.johnsnowlabs.nlp#jsl-llamacpp-cpu_2.12;0.1.4 in central\n",
      "\tfound org.jetbrains#annotations;24.1.0 in central\n",
      "\tfound com.johnsnowlabs.nlp#jsl-openvino-cpu_2.12;0.1.0 in central\n",
      ":: resolution report :: resolve 744ms :: artifacts dl 29ms\n",
      "\t:: modules in use:\n",
      "\tcom.amazonaws#aws-java-sdk-core;1.12.500 from central in [default]\n",
      "\tcom.amazonaws#aws-java-sdk-kms;1.12.500 from central in [default]\n",
      "\tcom.amazonaws#aws-java-sdk-s3;1.12.500 from central in [default]\n",
      "\tcom.amazonaws#jmespath-java;1.12.500 from central in [default]\n",
      "\tcom.github.universal-automata#liblevenshtein;3.0.0 from central in [default]\n",
      "\tcom.github.virtuald#curvesapi;1.06 from central in [default]\n",
      "\tcom.google.android#annotations;4.1.1.4 from central in [default]\n",
      "\tcom.google.api#api-common;2.6.2 from central in [default]\n",
      "\tcom.google.api#gax;2.23.2 from central in [default]\n",
      "\tcom.google.api#gax-grpc;2.23.2 from central in [default]\n",
      "\tcom.google.api#gax-httpjson;0.108.2 from central in [default]\n",
      "\tcom.google.api-client#google-api-client;2.2.0 from central in [default]\n",
      "\tcom.google.api.grpc#gapic-google-cloud-storage-v2;2.20.1-alpha from central in [default]\n",
      "\tcom.google.api.grpc#grpc-google-cloud-storage-v2;2.20.1-alpha from central in [default]\n",
      "\tcom.google.api.grpc#proto-google-cloud-storage-v2;2.20.1-alpha from central in [default]\n",
      "\tcom.google.api.grpc#proto-google-common-protos;2.14.2 from central in [default]\n",
      "\tcom.google.api.grpc#proto-google-iam-v1;1.9.2 from central in [default]\n",
      "\tcom.google.apis#google-api-services-storage;v1-rev20220705-2.0.0 from central in [default]\n",
      "\tcom.google.auth#google-auth-library-credentials;1.16.0 from central in [default]\n",
      "\tcom.google.auth#google-auth-library-oauth2-http;1.16.0 from central in [default]\n",
      "\tcom.google.auto.value#auto-value;1.10.1 from central in [default]\n",
      "\tcom.google.auto.value#auto-value-annotations;1.10.1 from central in [default]\n",
      "\tcom.google.cloud#google-cloud-core;2.12.0 from central in [default]\n",
      "\tcom.google.cloud#google-cloud-core-grpc;2.12.0 from central in [default]\n",
      "\tcom.google.cloud#google-cloud-core-http;2.12.0 from central in [default]\n",
      "\tcom.google.cloud#google-cloud-storage;2.20.1 from central in [default]\n",
      "\tcom.google.code.findbugs#jsr305;3.0.2 from central in [default]\n",
      "\tcom.google.code.gson#gson;2.10.1 from central in [default]\n",
      "\tcom.google.errorprone#error_prone_annotations;2.18.0 from central in [default]\n",
      "\tcom.google.guava#failureaccess;1.0.1 from central in [default]\n",
      "\tcom.google.guava#guava;31.1-jre from central in [default]\n",
      "\tcom.google.guava#listenablefuture;9999.0-empty-to-avoid-conflict-with-guava from central in [default]\n",
      "\tcom.google.http-client#google-http-client;1.43.0 from central in [default]\n",
      "\tcom.google.http-client#google-http-client-apache-v2;1.43.0 from central in [default]\n",
      "\tcom.google.http-client#google-http-client-appengine;1.43.0 from central in [default]\n",
      "\tcom.google.http-client#google-http-client-gson;1.43.0 from central in [default]\n",
      "\tcom.google.http-client#google-http-client-jackson2;1.43.0 from central in [default]\n",
      "\tcom.google.j2objc#j2objc-annotations;1.3 from central in [default]\n",
      "\tcom.google.oauth-client#google-oauth-client;1.34.1 from central in [default]\n",
      "\tcom.google.protobuf#protobuf-java;3.21.12 from central in [default]\n",
      "\tcom.google.protobuf#protobuf-java-util;3.21.12 from central in [default]\n",
      "\tcom.google.re2j#re2j;1.6 from central in [default]\n",
      "\tcom.johnsnowlabs.nlp#jsl-llamacpp-cpu_2.12;0.1.4 from central in [default]\n",
      "\tcom.johnsnowlabs.nlp#jsl-openvino-cpu_2.12;0.1.0 from central in [default]\n",
      "\tcom.johnsnowlabs.nlp#spark-nlp_2.12;5.5.3 from central in [default]\n",
      "\tcom.johnsnowlabs.nlp#tensorflow-cpu_2.12;0.4.4 from central in [default]\n",
      "\tcom.microsoft.onnxruntime#onnxruntime;1.19.2 from central in [default]\n",
      "\tcom.navigamez#greex;1.0 from central in [default]\n",
      "\tcom.typesafe#config;1.4.2 from central in [default]\n",
      "\tcom.zaxxer#SparseBitSet;1.2 from central in [default]\n",
      "\tcommons-codec#commons-codec;1.15 from central in [default]\n",
      "\tcommons-logging#commons-logging;1.1.3 from central in [default]\n",
      "\tdk.brics.automaton#automaton;1.11-8 from central in [default]\n",
      "\tio.grpc#grpc-alts;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-api;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-auth;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-context;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-core;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-googleapis;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-grpclb;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-netty-shaded;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-protobuf;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-protobuf-lite;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-services;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-stub;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-xds;1.53.0 from central in [default]\n",
      "\tio.opencensus#opencensus-api;0.31.1 from central in [default]\n",
      "\tio.opencensus#opencensus-contrib-http-util;0.31.1 from central in [default]\n",
      "\tio.opencensus#opencensus-proto;0.2.0 from central in [default]\n",
      "\tio.perfmark#perfmark-api;0.26.0 from central in [default]\n",
      "\tit.unimi.dsi#fastutil;7.0.12 from central in [default]\n",
      "\tjakarta.activation#jakarta.activation-api;2.1.3 from central in [default]\n",
      "\tjakarta.mail#jakarta.mail-api;2.1.3 from central in [default]\n",
      "\tjavax.annotation#javax.annotation-api;1.3.2 from central in [default]\n",
      "\tjoda-time#joda-time;2.8.1 from central in [default]\n",
      "\torg.apache.commons#commons-collections4;4.4 from central in [default]\n",
      "\torg.apache.commons#commons-compress;1.19 from central in [default]\n",
      "\torg.apache.commons#commons-math3;3.6.1 from central in [default]\n",
      "\torg.apache.httpcomponents#httpclient;4.5.13 from central in [default]\n",
      "\torg.apache.httpcomponents#httpcore;4.4.13 from central in [default]\n",
      "\torg.apache.poi#poi;4.1.2 from central in [default]\n",
      "\torg.apache.poi#poi-ooxml;4.1.2 from central in [default]\n",
      "\torg.apache.poi#poi-ooxml-schemas;4.1.2 from central in [default]\n",
      "\torg.apache.poi#poi-scratchpad;4.1.2 from central in [default]\n",
      "\torg.apache.xmlbeans#xmlbeans;3.1.0 from central in [default]\n",
      "\torg.checkerframework#checker-qual;3.31.0 from central in [default]\n",
      "\torg.codehaus.mojo#animal-sniffer-annotations;1.22 from central in [default]\n",
      "\torg.conscrypt#conscrypt-openjdk-uber;2.5.2 from central in [default]\n",
      "\torg.eclipse.angus#angus-activation;2.0.2 from central in [default]\n",
      "\torg.eclipse.angus#angus-mail;2.0.3 from central in [default]\n",
      "\torg.jetbrains#annotations;24.1.0 from central in [default]\n",
      "\torg.jsoup#jsoup;1.18.2 from central in [default]\n",
      "\torg.projectlombok#lombok;1.16.8 from central in [default]\n",
      "\torg.rocksdb#rocksdbjni;6.29.5 from central in [default]\n",
      "\torg.threeten#threetenbp;1.6.5 from central in [default]\n",
      "\tsoftware.amazon.ion#ion-java;1.0.2 from central in [default]\n",
      "\t:: evicted modules:\n",
      "\tcommons-logging#commons-logging;1.2 by [commons-logging#commons-logging;1.1.3] in [default]\n",
      "\tcommons-codec#commons-codec;1.11 by [commons-codec#commons-codec;1.15] in [default]\n",
      "\tcom.google.protobuf#protobuf-java-util;3.0.0-beta-3 by [com.google.protobuf#protobuf-java-util;3.21.12] in [default]\n",
      "\tcom.google.protobuf#protobuf-java;3.0.0-beta-3 by [com.google.protobuf#protobuf-java;3.21.12] in [default]\n",
      "\tcom.google.code.gson#gson;2.3 by [com.google.code.gson#gson;2.10.1] in [default]\n",
      "\tcommons-codec#commons-codec;1.13 by [commons-codec#commons-codec;1.15] in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |  102  |   0   |   0   |   6   ||   96  |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-e7f7aaf8-6de0-4ff2-b6bf-9a86a900f8e5\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 96 already retrieved (0kB/9ms)\n",
      "25/04/11 14:10:09 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Spark NLP\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .config(\"spark.driver.memory\", \"16G\") \\\n",
    "    .config(\"spark.serializer\", \"org.apache.spark.serializer.KryoSerializer\") \\\n",
    "    .config(\"spark.kryoserializer.buffer.max\", \"2000M\") \\\n",
    "    .config(\"spark.driver.maxResultSize\", \"0\") \\\n",
    "    .config(\"spark.jars.packages\", \"com.johnsnowlabs.nlp:spark-nlp_2.12:5.5.3\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 14:10:17.779162: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-11 14:10:17.788721: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1744373417.799199   30482 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1744373417.802346   30482 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1744373417.810969   30482 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744373417.810981   30482 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744373417.810982   30482 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744373417.810983   30482 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-04-11 14:10:17.815250: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from src.models.fine_tuning import * \n",
    "from src.models.inference import apply_inference_to_dataframe\n",
    "from src.data.NLP_preprocessing import PreprocessingPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = spark.sparkContext\n",
    "sc.addPyFile(\"../src.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.conf.set(\"spark.sql.legacy.timeParserPolicy\", \"LEGACY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#spark = sparknlp.start()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_csv_analyst = spark.read.option(\"header\", True) \\\n",
    "    .option(\"multiLine\", True) \\\n",
    "    .option(\"quote\", '\"') \\\n",
    "    .option(\"escape\", '\"') \\\n",
    "    .option(\"mode\", \"DROPMALFORMED\") \\\n",
    "    .csv(\"../data/raw/analyst_ratings_processed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 7:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+--------------------+-----+\n",
      "|     id|               title|                date|stock|\n",
      "+-------+--------------------+--------------------+-----+\n",
      "| 883755|How Treasuries an...|2009-02-14 14:02:...|  NAV|\n",
      "| 522587|Update on the Lux...|2009-04-27 14:39:...|   FT|\n",
      "|1396488|Update on the Lux...|2009-04-27 14:39:...|    Y|\n",
      "|   1834|Going Against the...|2009-04-29 08:48:...|    A|\n",
      "|  68387|Charles Sizemore ...|2009-05-22 14:28:...|   AM|\n",
      "| 561526|JVA perks to 39% ...|2009-05-27 03:32:...| GMCR|\n",
      "| 430148|JVA perks to 39% ...|2009-05-27 03:32:...|  EPS|\n",
      "| 714847|JVA perks to 39% ...|2009-05-27 03:32:...|  JVA|\n",
      "| 714846|MRM a $15-$20+ st...|2009-05-27 21:35:...|  JVA|\n",
      "| 430147|MRM a $15-$20+ st...|2009-05-27 21:35:...|  EPS|\n",
      "|1081067|MRM a $15-$20+ st...|2009-05-27 21:35:...|   RF|\n",
      "| 430146|In $7.60 UTA - Ne...|2009-05-29 07:47:...|  EPS|\n",
      "|1048384|In $7.60 UTA - Ne...|2009-05-29 07:47:...|    Q|\n",
      "| 365056|Saturday super-tr...|2009-05-30 09:32:...|  DIT|\n",
      "| 430145|Saturday super-tr...|2009-05-30 09:32:...|  EPS|\n",
      "| 945088|Saturday super-tr...|2009-05-30 09:32:...| OCLS|\n",
      "| 522586|A Contrarian's Dr...|2009-06-01 10:54:...|   FT|\n",
      "| 430144|super-trades - Tw...|2009-06-01 22:15:...|  EPS|\n",
      "|   1833|super-trades - Tw...|2009-06-01 22:15:...|    A|\n",
      "| 365055|super-trades - Tw...|2009-06-01 22:15:...|  DIT|\n",
      "+-------+--------------------+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_csv_analyst.sort(asc(\"date\")).show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lemma_antbnc download started this may take some time.\n",
      "Approximate size to download 907.6 KB\n",
      "[ | ]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/04/11 13:34:02 WARN S3AbortableInputStream: Not all bytes were read from the S3ObjectInputStream, aborting HTTP connection. This is likely an error and may result in sub-optimal behavior. Request only the bytes you need via a ranged GET or drain the input stream after use.\n",
      "25/04/11 13:34:03 WARN S3AbortableInputStream: Not all bytes were read from the S3ObjectInputStream, aborting HTTP connection. This is likely an error and may result in sub-optimal behavior. Request only the bytes you need via a ranged GET or drain the input stream after use.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lemma_antbnc download started this may take some time.\n",
      "Approximate size to download 907.6 KB\n",
      "Download done! Loading the resource.\n",
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "preproc = PreprocessingPipeline(spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nlp_analyst = preproc.run(df_csv_analyst, text_col=\"title\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_nlp_analyst.write.mode(\"overwrite\").parquet(\"../data/processed/processed_news_analyst.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "nlp_analyst = spark.read.parquet(\"../data/processed/processed_news_analyst.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+--------------------+-----+--------------------+--------------------+\n",
      "| id|            raw_text|                date|stock|     finished_tokens|          final_text|\n",
      "+---+--------------------+--------------------+-----+--------------------+--------------------+\n",
      "|  0|Stocks That Hit 5...|2020-06-05 10:30:...|    A|[stock, hit, 52we...|stock hit 52week ...|\n",
      "|  1|Stocks That Hit 5...|2020-06-03 10:45:...|    A|[stock, hit, 52we...|stock hit 52week ...|\n",
      "|  2|71 Biggest Movers...|2020-05-26 04:30:...|    A|[71, big, mover, ...| 71 big mover friday|\n",
      "|  3|46 Stocks Moving ...|2020-05-22 12:45:...|    A|[46, stock, move,...|46 stock move fri...|\n",
      "|  4|B of A Securities...|2020-05-22 11:38:...|    A|[b, security, mai...|b security mainta...|\n",
      "|  5|CFRA Maintains Ho...|2020-05-22 11:23:...|    A|[cfra, maintain, ...|cfra maintain hol...|\n",
      "|  6|UBS Maintains Neu...|2020-05-22 09:36:...|    A|[ubs, maintain, n...|ubs maintain neut...|\n",
      "|  7|Agilent Technolog...|2020-05-22 09:07:...|    A|[agilent, technol...|agilent technolog...|\n",
      "|  8|Wells Fargo Maint...|2020-05-22 08:37:...|    A|[well, fargo, mai...|well fargo mainta...|\n",
      "|  9|10 Biggest Price ...|2020-05-22 08:06:...|    A|[10, big, price, ...|10 big price targ...|\n",
      "+---+--------------------+--------------------+-----+--------------------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nlp_analyst.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_analyst_sentiment = apply_inference_to_dataframe(nlp_analyst, text_column=\"final_text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 14:10:46.978565: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-11 14:10:46.999420: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1744373447.022300   31450 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1744373447.029595   31450 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1744373447.054624   31450 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744373447.055071   31450 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744373447.055155   31450 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744373447.055212   31450 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-04-11 14:10:47.060464: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-04-11 14:10:47.118953: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-11 14:10:47.145856: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-04-11 14:10:47.162603: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-11 14:10:47.178210: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1744373447.178704   31434 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-04-11 14:10:47.182732: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-04-11 14:10:47.183651: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "E0000 00:00:1744373447.188626   31434 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-04-11 14:10:47.196814: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-04-11 14:10:47.207538: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1744373447.208199   31458 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1744373447.215587   31458 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1744373447.215686   31434 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744373447.215747   31434 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744373447.215760   31434 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744373447.215771   31434 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1744373447.219460   31453 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-04-11 14:10:47.222113: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-11 14:10:47.223068: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "E0000 00:00:1744373447.226659   31453 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1744373447.233626   31458 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744373447.234115   31458 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744373447.234296   31458 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744373447.234372   31458 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-04-11 14:10:47.240457: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1744373447.242438   31438 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "W0000 00:00:1744373447.244371   31453 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744373447.244541   31453 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744373447.244585   31453 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744373447.244608   31453 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-04-11 14:10:47.246524: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-04-11 14:10:47.249837: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "E0000 00:00:1744373447.252128   31438 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-04-11 14:10:47.266404: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "W0000 00:00:1744373447.276382   31438 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744373447.276579   31438 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744373447.276617   31438 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744373447.276646   31438 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1744373447.278865   31446 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-04-11 14:10:47.283474: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-04-11 14:10:47.284199: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "E0000 00:00:1744373447.288684   31446 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-04-11 14:10:47.291074: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-11 14:10:47.304776: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-11 14:10:47.308876: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "W0000 00:00:1744373447.312797   31446 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744373447.313004   31446 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744373447.313054   31446 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744373447.313085   31446 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1744373447.317742   31467 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-04-11 14:10:47.320021: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-04-11 14:10:47.325180: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "E0000 00:00:1744373447.327505   31467 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1744373447.331285   31426 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-04-11 14:10:47.339116: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-11 14:10:47.339324: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "E0000 00:00:1744373447.340334   31426 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-04-11 14:10:47.347681: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "W0000 00:00:1744373447.351351   31467 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744373447.351546   31467 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744373447.351657   31467 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744373447.351703   31467 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-04-11 14:10:47.357742: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1744373447.358010   31442 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "W0000 00:00:1744373447.358424   31426 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744373447.358549   31426 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744373447.358575   31426 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744373447.358590   31426 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-04-11 14:10:47.358645: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-04-11 14:10:47.362594: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-04-11 14:10:47.363595: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-04-11 14:10:47.365584: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "E0000 00:00:1744373447.367933   31442 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-04-11 14:10:47.384537: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-11 14:10:47.384531: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1744373447.387346   31422 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1744373447.389462   31465 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "W0000 00:00:1744373447.392211   31442 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744373447.392383   31442 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744373447.392421   31442 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744373447.392449   31442 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1744373447.392760   31498 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1744373447.393996   31422 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-04-11 14:10:47.395857: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-11 14:10:47.396365: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "E0000 00:00:1744373447.397393   31465 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-04-11 14:10:47.399232: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "E0000 00:00:1744373447.400128   31498 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-04-11 14:10:47.402212: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-11 14:10:47.402245: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-11 14:10:47.402623: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-11 14:10:47.402977: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-11 14:10:47.405725: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-11 14:10:47.407611: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-04-11 14:10:47.409277: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "W0000 00:00:1744373447.411545   31422 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744373447.411679   31422 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744373447.411702   31422 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744373447.411717   31422 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-04-11 14:10:47.412714: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-11 14:10:47.413972: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "W0000 00:00:1744373447.415019   31465 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744373447.415121   31465 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744373447.415158   31465 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744373447.415173   31465 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-04-11 14:10:47.415878: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-04-11 14:10:47.416802: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "W0000 00:00:1744373447.416901   31498 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744373447.416989   31498 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744373447.417024   31498 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744373447.417038   31498 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-04-11 14:10:47.419341: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-04-11 14:10:47.420374: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-04-11 14:10:47.423454: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-04-11 14:10:47.424547: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-04-11 14:10:47.424745: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-04-11 14:10:47.424808: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-04-11 14:10:47.425529: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-04-11 14:10:47.426491: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-04-11 14:10:47.430971: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-11 14:10:47.434962: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-04-11 14:10:47.434958: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1744373447.435894   31400 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1744373447.437737   31418 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1744373447.439512   31472 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1744373447.439714   31480 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1744373447.441877   31400 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1744373447.444703   31479 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1744373447.445134   31418 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "E0000 00:00:1744373447.447665   31472 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1744373447.448944   31462 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1744373447.449111   31480 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "E0000 00:00:1744373447.452215   31479 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1744373447.452771   31414 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-04-11 14:10:47.455256: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "E0000 00:00:1744373447.455560   31462 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1744373447.457645   31489 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1744373447.457839   31494 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1744373447.458094   31476 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "W0000 00:00:1744373447.458568   31400 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744373447.458643   31400 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744373447.458670   31400 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744373447.458687   31400 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "E0000 00:00:1744373447.459409   31414 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1744373447.463071   31418 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744373447.463276   31418 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744373447.463303   31418 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744373447.463317   31418 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-04-11 14:10:47.463965: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "W0000 00:00:1744373447.464014   31472 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744373447.464052   31472 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744373447.464058   31472 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744373447.464064   31472 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "E0000 00:00:1744373447.464415   31489 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1744373447.464469   31497 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1744373447.467696   31494 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "E0000 00:00:1744373447.467968   31476 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-04-11 14:10:47.468276: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-04-11 14:10:47.468555: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "W0000 00:00:1744373447.469539   31479 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744373447.469657   31479 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744373447.469696   31479 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744373447.469713   31479 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "E0000 00:00:1744373447.471772   31497 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1744373447.472332   31462 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744373447.472452   31462 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744373447.472478   31462 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744373447.472493   31462 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744373447.472575   31480 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744373447.472684   31480 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744373447.472731   31480 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744373447.472765   31480 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-04-11 14:10:47.475142: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "W0000 00:00:1744373447.476428   31414 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744373447.476600   31414 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744373447.476627   31414 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744373447.476643   31414 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-04-11 14:10:47.478629: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-04-11 14:10:47.479487: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "W0000 00:00:1744373447.482913   31489 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744373447.483091   31489 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744373447.483117   31489 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744373447.483132   31489 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-04-11 14:10:47.483121: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-04-11 14:10:47.488273: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1744373447.488474   31428 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "W0000 00:00:1744373447.489594   31476 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744373447.489683   31476 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744373447.489707   31476 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744373447.489721   31476 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744373447.492473   31494 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744373447.492652   31494 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744373447.492691   31494 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744373447.492729   31494 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-04-11 14:10:47.495388: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "E0000 00:00:1744373447.498199   31428 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1744373447.499175   31497 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744373447.499232   31497 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744373447.499241   31497 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744373447.499247   31497 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-04-11 14:10:47.499789: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-04-11 14:10:47.504785: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "W0000 00:00:1744373447.522789   31428 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744373447.522988   31428 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744373447.523030   31428 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744373447.523058   31428 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-04-11 14:10:47.529857: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-04-11 14:10:47.535441: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-11 14:10:47.540733: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-11 14:10:47.554843: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-04-11 14:10:47.564884: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1744373447.581802   31399 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1744373447.597350   31399 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1744373447.598272   31483 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1744373447.608717   31483 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1744373447.624472   31399 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744373447.624770   31399 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744373447.624817   31399 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744373447.625646   31399 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-04-11 14:10:47.632481: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "W0000 00:00:1744373447.635358   31483 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744373447.635555   31483 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744373447.635593   31483 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744373447.635622   31483 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-04-11 14:10:47.642592: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-04-11 14:10:47.916211: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-11 14:10:47.934424: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-04-11 14:10:47.946870: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1744373447.957271   31409 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1744373447.964542   31409 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-04-11 14:10:47.966428: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "W0000 00:00:1744373447.985374   31409 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744373447.985897   31409 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744373447.986055   31409 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744373447.986184   31409 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-04-11 14:10:47.991770: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1744373447.992693   31405 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1744373448.000014   31405 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1744373448.020193   31405 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744373448.020606   31405 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744373448.020719   31405 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744373448.020931   31405 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-04-11 14:10:48.026306: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at /home/pipe/BigData/project/Financial-News-SA/src/models/finetuned_distilroberta and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight', 'embeddings.LayerNorm.bias', 'embeddings.LayerNorm.weight', 'embeddings.position_embeddings.weight', 'embeddings.token_type_embeddings.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Device set to use cuda:0\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at /home/pipe/BigData/project/Financial-News-SA/src/models/finetuned_distilroberta and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight', 'embeddings.LayerNorm.bias', 'embeddings.LayerNorm.weight', 'embeddings.position_embeddings.weight', 'embeddings.token_type_embeddings.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Device set to use cuda:0\n",
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_analyst_sentiment.write.partitionBy(\"stock\").mode(\"overwrite\").parquet(\"../data/processed/sentiment_analyst.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "SA_analyst = spark.read.parquet(\"../data/processed/sentiment_analyst.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 6:===================================>                  (127 + 28) / 194]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+--------------------+--------------------+--------------------+-------------------+-----+\n",
      "|     id|            raw_text|                date|     finished_tokens|          final_text|predicted_sentiment|stock|\n",
      "+-------+--------------------+--------------------+--------------------+--------------------+-------------------+-----+\n",
      "|1329386|Emerging Companie...|2020-03-02 09:03:...|[emerge, company,...|emerge company po...|            LABEL_2| VSLR|\n",
      "|1358434|10 Ways to Build ...|2011-05-22 18:00:...|[10, way, build, ...|10 way build defe...|            LABEL_2|  WIP|\n",
      "|1120937|Unheralded $1B ET...|2012-07-20 06:35:...|[unheralded, 1b, ...|unheralded 1b etf...|            LABEL_2| SCPB|\n",
      "|1047206|More Tech ETFs Th...|2012-02-27 14:51:...|[tech, etfs, dont...|tech etfs dont ne...|            LABEL_2|  PXQ|\n",
      "|1373624|WVFC Trading Resu...|2015-03-25 10:53:...|[wvfc, trade, res...|wvfc trade resume...|            LABEL_2| WVFC|\n",
      "|1379591|This Dead Money S...|2013-03-25 08:21:...|[dead, money, sec...|dead money sector...|            LABEL_2|  XHS|\n",
      "|1358807|Some Low Volume C...|2012-10-02 12:47:...|[low, volume, com...|low volume commod...|            LABEL_2| WITE|\n",
      "|1236219|Bill Gross Versus...|2011-05-17 10:06:...|[bill, gross, ver...|bill gross versus...|            LABEL_2|  TLO|\n",
      "|1330682|This Day In Marke...|2019-01-29 07:30:...|[day, market, his...|day market histor...|            LABEL_2| VTIP|\n",
      "|1358811|ETF Securities Re...|2011-05-02 03:24:...|[etf, security, r...|etf security repo...|            LABEL_2| WITE|\n",
      "|1037559|5 Best ETFs Of Th...|2018-07-02 13:02:...|[5, good, etfs, f...|5 good etfs first...|            LABEL_2| PSCH|\n",
      "|1330684|Try This Approach...|2016-05-23 08:53:...|[try, approach, t...|try approach tip ...|            LABEL_2| VTIP|\n",
      "|1326204|Morning Market Lo...|2012-12-24 09:54:...|[morning, market,...|morning market loser|            LABEL_2| VRTB|\n",
      "| 705297|ETFs To Play/Avoi...|2011-08-25 12:25:...|[etfs, playavoid,...|etfs playavoid sh...|            LABEL_2|  JKE|\n",
      "|  21665|Unheralded $1B ET...|2012-07-20 06:35:...|[unheralded, 1b, ...|unheralded 1b etf...|            LABEL_2| ACWI|\n",
      "|1079623|ETFs To Play/Avoi...|2011-08-25 12:25:...|[etfs, playavoid,...|etfs playavoid sh...|            LABEL_2|  REW|\n",
      "| 392451|These ETFs House ...|2013-08-26 07:44:...|[etfs, house, nex...|etfs house next b...|            LABEL_2| DWAS|\n",
      "| 196057|Cordia Bancorp Re...|2016-05-16 16:01:...|[cordia, bancorp,...|cordia bancorp re...|            LABEL_2|  BVA|\n",
      "|1395478|Better A Way To E...|2019-05-17 13:48:...|[well, way, emerg...|well way emerge m...|            LABEL_2| XSOE|\n",
      "| 196058|Cordia Bancorp Re...|2016-03-03 16:08:...|[cordia, bancorp,...|cordia bancorp re...|            LABEL_2|  BVA|\n",
      "+-------+--------------------+--------------------+--------------------+--------------------+-------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "SA_analyst.sort(desc(\"predicted_sentiment\")).show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6192"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SA_analyst.select(\"stock\").distinct().count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "SA_analyst_final = SA_analyst.withColumn(\n",
    "    \"sentiment_numeric\",\n",
    "    when(col(\"predicted_sentiment\") == \"LABEL_0\", 0)\n",
    "    .when(col(\"predicted_sentiment\") == \"LABEL_1\", 1)\n",
    "    .when(col(\"predicted_sentiment\") == \"LABEL_2\", 2)\n",
    "    .otherwise(-1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# If you want to keep the full timestamp (if later you need intraday ordering)\n",
    "SA_analyst_final = SA_analyst_final.withColumn(\"news_timestamp\", to_timestamp(\"date\", \"yyyy-MM-dd HH:mm:ss\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "SA_analyst_final = SA_analyst_final.withColumn(\"news_date\", to_date(\"date\", \"yyyy-MM-dd\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.describe of DataFrame[id: string, raw_text: string, date: string, finished_tokens: array<string>, final_text: string, predicted_sentiment: string, stock: string, sentiment_numeric: int, news_timestamp: timestamp, news_date: date]>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SA_analyst_final.describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+--------------------+--------------------+--------------------+-------------------+-----+-----------------+-------------------+----------+\n",
      "|    id|            raw_text|                date|     finished_tokens|          final_text|predicted_sentiment|stock|sentiment_numeric|     news_timestamp| news_date|\n",
      "+------+--------------------+--------------------+--------------------+--------------------+-------------------+-----+-----------------+-------------------+----------+\n",
      "|850715|Shares of several...|2020-06-11 10:22:...|[share, several, ...|share several hea...|            LABEL_0|  MRK|                0|2020-06-11 10:22:00|2020-06-11|\n",
      "|850716|Johnson & Johnson...|2020-06-11 00:16:...|[johnson, johnson...|johnson johnson s...|            LABEL_0|  MRK|                0|2020-06-11 00:16:00|2020-06-11|\n",
      "|850717|The Daily Biotech...|2020-06-10 07:30:...|[daily, biotech, ...|daily biotech pul...|            LABEL_0|  MRK|                0|2020-06-10 07:30:00|2020-06-10|\n",
      "|850718|Merck Announces T...|2020-06-09 16:13:...|[merck, announce,...|merck announce ph...|            LABEL_0|  MRK|                0|2020-06-09 16:13:00|2020-06-09|\n",
      "|850719|The Week Ahead In...|2020-06-07 13:43:...|[week, ahead, bio...|week ahead biotec...|            LABEL_0|  MRK|                0|2020-06-07 13:43:00|2020-06-07|\n",
      "|850720|The Daily Biotech...|2020-06-05 07:34:...|[daily, biotech, ...|daily biotech pul...|            LABEL_0|  MRK|                0|2020-06-05 07:34:00|2020-06-05|\n",
      "|850721|Merck Reports FDA...|2020-06-05 06:52:...|[merck, report, f...|merck report fda ...|            LABEL_0|  MRK|                0|2020-06-05 06:52:00|2020-06-05|\n",
      "|850722|Ex-FDA Chief On W...|2020-06-04 11:02:...|[exfda, chief, wh...|exfda chief white...|            LABEL_0|  MRK|                0|2020-06-04 11:02:00|2020-06-04|\n",
      "|850723|The Daily Biotech...|2020-06-04 08:13:...|[daily, biotech, ...|daily biotech pul...|            LABEL_0|  MRK|                0|2020-06-04 08:13:00|2020-06-04|\n",
      "|850724|Revisiting The Co...|2020-06-03 17:53:...|[revisit, coronav...|revisit coronavir...|            LABEL_0|  MRK|                0|2020-06-03 17:53:00|2020-06-03|\n",
      "|850725|Traders Share The...|2020-06-03 17:17:...|[trader, share, h...|trader share heal...|            LABEL_0|  MRK|                0|2020-06-03 17:17:00|2020-06-03|\n",
      "|850726|UPDATE: Five Comp...|2020-06-03 13:09:...|[update, five, co...|update five compa...|            LABEL_0|  MRK|                0|2020-06-03 13:09:00|2020-06-03|\n",
      "|850727|Pharma Large And ...|2020-06-02 14:50:...|[pharma, large, m...|pharma large midc...|            LABEL_0|  MRK|                0|2020-06-02 14:50:00|2020-06-02|\n",
      "|850728|Attention Biotech...|2020-06-01 16:00:...|[attention, biote...|attention biotech...|            LABEL_0|  MRK|                0|2020-06-01 16:00:00|2020-06-01|\n",
      "|850729|'New Ebola epidem...|2020-06-01 08:39:...|[new, ebola, epid...|new ebola epidemi...|            LABEL_0|  MRK|                0|2020-06-01 08:39:00|2020-06-01|\n",
      "|850730|Merck and AstraZe...|2020-06-01 06:46:...|[merck, astrazene...|merck astrazeneca...|            LABEL_0|  MRK|                0|2020-06-01 06:46:00|2020-06-01|\n",
      "|850731|AstraZeneca Annou...|2020-06-01 05:31:...|[astrazeneca, ann...|astrazeneca annou...|            LABEL_0|  MRK|                0|2020-06-01 05:31:00|2020-06-01|\n",
      "|850732|The Week Ahead In...|2020-05-30 09:25:...|[week, ahead, bio...|week ahead biotec...|            LABEL_0|  MRK|                0|2020-05-30 09:25:00|2020-05-30|\n",
      "|850733|Merck Yesterday A...|2020-05-29 09:55:...|[merck, yesterday...|merck yesterday a...|            LABEL_0|  MRK|                0|2020-05-29 09:55:00|2020-05-29|\n",
      "|850734|The Daily Biotech...|2020-05-29 07:22:...|[daily, biotech, ...|daily biotech pul...|            LABEL_0|  MRK|                0|2020-05-29 07:22:00|2020-05-29|\n",
      "+------+--------------------+--------------------+--------------------+--------------------+-------------------+-----+-----------------+-------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "SA_analyst_final.show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_news_agg = SA_analyst_final.groupBy(\"stock\", \"news_date\") \\\n",
    "    .agg(avg(\"sentiment_numeric\").alias(\"avg_sentiment\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 36:========================================>            (150 + 29) / 194]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+-------------+\n",
      "|stock| news_date|avg_sentiment|\n",
      "+-----+----------+-------------+\n",
      "|  MRK|2019-10-01|          0.0|\n",
      "|  MRK|2014-11-21|          0.0|\n",
      "|  MRK|2014-10-08|          0.0|\n",
      "|  MRK|2014-05-02|          0.0|\n",
      "|  MRK|2010-02-25|          0.0|\n",
      "| NFLX|2019-11-09|          0.0|\n",
      "| NFLX|2019-08-29|          0.0|\n",
      "| NFLX|2018-08-02|          0.0|\n",
      "| NFLX|2018-03-11|          0.0|\n",
      "| NFLX|2018-02-02|          0.0|\n",
      "| NFLX|2017-12-11|          0.0|\n",
      "|  JNJ|2019-10-14|          0.0|\n",
      "|  JNJ|2019-09-27|          0.0|\n",
      "|  JNJ|2019-06-19|          0.0|\n",
      "|  JNJ|2018-10-19|          0.0|\n",
      "|  JNJ|2017-11-06|          0.0|\n",
      "|  JNJ|2015-01-08|          0.0|\n",
      "|  JNJ|2014-09-30|          0.0|\n",
      "|  JNJ|2014-08-22|          0.0|\n",
      "|  JNJ|2014-01-23|          0.0|\n",
      "+-----+----------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_news_agg.show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column 'effective_date' that corresponds to the next day (i.e., news_date + 1 day)\n",
    "df_news_agg = df_news_agg.withColumn(\"effective_date\", date_add(col(\"news_date\"), 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 48:================================================>    (177 + 17) / 194]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+-------------+----------+--------------+\n",
      "|stock| news_date|avg_sentiment| join_date|effective_date|\n",
      "+-----+----------+-------------+----------+--------------+\n",
      "|  MRK|2019-10-01|          0.0|2019-10-02|    2019-10-02|\n",
      "|  MRK|2014-11-21|          0.0|2014-11-22|    2014-11-22|\n",
      "|  MRK|2014-10-08|          0.0|2014-10-09|    2014-10-09|\n",
      "|  MRK|2014-05-02|          0.0|2014-05-03|    2014-05-03|\n",
      "|  MRK|2010-02-25|          0.0|2010-02-26|    2010-02-26|\n",
      "| NFLX|2019-11-09|          0.0|2019-11-10|    2019-11-10|\n",
      "| NFLX|2019-08-29|          0.0|2019-08-30|    2019-08-30|\n",
      "| NFLX|2018-08-02|          0.0|2018-08-03|    2018-08-03|\n",
      "| NFLX|2018-03-11|          0.0|2018-03-12|    2018-03-12|\n",
      "| NFLX|2018-02-02|          0.0|2018-02-03|    2018-02-03|\n",
      "| NFLX|2017-12-11|          0.0|2017-12-12|    2017-12-12|\n",
      "|  JNJ|2019-10-14|          0.0|2019-10-15|    2019-10-15|\n",
      "|  JNJ|2019-09-27|          0.0|2019-09-28|    2019-09-28|\n",
      "|  JNJ|2019-06-19|          0.0|2019-06-20|    2019-06-20|\n",
      "|  JNJ|2018-10-19|          0.0|2018-10-20|    2018-10-20|\n",
      "|  JNJ|2017-11-06|          0.0|2017-11-07|    2017-11-07|\n",
      "|  JNJ|2015-01-08|          0.0|2015-01-09|    2015-01-09|\n",
      "|  JNJ|2014-09-30|          0.0|2014-10-01|    2014-10-01|\n",
      "|  JNJ|2014-08-22|          0.0|2014-08-23|    2014-08-23|\n",
      "|  JNJ|2014-01-23|          0.0|2014-01-24|    2014-01-24|\n",
      "+-----+----------+-------------+----------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_news_agg.show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_prices = spark.read \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .csv(\"../data/raw/price_data/*.csv\") \\\n",
    "    .withColumn(\"file_path\", input_file_name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prices = df_prices.withColumn(\"ticker\",\n",
    "    regexp_extract(col(\"file_path\"), r\"([^/\\\\]+)_historical\\.csv$\", 1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prices_clean = df_prices.filter(col(\"Date\").isNotNull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 29:================================================>    (105 + 10) / 115]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+------------------+------------------+------------------+---------+--------------------+------+\n",
      "|      Date|             Close|              High|               Low|              Open|   Volume|           file_path|ticker|\n",
      "+----------+------------------+------------------+------------------+------------------+---------+--------------------+------+\n",
      "|2020-06-10| 35.38862228393555|37.386511182506446| 35.36174594293514| 37.37755354138716|  2091100|file:///home/pipe...|   TAP|\n",
      "|2020-06-10|  48.5067253112793|50.072545171702956|48.077389161497884|50.047291048585954|  2498900|file:///home/pipe...|   QSR|\n",
      "|2020-06-10|15.153594017028809|16.112681923785726|15.128573751550041|16.104341835292804|  4586100|file:///home/pipe...|   UNM|\n",
      "|2020-06-10|103.48999786376953|104.63999938964844|102.16000366210938| 103.4000015258789|  1415900|file:///home/pipe...|  KEYS|\n",
      "|2020-06-10| 7.216312885284424| 7.819087288088239| 7.216312885284424| 7.776638226833336|  2643400|file:///home/pipe...|  PGRE|\n",
      "|2020-06-10| 27.61338996887207| 28.02082540823069|27.590325719312116|27.951638841338436| 29557217|file:///home/pipe...|   PFE|\n",
      "|2020-06-10| 9.420000076293945| 9.729999542236328| 9.069999694824219| 9.729999542236328|  8591780|file:///home/pipe...|    UA|\n",
      "|2020-06-10| 82.87000274658203|  83.2699966430664| 80.33000183105469|             82.25|   222300|file:///home/pipe...|  USNA|\n",
      "|2020-06-10|  47.6754035949707|  47.9545517220999| 47.47238413506187| 47.75153548907591|  1061000|file:///home/pipe...|    UL|\n",
      "|2020-06-10| 9.758442878723145|10.234701324461374| 9.680686435620164|10.118066659806905| 10960500|file:///home/pipe...|     X|\n",
      "|2020-06-10|12.050000190734863|12.640000343322754|12.050000190734863|12.640000343322754| 12645700|file:///home/pipe...|  TEVA|\n",
      "|2020-06-10|100.08702087402344| 101.9058071166856|  100.033077290467|101.84415115668638|  4952601|file:///home/pipe...|   IBM|\n",
      "|2020-06-10|32.637840270996094| 33.13069631670322|  32.4187969377246| 32.78719127845048|  3277800|file:///home/pipe...|    IR|\n",
      "|2020-06-10|18.200000762939453|19.299999237060547|              18.0|              19.0|   576220|file:///home/pipe...|  CANF|\n",
      "|2020-06-10| 107.1565933227539|109.10327170729724|106.96013847827562|107.82632203102112|  3653700|file:///home/pipe...|   TGT|\n",
      "|2020-06-10|  151.686767578125|154.91352086000182|149.73706627185112|154.24087152933086|  1502700|file:///home/pipe...|   URI|\n",
      "|2020-06-10|39.720001220703125|42.599998474121094| 38.29999923706055|42.040000915527344|105254900|file:///home/pipe...|   UAL|\n",
      "|2020-06-10| 40.73004150390625|43.021858930164605| 40.68983170505013|43.021858930164605| 31156800|file:///home/pipe...|   XOM|\n",
      "|2020-06-10| 47.50264358520508| 48.25956841513507| 46.56986969079578|48.213694091808144|  3231914|file:///home/pipe...|     O|\n",
      "|2020-06-10| 5.374337196350098|  5.79260443064963| 5.342769900513739| 5.784712418534615|147327100|file:///home/pipe...|     F|\n",
      "+----------+------------------+------------------+------------------+------------------+---------+--------------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_prices_clean.sort(desc(\"Date\")).show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 26:====================================>                 (78 + 28) / 115]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+------------------+------------------+------------------+-------+--------------------+------+\n",
      "|      Date|             Close|              High|               Low|              Open| Volume|           file_path|ticker|\n",
      "+----------+------------------+------------------+------------------+------------------+-------+--------------------+------+\n",
      "|2009-04-27|1.3759037256240845| 1.396287464122779|1.3623145666249548|1.3623145666249548|  77500|file:///home/pipe...|    FT|\n",
      "|2009-04-28|1.3820761442184448| 1.423229734914669|1.3752172124357407|1.3752172124357407| 100200|file:///home/pipe...|    FT|\n",
      "|2009-04-29|11.505555152893066|11.607656843311771|10.918471921856835|10.982284946628768|5516508|file:///home/pipe...|     A|\n",
      "|2009-04-29| 1.392364263534546|1.4129410559773448|1.3820759490780512|1.3992231943488123|  57600|file:///home/pipe...|    FT|\n",
      "|2009-04-30|11.652327537536621|12.086259583684875| 11.55022668035704| 11.55022668035704|4977998|file:///home/pipe...|     A|\n",
      "|2009-04-30|1.4026530981063843|1.4266592802943157| 1.399223550062479|1.4129414151783972|  98900|file:///home/pipe...|    FT|\n",
      "|2009-05-01|12.003300666809082|12.124545844495431|11.601275615668673|11.620419949317528|4039241|file:///home/pipe...|     A|\n",
      "|2009-05-01|1.4232300519943237|1.4369479186159182|1.3957943187511346|1.4129415702631931|  89400|file:///home/pipe...|    FT|\n",
      "|2009-05-04| 12.39256477355957| 12.39256477355957|11.965015246179265|12.003303923866483|3885042|file:///home/pipe...|     A|\n",
      "|2009-05-04|1.4609534740447998|1.4678124036329536| 1.436947138721371| 1.436947138721371| 133600|file:///home/pipe...|    FT|\n",
      "|2009-05-05|11.952250480651855|  12.3798007816726|11.850149627331806|12.354275568342587|4895656|file:///home/pipe...|     A|\n",
      "|2009-05-05|1.4918196201324463| 1.498678554523841| 1.457524948175473|1.4678134315275126| 172800|file:///home/pipe...|    FT|\n",
      "|2009-05-06|12.271319389343262|12.309606362266509| 11.97777685523774|12.099022906485796|4313529|file:///home/pipe...|     A|\n",
      "|2009-05-06|1.5192550420761108|1.5364024562572074|1.4918193102102457| 1.508966724391342| 144800|file:///home/pipe...|    FT|\n",
      "|2009-05-07|11.977778434753418| 12.35427839526537|11.862914948485143|12.347896665080729|3590903|file:///home/pipe...|     A|\n",
      "|2009-05-07|1.5226844549179077| 1.560408664643737| 1.508966590204851|1.5261138393312486| 145900|file:///home/pipe...|    FT|\n",
      "|2009-05-08|12.341517448425293|12.386186162600223| 12.04797483606182|12.099026132065223|3597893|file:///home/pipe...|     A|\n",
      "|2009-05-08| 1.577554702758789|1.5878431751605493|  1.53640114021119|1.5432600673024564| 153400|file:///home/pipe...|    FT|\n",
      "|2009-05-11|12.022442817687988| 12.23302706135982|11.850147237071802|12.169214040906335|2973686|file:///home/pipe...|     A|\n",
      "|2009-05-11|1.5432614088058472|1.5741266893115204|1.5261139944071704|1.5741266893115204|  88700|file:///home/pipe...|    FT|\n",
      "+----------+------------------+------------------+------------------+------------------+-------+--------------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_prices_clean.sort(asc(\"Date\")).show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prices_clean = df_prices_clean.withColumn(\"Date\", to_date(col(\"Date\"), \"yyyy-MM-dd\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.describe of DataFrame[Date: date, Close: string, High: string, Low: string, Open: string, Volume: string, file_path: string, ticker: string]>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_prices_clean.describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "window function allows to perform calculations across a set (or window) of rows related to the current row. In other words, every group of rows sharing the same ticker will be treated independently.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "w = Window.partitionBy(\"ticker\").orderBy(\"Date\")  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The lag function is a window function that allows you to access a previous row's value from the current row's partition. In this case, it takes the \"Close\" value (the closing price) from the previous row for the same ticker.\n",
    "\n",
    "over(w) applies the window specification w (i.e., partitioned by ticker and ordered by Date) to the lag function.\n",
    "\"\"\"\n",
    "\n",
    "df_prices_clean = df_prices_clean.withColumn(\"prev_close\", lag(\"Close\").over(w))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculation of daily percentage change "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prices_clean = df_prices_clean.withColumn(\"pct_change\", \n",
    "                                            when(col(\"prev_close\").isNull(), lit(0.0))\n",
    "                                            .otherwise((col(\"Close\") - col(\"prev_close\")) / col(\"prev_close\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prices_clean = df_prices_clean.drop(\"prev_close\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 42:===================================================>  (109 + 6) / 115]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------------+------------------+------------------+------------------+-------+--------------------+------+-----------------+--------------------+\n",
      "|      Date|            Close|              High|               Low|              Open| Volume|           file_path|ticker|       prev_close|          pct_change|\n",
      "+----------+-----------------+------------------+------------------+------------------+-------+--------------------+------+-----------------+--------------------+\n",
      "|2012-04-13|8.568169593811035| 8.746518853159165| 8.501288710142255| 8.731656119590928| 786200|file:///home/pipe...|  ACCO|             NULL|                 0.0|\n",
      "|2012-04-16|8.753949165344238| 8.902572951683151| 8.486426349934197| 8.620188111986275| 725500|file:///home/pipe...|  ACCO|8.568169593811035|0.021682527347193913|\n",
      "|2012-04-17|8.456703186035156| 8.709364024763426| 8.456703186035156| 8.627620395354722|1815100|file:///home/pipe...|  ACCO|8.753949165344238|-0.03395564375514...|\n",
      "|2012-04-18|8.412115097045898| 8.531014140175364| 8.152023617373741|  8.41954646441504|1551400|file:///home/pipe...|  ACCO|8.456703186035156|-0.00527251436031...|\n",
      "|2012-04-19|8.166884422302246| 8.441838595601435| 7.995967250532787| 8.397251815441617|2229500|file:///home/pipe...|  ACCO|8.412115097045898|-0.02915208267059...|\n",
      "|2012-04-20|8.196611404418945| 8.337804566885401| 8.114868479466034| 8.270923669790163| 751300|file:///home/pipe...|  ACCO|8.166884422302246|0.003639941571294966|\n",
      "|2012-04-23|7.936519622802734| 8.114868203188484|7.8473453326098594| 8.114868203188484| 953000|file:///home/pipe...|  ACCO|8.196611404418945|-0.03173162283574...|\n",
      "|2012-04-24|7.973672866821289| 8.025691720074319| 7.735874824615672| 7.943948111545587|1259200|file:///home/pipe...|  ACCO|7.936519622802734| 0.00468130185324663|\n",
      "|2012-04-25|7.817620277404785|  8.18174879260747| 7.735876649591856| 8.018262245675848| 907800|file:///home/pipe...|  ACCO|7.973672866821289|-0.01957097965052514|\n",
      "|2012-04-26|7.995965957641602|  8.07027748212368| 7.773029966807404| 7.817617448451835|1338100|file:///home/pipe...|  ACCO|7.817620277404785|  0.0228132953390289|\n",
      "|2012-04-27|8.152024269104004| 8.189180400226036| 7.884500691980787| 8.003400453310137|1015600|file:///home/pipe...|  ACCO|7.995965957641602|0.019517130549219035|\n",
      "|2012-04-30|7.839913368225098|  8.15202371450587|7.6541334339481715| 8.129729612132808|8582300|file:///home/pipe...|  ACCO|8.152024269104004|-0.03828630663696621|\n",
      "|2012-05-01|8.174315452575684| 9.883490643489413| 7.847343146298044|  7.96624216676264|5953300|file:///home/pipe...|  ACCO|7.839913368225098| 0.04265379840878169|\n",
      "|2012-05-02|8.374959945678711| 8.478996257400192|   7.8770696551155| 8.248629531136151|4821900|file:///home/pipe...|  ACCO|8.174315452575684|0.024545724258758003|\n",
      "|2012-05-03|8.308076858520508|  8.47156265049537| 8.166883746085633| 8.241195985124413|2276500|file:///home/pipe...|  ACCO|8.374959945678711|-0.00798607845195...|\n",
      "|2012-05-04|8.047985076904297| 8.360095360387627|  7.97367283466767| 8.256058362995162|4409900|file:///home/pipe...|  ACCO|8.308076858520508|-0.03130589497971108|\n",
      "|2012-05-07|7.765599250793457| 8.100002910646948|7.6467002347294635| 7.906792363889978|3464700|file:///home/pipe...|  ACCO|8.047985076904297|-0.03508776711343768|\n",
      "|2012-05-08|7.743308067321777| 7.832482354761689|  7.43119770693497| 7.698720569254703|2930900|file:///home/pipe...|  ACCO|7.765599250793457|-0.00287050396907...|\n",
      "|2012-05-09|7.505510330200195| 7.624409385866101| 7.282574246479484|7.5649598580331485|2895900|file:///home/pipe...|  ACCO|7.743308067321777|-0.03071009638956939|\n",
      "|2012-05-10|7.706151008605957|7.8324814110990175| 7.438628178517556| 7.579820606112896|3047900|file:///home/pipe...|  ACCO|7.505510330200195| 0.02673244983734637|\n",
      "+----------+-----------------+------------------+------------------+------------------+-------+--------------------+------+-----------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_prices_clean.show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prices_clean = df_prices_clean.withColumn(\n",
    "    \"movement_label\",\n",
    "    when(col(\"pct_change\") > 0, \"up\")\n",
    "    .when(col(\"pct_change\") < 0, \"down\")\n",
    "    .otherwise(\"neutral\")\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use lag(\"Close\").over(w) to compute the previous day’s closing price, and then compute the percent change. Then we define a target variable (label) for the daily price movement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 51:==============================================>       (99 + 16) / 115]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------------+------------------+------------------+------------------+-------+--------------------+------+-----------------+--------------------+--------------+\n",
      "|      Date|            Close|              High|               Low|              Open| Volume|           file_path|ticker|       prev_close|          pct_change|movement_label|\n",
      "+----------+-----------------+------------------+------------------+------------------+-------+--------------------+------+-----------------+--------------------+--------------+\n",
      "|2012-04-13|8.568169593811035| 8.746518853159165| 8.501288710142255| 8.731656119590928| 786200|file:///home/pipe...|  ACCO|             NULL|                 0.0|       neutral|\n",
      "|2012-04-16|8.753949165344238| 8.902572951683151| 8.486426349934197| 8.620188111986275| 725500|file:///home/pipe...|  ACCO|8.568169593811035|0.021682527347193913|            up|\n",
      "|2012-04-17|8.456703186035156| 8.709364024763426| 8.456703186035156| 8.627620395354722|1815100|file:///home/pipe...|  ACCO|8.753949165344238|-0.03395564375514...|          down|\n",
      "|2012-04-18|8.412115097045898| 8.531014140175364| 8.152023617373741|  8.41954646441504|1551400|file:///home/pipe...|  ACCO|8.456703186035156|-0.00527251436031...|          down|\n",
      "|2012-04-19|8.166884422302246| 8.441838595601435| 7.995967250532787| 8.397251815441617|2229500|file:///home/pipe...|  ACCO|8.412115097045898|-0.02915208267059...|          down|\n",
      "|2012-04-20|8.196611404418945| 8.337804566885401| 8.114868479466034| 8.270923669790163| 751300|file:///home/pipe...|  ACCO|8.166884422302246|0.003639941571294966|            up|\n",
      "|2012-04-23|7.936519622802734| 8.114868203188484|7.8473453326098594| 8.114868203188484| 953000|file:///home/pipe...|  ACCO|8.196611404418945|-0.03173162283574...|          down|\n",
      "|2012-04-24|7.973672866821289| 8.025691720074319| 7.735874824615672| 7.943948111545587|1259200|file:///home/pipe...|  ACCO|7.936519622802734| 0.00468130185324663|            up|\n",
      "|2012-04-25|7.817620277404785|  8.18174879260747| 7.735876649591856| 8.018262245675848| 907800|file:///home/pipe...|  ACCO|7.973672866821289|-0.01957097965052514|          down|\n",
      "|2012-04-26|7.995965957641602|  8.07027748212368| 7.773029966807404| 7.817617448451835|1338100|file:///home/pipe...|  ACCO|7.817620277404785|  0.0228132953390289|            up|\n",
      "|2012-04-27|8.152024269104004| 8.189180400226036| 7.884500691980787| 8.003400453310137|1015600|file:///home/pipe...|  ACCO|7.995965957641602|0.019517130549219035|            up|\n",
      "|2012-04-30|7.839913368225098|  8.15202371450587|7.6541334339481715| 8.129729612132808|8582300|file:///home/pipe...|  ACCO|8.152024269104004|-0.03828630663696621|          down|\n",
      "|2012-05-01|8.174315452575684| 9.883490643489413| 7.847343146298044|  7.96624216676264|5953300|file:///home/pipe...|  ACCO|7.839913368225098| 0.04265379840878169|            up|\n",
      "|2012-05-02|8.374959945678711| 8.478996257400192|   7.8770696551155| 8.248629531136151|4821900|file:///home/pipe...|  ACCO|8.174315452575684|0.024545724258758003|            up|\n",
      "|2012-05-03|8.308076858520508|  8.47156265049537| 8.166883746085633| 8.241195985124413|2276500|file:///home/pipe...|  ACCO|8.374959945678711|-0.00798607845195...|          down|\n",
      "|2012-05-04|8.047985076904297| 8.360095360387627|  7.97367283466767| 8.256058362995162|4409900|file:///home/pipe...|  ACCO|8.308076858520508|-0.03130589497971108|          down|\n",
      "|2012-05-07|7.765599250793457| 8.100002910646948|7.6467002347294635| 7.906792363889978|3464700|file:///home/pipe...|  ACCO|8.047985076904297|-0.03508776711343768|          down|\n",
      "|2012-05-08|7.743308067321777| 7.832482354761689|  7.43119770693497| 7.698720569254703|2930900|file:///home/pipe...|  ACCO|7.765599250793457|-0.00287050396907...|          down|\n",
      "|2012-05-09|7.505510330200195| 7.624409385866101| 7.282574246479484|7.5649598580331485|2895900|file:///home/pipe...|  ACCO|7.743308067321777|-0.03071009638956939|          down|\n",
      "|2012-05-10|7.706151008605957|7.8324814110990175| 7.438628178517556| 7.579820606112896|3047900|file:///home/pipe...|  ACCO|7.505510330200195| 0.02673244983734637|            up|\n",
      "+----------+-----------------+------------------+------------------+------------------+-------+--------------------+------+-----------------+--------------------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_prices_clean.show(20)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we join both df, this join aligns each day’s price movement with the aggregated sentiment of the previous day’s news. We use a left join so that if a price day has no corresponding news, we still keep the record (filling the news features with default values). For example, set the default \"neutral\" sentiment at 1.0 (if you encoded neutral as 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_joined = df_prices_clean.join(\n",
    "    df_news_agg,\n",
    "    (df_prices_clean.ticker == df_news_agg.stock) &\n",
    "    (df_prices_clean.Date == df_news_agg.effective_date),\n",
    "    how=\"left\"  # Use left join to keep all price records\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = df_joined.withColumn(\n",
    "    \"movement_numeric\",\n",
    "    when(col(\"movement_label\") == \"up\", 2)\n",
    "    .when(col(\"movement_label\") == \"neutral\", 1)\n",
    "    .when(col(\"movement_label\") == \"down\", 0)\n",
    "    .otherwise(1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 57:===>                                                    (2 + 28) / 30]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+------------------+------------------+------------------+---------+--------------------+------+------------------+--------------------+--------------+-----+----------+-------------+----------+--------------+----------------+\n",
      "|      Date|             Close|              High|               Low|              Open|   Volume|           file_path|ticker|        prev_close|          pct_change|movement_label|stock| news_date|avg_sentiment| join_date|effective_date|movement_numeric|\n",
      "+----------+------------------+------------------+------------------+------------------+---------+--------------------+------+------------------+--------------------+--------------+-----+----------+-------------+----------+--------------+----------------+\n",
      "|2013-10-03|              10.0|10.010000228881836| 9.800000190734863|              10.0|    72400|file:///home/pipe...|  AAOI| 9.970000267028809|0.003009000217422...|            up| NULL|      NULL|         NULL|      NULL|          NULL|               2|\n",
      "|2013-10-16|             10.25|10.279999732971191|10.010000228881836|10.279999732971191|     7100|file:///home/pipe...|  AAOI|10.180000305175781|0.006876197713729837|            up| NULL|      NULL|         NULL|      NULL|          NULL|               2|\n",
      "|2009-09-09| 36.47001647949219| 36.75967165248416| 36.15403023561187|36.522681969573924|  1791700|file:///home/pipe...|   AAP|  36.4261360168457|0.001204642255390232|            up| NULL|      NULL|         NULL|      NULL|          NULL|               2|\n",
      "|2009-09-10|35.644954681396484| 36.65435176789469| 35.42552009542217|36.408586103061396|  3503400|file:///home/pipe...|   AAP| 36.47001647949219|-0.02262301687084...|          down| NULL|      NULL|         NULL|      NULL|          NULL|               0|\n",
      "|2020-03-17| 61.36381912231445|  62.5165408014644|57.854678750743666| 60.06548484229005|324056000|file:///home/pipe...|  AAPL|  58.7792854309082|  0.0439701447960647|            up| AAPL|2020-03-16|          0.0|2020-03-17|    2020-03-17|               2|\n",
      "|2020-03-31|61.710845947265625| 63.70081315714961| 61.15511262455559| 62.02875857181586|197002000|file:///home/pipe...|  AAPL|61.837032318115234|-0.00204062785873...|          down| AAPL|2020-03-30|          0.0|2020-03-31|    2020-03-31|               0|\n",
      "|2020-04-06|63.695960998535156|63.851271716138356| 60.51929359909339| 60.88816303362977|201820400|file:///home/pipe...|  AAPL| 58.58515548706055|  0.0872372099891996|            up| AAPL|2020-04-05|          0.0|2020-04-06|    2020-04-06|               2|\n",
      "|2009-08-25|  6.11391019821167| 6.136971208672484| 5.969782181660092| 5.969782181660092|   663300|file:///home/pipe...|    AB| 5.955367088317871|0.026621887037794723|            up| NULL|      NULL|         NULL|      NULL|          NULL|               2|\n",
      "|2020-03-16|        20.1484375|21.052947788400637| 19.79770963158421|20.028452159875744|   984100|file:///home/pipe...|  ABCB|23.711095809936523|-0.15025279044435952|          down| NULL|      NULL|         NULL|      NULL|          NULL|               0|\n",
      "|2020-03-18|18.773210525512695|21.569810346364065|18.136360712759288|21.062175774298797|   948800|file:///home/pipe...|  ABCB|22.455862045288086|-0.16399510792987443|          down| NULL|      NULL|         NULL|      NULL|          NULL|               0|\n",
      "|2020-04-01|20.943246841430664|21.454283634531347|20.209210306079516|20.841038773918395|   433900|file:///home/pipe...|  ABCB| 22.07680892944336|-0.05134628340696867|          down| NULL|      NULL|         NULL|      NULL|          NULL|               0|\n",
      "|2020-04-02|21.296321868896484|21.705152277473537| 20.54370366283527|20.701660745315273|   440300|file:///home/pipe...|  ABCB|20.943246841430664|0.016858657596841905|            up| NULL|      NULL|         NULL|      NULL|          NULL|               2|\n",
      "|2011-06-03|2.9200000762939453|3.2699999809265137|2.9200000762939453|3.1500000953674316|    48777|file:///home/pipe...|  ABCD|3.2200000286102295|-0.09316768622693643|          down| NULL|      NULL|         NULL|      NULL|          NULL|               0|\n",
      "|2014-01-14| 4.904768943786621| 4.945248428896133| 4.857542716974348| 4.877782620380279|  9118300|file:///home/pipe...|  ABEV| 4.884530067443848|0.004143464379033859|            up| NULL|      NULL|         NULL|      NULL|          NULL|               2|\n",
      "|2010-09-07|13.079999923706055|  13.5600004196167|13.020000457763672|13.539999961853027|   140500|file:///home/pipe...|   ABG|13.600000381469727|-0.03823532670426...|          down| NULL|      NULL|         NULL|      NULL|          NULL|               0|\n",
      "|2017-09-18| 33.60163116455078| 33.98766027782365| 33.37001696899085| 33.98766027782365|   319500|file:///home/pipe...|   ABM| 33.93619155883789|-0.00985851325441322|          down| NULL|      NULL|         NULL|      NULL|          NULL|               0|\n",
      "|2017-10-05|36.861915588378906|37.266708710641204|36.853304436721146|37.034168190540214|   350900|file:///home/pipe...|   ABM| 37.04277038574219|-0.00488232374306...|          down| NULL|      NULL|         NULL|      NULL|          NULL|               0|\n",
      "|2018-02-05|118.58000183105469|120.74299621582031|110.45999908447266| 118.6500015258789|    28586|file:///home/pipe...|  ACET|119.27999877929688|-0.00586851907617293|          down| NULL|      NULL|         NULL|      NULL|          NULL|               0|\n",
      "|2009-09-16| 5.170000076293945| 5.210000038146973|5.0833330154418945| 5.123332977294922|   302100|file:///home/pipe...|  ACIW| 5.139999866485596|0.005836616845840862|            up| NULL|      NULL|         NULL|      NULL|          NULL|               2|\n",
      "|2009-10-05|4.8333330154418945| 4.869999885559082| 4.763332843780518| 4.800000190734863|   509100|file:///home/pipe...|  ACIW| 4.796667098999023|0.007644040265067092|            up| NULL|      NULL|         NULL|      NULL|          NULL|               2|\n",
      "+----------+------------------+------------------+------------------+------------------+---------+--------------------+------+------------------+--------------------+--------------+-----+----------+-------------+----------+--------------+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_final.show(20)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When there is no sentiment available (i.e. no news for that stock on that day), we impute the average sentiment as “neutral” (1). With this we interpret that in that specific day there wasn't any sentiment towards that stock, this might bias the model but for lack of time is the selected approach "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = df_final.fillna({\"avg_sentiment\": 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 68:====================================>                  (20 + 10) / 30]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+------------------+------------------+------------------+---------+--------------------+------+------------------+--------------------+--------------+-----+----------+-------------+----------+--------------+----------------+\n",
      "|      Date|             Close|              High|               Low|              Open|   Volume|           file_path|ticker|        prev_close|          pct_change|movement_label|stock| news_date|avg_sentiment| join_date|effective_date|movement_numeric|\n",
      "+----------+------------------+------------------+------------------+------------------+---------+--------------------+------+------------------+--------------------+--------------+-----+----------+-------------+----------+--------------+----------------+\n",
      "|2013-10-03|              10.0|10.010000228881836| 9.800000190734863|              10.0|    72400|file:///home/pipe...|  AAOI| 9.970000267028809|0.003009000217422...|            up| NULL|      NULL|          0.0|      NULL|          NULL|               2|\n",
      "|2013-10-16|             10.25|10.279999732971191|10.010000228881836|10.279999732971191|     7100|file:///home/pipe...|  AAOI|10.180000305175781|0.006876197713729837|            up| NULL|      NULL|          0.0|      NULL|          NULL|               2|\n",
      "|2009-09-09| 36.47001647949219| 36.75967165248416| 36.15403023561187|36.522681969573924|  1791700|file:///home/pipe...|   AAP|  36.4261360168457|0.001204642255390232|            up| NULL|      NULL|          0.0|      NULL|          NULL|               2|\n",
      "|2009-09-10|35.644954681396484| 36.65435176789469| 35.42552009542217|36.408586103061396|  3503400|file:///home/pipe...|   AAP| 36.47001647949219|-0.02262301687084...|          down| NULL|      NULL|          0.0|      NULL|          NULL|               0|\n",
      "|2020-03-17| 61.36381912231445|  62.5165408014644|57.854678750743666| 60.06548484229005|324056000|file:///home/pipe...|  AAPL|  58.7792854309082|  0.0439701447960647|            up| AAPL|2020-03-16|          0.0|2020-03-17|    2020-03-17|               2|\n",
      "|2020-03-31|61.710845947265625| 63.70081315714961| 61.15511262455559| 62.02875857181586|197002000|file:///home/pipe...|  AAPL|61.837032318115234|-0.00204062785873...|          down| AAPL|2020-03-30|          0.0|2020-03-31|    2020-03-31|               0|\n",
      "|2020-04-06|63.695960998535156|63.851271716138356| 60.51929359909339| 60.88816303362977|201820400|file:///home/pipe...|  AAPL| 58.58515548706055|  0.0872372099891996|            up| AAPL|2020-04-05|          0.0|2020-04-06|    2020-04-06|               2|\n",
      "|2009-08-25|  6.11391019821167| 6.136971208672484| 5.969782181660092| 5.969782181660092|   663300|file:///home/pipe...|    AB| 5.955367088317871|0.026621887037794723|            up| NULL|      NULL|          0.0|      NULL|          NULL|               2|\n",
      "|2020-03-16|        20.1484375|21.052947788400637| 19.79770963158421|20.028452159875744|   984100|file:///home/pipe...|  ABCB|23.711095809936523|-0.15025279044435952|          down| NULL|      NULL|          0.0|      NULL|          NULL|               0|\n",
      "|2020-03-18|18.773210525512695|21.569810346364065|18.136360712759288|21.062175774298797|   948800|file:///home/pipe...|  ABCB|22.455862045288086|-0.16399510792987443|          down| NULL|      NULL|          0.0|      NULL|          NULL|               0|\n",
      "|2020-04-01|20.943246841430664|21.454283634531347|20.209210306079516|20.841038773918395|   433900|file:///home/pipe...|  ABCB| 22.07680892944336|-0.05134628340696867|          down| NULL|      NULL|          0.0|      NULL|          NULL|               0|\n",
      "|2020-04-02|21.296321868896484|21.705152277473537| 20.54370366283527|20.701660745315273|   440300|file:///home/pipe...|  ABCB|20.943246841430664|0.016858657596841905|            up| NULL|      NULL|          0.0|      NULL|          NULL|               2|\n",
      "|2011-06-03|2.9200000762939453|3.2699999809265137|2.9200000762939453|3.1500000953674316|    48777|file:///home/pipe...|  ABCD|3.2200000286102295|-0.09316768622693643|          down| NULL|      NULL|          0.0|      NULL|          NULL|               0|\n",
      "|2014-01-14| 4.904768943786621| 4.945248428896133| 4.857542716974348| 4.877782620380279|  9118300|file:///home/pipe...|  ABEV| 4.884530067443848|0.004143464379033859|            up| NULL|      NULL|          0.0|      NULL|          NULL|               2|\n",
      "|2010-09-07|13.079999923706055|  13.5600004196167|13.020000457763672|13.539999961853027|   140500|file:///home/pipe...|   ABG|13.600000381469727|-0.03823532670426...|          down| NULL|      NULL|          0.0|      NULL|          NULL|               0|\n",
      "|2017-09-18| 33.60163116455078| 33.98766027782365| 33.37001696899085| 33.98766027782365|   319500|file:///home/pipe...|   ABM| 33.93619155883789|-0.00985851325441322|          down| NULL|      NULL|          0.0|      NULL|          NULL|               0|\n",
      "|2017-10-05|36.861915588378906|37.266708710641204|36.853304436721146|37.034168190540214|   350900|file:///home/pipe...|   ABM| 37.04277038574219|-0.00488232374306...|          down| NULL|      NULL|          0.0|      NULL|          NULL|               0|\n",
      "|2018-02-05|118.58000183105469|120.74299621582031|110.45999908447266| 118.6500015258789|    28586|file:///home/pipe...|  ACET|119.27999877929688|-0.00586851907617293|          down| NULL|      NULL|          0.0|      NULL|          NULL|               0|\n",
      "|2009-09-16| 5.170000076293945| 5.210000038146973|5.0833330154418945| 5.123332977294922|   302100|file:///home/pipe...|  ACIW| 5.139999866485596|0.005836616845840862|            up| NULL|      NULL|          0.0|      NULL|          NULL|               2|\n",
      "|2009-10-05|4.8333330154418945| 4.869999885559082| 4.763332843780518| 4.800000190734863|   509100|file:///home/pipe...|  ACIW| 4.796667098999023|0.007644040265067092|            up| NULL|      NULL|          0.0|      NULL|          NULL|               2|\n",
      "+----------+------------------+------------------+------------------+------------------+---------+--------------------+------+------------------+--------------------+--------------+-----+----------+-------------+----------+--------------+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_final.show(20)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML models implementation and comparison "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the feature columns. \n",
    "feature_cols = [\"pct_change\", \"avg_sentiment\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(inputCols=feature_cols, outputCol=\"features\") #to combine features into a single column \n",
    "df_features = assembler.transform(df_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "indexer = StringIndexer(inputCol=\"movement_label\", outputCol=\"label\")\n",
    "df_features = indexer.fit(df_features).transform(df_features)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = df_features.randomSplit([0.8, 0.2], seed=42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler, StandardScaler\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the features using StandardScaler\n",
    "#    We turn on centering (withMean=True) and scaling (withStd=True).\n",
    "scaler = StandardScaler(\n",
    "    inputCol=\"features\",\n",
    "    outputCol=\"scaled_features\",\n",
    "    withMean=True,\n",
    "    withStd=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/04/11 18:59:10 ERROR StrongWolfeLineSearch: Encountered bad values in function evaluation. Decreasing step size to 0.5\n",
      "25/04/11 18:59:10 ERROR StrongWolfeLineSearch: Encountered bad values in function evaluation. Decreasing step size to 0.5\n",
      "25/04/11 18:59:10 ERROR StrongWolfeLineSearch: Encountered bad values in function evaluation. Decreasing step size to 0.25\n",
      "25/04/11 18:59:10 ERROR StrongWolfeLineSearch: Encountered bad values in function evaluation. Decreasing step size to 0.5\n",
      "25/04/11 18:59:10 ERROR StrongWolfeLineSearch: Encountered bad values in function evaluation. Decreasing step size to 0.25\n",
      "25/04/11 18:59:10 ERROR StrongWolfeLineSearch: Encountered bad values in function evaluation. Decreasing step size to 0.125\n",
      "25/04/11 18:59:10 ERROR StrongWolfeLineSearch: Encountered bad values in function evaluation. Decreasing step size to 0.0625\n",
      "25/04/11 18:59:11 ERROR StrongWolfeLineSearch: Encountered bad values in function evaluation. Decreasing step size to 0.03125\n",
      "25/04/11 18:59:11 ERROR StrongWolfeLineSearch: Encountered bad values in function evaluation. Decreasing step size to 0.015625\n",
      "25/04/11 18:59:11 ERROR StrongWolfeLineSearch: Encountered bad values in function evaluation. Decreasing step size to 0.017578125\n",
      "25/04/11 18:59:12 ERROR LBFGS: Failure! Resetting history: breeze.optimize.FirstOrderException: Line search zoom failed\n",
      "25/04/11 18:59:14 ERROR StrongWolfeLineSearch: Encountered bad values in function evaluation. Decreasing step size to 0.5\n",
      "25/04/11 18:59:24 ERROR StrongWolfeLineSearch: Encountered bad values in function evaluation. Decreasing step size to 0.5\n",
      "25/04/11 18:59:24 ERROR StrongWolfeLineSearch: Encountered bad values in function evaluation. Decreasing step size to 0.25\n",
      "[Stage 1949:==========================================>           (23 + 6) / 29]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression F1 score: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Create the Logistic Regression model\n",
    "lr = LogisticRegression(featuresCol=\"features\", labelCol=\"label\", maxIter=100)\n",
    "\n",
    "# Fit the model\n",
    "lr_model = lr.fit(train_df)\n",
    "\n",
    "# Make predictions\n",
    "lr_predictions = lr_model.transform(test_df)\n",
    "\n",
    "# Evaluate the model\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"f1\")\n",
    "lr_f1 = evaluator.evaluate(lr_predictions)\n",
    "\n",
    "print(\"Logistic Regression F1 score: {:.2f}%\".format(lr_f1 * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients matrix:\n",
      " DenseMatrix([[ 2.48760694e+08, -2.90275116e+02],\n",
      "             [-2.48759446e+08,  1.40006751e+02],\n",
      "             [-1.24842701e+03,  1.50268365e+02]])\n",
      "Intercepts: [-4.502981337633845,-3.7929765935139024,8.295957931147747]\n"
     ]
    }
   ],
   "source": [
    "print(\"Coefficients matrix:\\n \" + str(lr_model.coefficientMatrix))\n",
    "print(\"Intercepts: \" + str(lr_model.interceptVector))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1042:==================================================>   (28 + 2) / 30]\r"
     ]
    }
   ],
   "source": [
    "# Create the Random Forest classifier model. You can tweak hyperparameters like numTrees, maxDepth, etc.\n",
    "rf = RandomForestClassifier(featuresCol=\"features\", labelCol=\"label\", numTrees=50, maxDepth=5)\n",
    "\n",
    "# Fit the model\n",
    "rf_model = rf.fit(train_df)\n",
    "\n",
    "# Make predictions\n",
    "rf_predictions = rf_model.transform(test_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1055:====================================================> (28 + 1) / 29]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest F1: 99.99%\n",
      "Feature Importances: (2,[0],[1.0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "rf_f1 = evaluator.evaluate(rf_predictions)\n",
    "print(\"Random Forest F1: {:.2f}%\".format(rf_f1 * 100))\n",
    "\n",
    "# Optionally inspect feature importance:\n",
    "feature_importances = rf_model.featureImportances\n",
    "print(\"Feature Importances: \" + str(feature_importances))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BigDataVenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
